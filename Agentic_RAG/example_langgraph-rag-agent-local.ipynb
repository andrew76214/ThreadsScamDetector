{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f53f753-12c6-4fac-b910-6e96677d8a49",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/meta-llama/llama-recipes/blob/main/recipes/use_cases/agents/langchain/langgraph-rag-agent-local.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b9ab14a-fd80-4ca2-afc5-efe1c39532bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -U langchain_community tiktoken langchainhub pymilvus langchain langgraph tavily-python sentence-transformers langchain-milvus langchain-huggingface"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0216de30-29cf-4464-9cc3-6e9a6d6c3e40",
   "metadata": {},
   "source": [
    "# Local LangGraph RAG agent with Llama 3\n",
    "\n",
    "\n",
    "Let's build an Advanced RAG that will run everything locally, for that we will use Ollama.\n",
    "\n",
    "## Ideas\n",
    "\n",
    "We'll combine ideas from three RAG papers into a RAG agent:\n",
    "\n",
    "- **Routing:**  Adaptive RAG ([paper](https://arxiv.org/abs/2403.14403)). Route questions to different retrieval approaches\n",
    "- **Fallback:** Corrective RAG ([paper](https://arxiv.org/pdf/2401.15884.pdf)). Fallback to web search if docs are not relevant to query\n",
    "- **Self-correction:** Self-RAG ([paper](https://arxiv.org/abs/2310.11511)). Fix answers w/ hallucinations or don’t address question\n",
    "\n",
    "![langgraph_adaptive_rag.png](imgs/RAG_Agent_langGraph.png)\n",
    "\n",
    "Note that this will incorperate [a few general ideas for agents](https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/):\n",
    "\n",
    "- **Reflection**: The self-correction mechanism is a form of reflection, where the LangGraph agent reflects on its retrieval and generations\n",
    "- **Planning**: The control flow laid out in the graph is a form of planning \n",
    "- **Tool use**: Specific nodes in the control flow (e.g., web search) will use tools\n",
    "\n",
    "## Local models\n",
    "\n",
    "### LLM\n",
    "\n",
    "Use [Ollama](https://ollama.ai/) and [llama3](https://ollama.ai/library/llama3):\n",
    "\n",
    "```\n",
    "ollama pull llama3\n",
    "```\n",
    "\n",
    "### Search\n",
    "\n",
    "Uses [Tavily](https://tavily.com/#api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d2242c5-0dbb-4f21-9771-92f6d679b1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3897d23e-011f-469c-ad72-829c429e2840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_verbose, set_debug\n",
    "\n",
    "set_debug(True)\n",
    "set_verbose(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2096d49c-d3dc-4329-ada7-aff56d210198",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LLM\n",
    "\n",
    "local_llm = 'llama3.2:3b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "267c63e1-4c2f-439d-8d95-4c6aa01f41cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2744783/3604890853.py:25: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embedding=HuggingFaceEmbeddings(),\n"
     ]
    }
   ],
   "source": [
    "### Index\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_milvus import Milvus\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to Milvus\n",
    "vectorstore = Milvus.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag_milvus\",\n",
    "    embedding=HuggingFaceEmbeddings(),\n",
    "    connection_args={\"uri\": \"./milvus_rag.db\"},\n",
    "\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b008df98-8394-49da-8fb8-aefe2c90d03c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"agent memory\",\n",
      "  \"document\": \"Each element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"agent memory\",\n",
      "  \"document\": \"Each element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing relevance \\n    of a retrieved document to a user question. If the document contains keywords related to the user question, \\n    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n    \\n    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\\n    Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\\n     \\n    Here is the retrieved document: \\n    Each element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n    \\n    Here is the user question: \\n    agent memory\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [49ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:21.173271498Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 47716845,\n",
      "          \"load_duration\": 9058241,\n",
      "          \"prompt_eval_count\": 331,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 33000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:21.173271498Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 47716845,\n",
      "              \"load_duration\": 9058241,\n",
      "              \"prompt_eval_count\": 331,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 33000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-2cd8a88d-1a02-487a-b823-aa88544c04b1-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [50ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "### Retrieval Grader \n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing relevance \n",
    "    of a retrieved document to a user question. If the document contains keywords related to the user question, \n",
    "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \n",
    "    \n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\n",
    "     \n",
    "    Here is the retrieved document: \n",
    "    {document}\n",
    "    \n",
    "    Here is the user question: \n",
    "    {question}\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "retrieval_grader = prompt | llm | JsonOutputParser()\n",
    "question = \"agent memory\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d531a81-6d4d-405e-975a-01ef1c9679fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: agent memory \\n    Context: [Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\\\n\\\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\\\n\\\\n\\\\nTool use\\\\n\\\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\\\n\\\\n\\\\n\\\\n\\\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'pk': 454469909457666083, 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \\\"LLM Powered Autonomous Agents | Lil'Log\\\"}, page_content='Each element is an observation, an event directly provided by the agent.\\\\n- Inter-agent communication can trigger new natural language statements.\\\\n\\\\n\\\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\\\n\\\\nRecency: recent events have higher scores\\\\nImportance: distinguish mundane from core memories. Ask LM directly.\\\\nRelevance: based on how related it is to the current situation / query.\\\\n\\\\n\\\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\\\n\\\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\\\n\\\\n\\\\nPlanning & Reacting: translate the reflections and the environment information into actions'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\\\n\\\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\\\n\\\\n\\\\nTool use\\\\n\\\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\\\n\\\\n\\\\n\\\\n\\\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'pk': 454470049711521827, 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \\\"LLM Powered Autonomous Agents | Lil'Log\\\"}, page_content='Each element is an observation, an event directly provided by the agent.\\\\n- Inter-agent communication can trigger new natural language statements.\\\\n\\\\n\\\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\\\n\\\\nRecency: recent events have higher scores\\\\nImportance: distinguish mundane from core memories. Ask LM directly.\\\\nRelevance: based on how related it is to the current situation / query.\\\\n\\\\n\\\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\\\n\\\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\\\n\\\\n\\\\nPlanning & Reacting: translate the reflections and the environment information into actions'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\\\n\\\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\\\n\\\\n\\\\nTool use\\\\n\\\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\\\n\\\\n\\\\n\\\\n\\\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'pk': 454470395555479587, 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \\\"LLM Powered Autonomous Agents | Lil'Log\\\"}, page_content='Each element is an observation, an event directly provided by the agent.\\\\n- Inter-agent communication can trigger new natural language statements.\\\\n\\\\n\\\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\\\n\\\\nRecency: recent events have higher scores\\\\nImportance: distinguish mundane from core memories. Ask LM directly.\\\\nRelevance: based on how related it is to the current situation / query.\\\\n\\\\n\\\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\\\n\\\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\\\n\\\\n\\\\nPlanning & Reacting: translate the reflections and the environment information into actions'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\\\n\\\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\\\n\\\\n\\\\nTool use\\\\n\\\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\\\n\\\\n\\\\n\\\\n\\\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'pk': 454470497206534179, 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \\\"LLM Powered Autonomous Agents | Lil'Log\\\"}, page_content='Each element is an observation, an event directly provided by the agent.\\\\n- Inter-agent communication can trigger new natural language statements.\\\\n\\\\n\\\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\\\n\\\\nRecency: recent events have higher scores\\\\nImportance: distinguish mundane from core memories. Ask LM directly.\\\\nRelevance: based on how related it is to the current situation / query.\\\\n\\\\n\\\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\\\n\\\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\\\n\\\\n\\\\nPlanning & Reacting: translate the reflections and the environment information into actions')] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [1.16s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The text appears to be a collection of articles or blog posts about Large Language Models (LLMs) and their applications in autonomous agents. The content is not particularly cohesive, but it seems to cover various aspects of LLMs, including:\\n\\n1. Introduction to LLMs and their potential as a core controller for autonomous agents.\\n2. Explanation of the different components of an LLM-powered autonomous agent system, including planning, memory, and tool use.\\n3. Discussion of how LLMs can be used to learn from observations and generate high-level questions to answer.\\n4. Examples of proof-of-concept demos, such as AutoGPT, GPT-Engineer, and BabyAGI.\\n\\nThe text does not provide a clear narrative or argument, but rather presents various concepts and ideas related to LLMs and autonomous agents. It appears to be intended for an audience interested in AI and machine learning, particularly those familiar with the basics of language models and their applications.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:22.339097746Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 1153873195,\n",
      "          \"load_duration\": 9808227,\n",
      "          \"prompt_eval_count\": 2048,\n",
      "          \"prompt_eval_duration\": 97000000,\n",
      "          \"eval_count\": 197,\n",
      "          \"eval_duration\": 1045000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The text appears to be a collection of articles or blog posts about Large Language Models (LLMs) and their applications in autonomous agents. The content is not particularly cohesive, but it seems to cover various aspects of LLMs, including:\\n\\n1. Introduction to LLMs and their potential as a core controller for autonomous agents.\\n2. Explanation of the different components of an LLM-powered autonomous agent system, including planning, memory, and tool use.\\n3. Discussion of how LLMs can be used to learn from observations and generate high-level questions to answer.\\n4. Examples of proof-of-concept demos, such as AutoGPT, GPT-Engineer, and BabyAGI.\\n\\nThe text does not provide a clear narrative or argument, but rather presents various concepts and ideas related to LLMs and autonomous agents. It appears to be intended for an audience interested in AI and machine learning, particularly those familiar with the basics of language models and their applications.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:22.339097746Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 1153873195,\n",
      "              \"load_duration\": 9808227,\n",
      "              \"prompt_eval_count\": 2048,\n",
      "              \"prompt_eval_duration\": 97000000,\n",
      "              \"eval_count\": 197,\n",
      "              \"eval_duration\": 1045000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-a71a11b2-e7bd-4e21-a251-cb32744d5de8-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The text appears to be a collection of articles or blog posts about Large Language Models (LLMs) and their applications in autonomous agents. The content is not particularly cohesive, but it seems to cover various aspects of LLMs, including:\\n\\n1. Introduction to LLMs and their potential as a core controller for autonomous agents.\\n2. Explanation of the different components of an LLM-powered autonomous agent system, including planning, memory, and tool use.\\n3. Discussion of how LLMs can be used to learn from observations and generate high-level questions to answer.\\n4. Examples of proof-of-concept demos, such as AutoGPT, GPT-Engineer, and BabyAGI.\\n\\nThe text does not provide a clear narrative or argument, but rather presents various concepts and ideas related to LLMs and autonomous agents. It appears to be intended for an audience interested in AI and machine learning, particularly those familiar with the basics of language models and their applications.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [1.16s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The text appears to be a collection of articles or blog posts about Large Language Models (LLMs) and their applications in autonomous agents. The content is not particularly cohesive, but it seems to cover various aspects of LLMs, including:\\n\\n1. Introduction to LLMs and their potential as a core controller for autonomous agents.\\n2. Explanation of the different components of an LLM-powered autonomous agent system, including planning, memory, and tool use.\\n3. Discussion of how LLMs can be used to learn from observations and generate high-level questions to answer.\\n4. Examples of proof-of-concept demos, such as AutoGPT, GPT-Engineer, and BabyAGI.\\n\\nThe text does not provide a clear narrative or argument, but rather presents various concepts and ideas related to LLMs and autonomous agents. It appears to be intended for an audience interested in AI and machine learning, particularly those familiar with the basics of language models and their applications.\"\n",
      "}\n",
      "The text appears to be a collection of articles or blog posts about Large Language Models (LLMs) and their applications in autonomous agents. The content is not particularly cohesive, but it seems to cover various aspects of LLMs, including:\n",
      "\n",
      "1. Introduction to LLMs and their potential as a core controller for autonomous agents.\n",
      "2. Explanation of the different components of an LLM-powered autonomous agent system, including planning, memory, and tool use.\n",
      "3. Discussion of how LLMs can be used to learn from observations and generate high-level questions to answer.\n",
      "4. Examples of proof-of-concept demos, such as AutoGPT, GPT-Engineer, and BabyAGI.\n",
      "\n",
      "The text does not provide a clear narrative or argument, but rather presents various concepts and ideas related to LLMs and autonomous agents. It appears to be intended for an audience interested in AI and machine learning, particularly those familiar with the basics of language models and their applications.\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \n",
    "    Use three sentences maximum and keep the answer concise:\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer: \n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "question = \"agent memory\"\n",
    "docs = retriever.invoke(question)\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0261a9a4-de13-4dd8-b082-95305a3e43ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\\\n\\\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\\\n\\\\n\\\\nTool use\\\\n\\\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\\\n\\\\n\\\\n\\\\n\\\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'pk': 454469909457666083, 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \\\"LLM Powered Autonomous Agents | Lil'Log\\\"}, page_content='Each element is an observation, an event directly provided by the agent.\\\\n- Inter-agent communication can trigger new natural language statements.\\\\n\\\\n\\\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\\\n\\\\nRecency: recent events have higher scores\\\\nImportance: distinguish mundane from core memories. Ask LM directly.\\\\nRelevance: based on how related it is to the current situation / query.\\\\n\\\\n\\\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\\\n\\\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\\\n\\\\n\\\\nPlanning & Reacting: translate the reflections and the environment information into actions'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\\\n\\\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\\\n\\\\n\\\\nTool use\\\\n\\\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\\\n\\\\n\\\\n\\\\n\\\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'pk': 454470049711521827, 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \\\"LLM Powered Autonomous Agents | Lil'Log\\\"}, page_content='Each element is an observation, an event directly provided by the agent.\\\\n- Inter-agent communication can trigger new natural language statements.\\\\n\\\\n\\\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\\\n\\\\nRecency: recent events have higher scores\\\\nImportance: distinguish mundane from core memories. Ask LM directly.\\\\nRelevance: based on how related it is to the current situation / query.\\\\n\\\\n\\\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\\\n\\\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\\\n\\\\n\\\\nPlanning & Reacting: translate the reflections and the environment information into actions'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\\\n\\\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\\\n\\\\n\\\\nTool use\\\\n\\\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\\\n\\\\n\\\\n\\\\n\\\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'pk': 454470395555479587, 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \\\"LLM Powered Autonomous Agents | Lil'Log\\\"}, page_content='Each element is an observation, an event directly provided by the agent.\\\\n- Inter-agent communication can trigger new natural language statements.\\\\n\\\\n\\\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\\\n\\\\nRecency: recent events have higher scores\\\\nImportance: distinguish mundane from core memories. Ask LM directly.\\\\nRelevance: based on how related it is to the current situation / query.\\\\n\\\\n\\\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\\\n\\\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\\\n\\\\n\\\\nPlanning & Reacting: translate the reflections and the environment information into actions'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\\\n\\\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\\\n\\\\n\\\\nTool use\\\\n\\\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\\\n\\\\n\\\\n\\\\n\\\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'pk': 454470497206534179, 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \\\"LLM Powered Autonomous Agents | Lil'Log\\\"}, page_content='Each element is an observation, an event directly provided by the agent.\\\\n- Inter-agent communication can trigger new natural language statements.\\\\n\\\\n\\\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\\\n\\\\nRecency: recent events have higher scores\\\\nImportance: distinguish mundane from core memories. Ask LM directly.\\\\nRelevance: based on how related it is to the current situation / query.\\\\n\\\\n\\\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\\\n\\\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\\\n\\\\n\\\\nPlanning & Reacting: translate the reflections and the environment information into actions')] \\n\\n    Here is the answer: \\n    The text appears to be a collection of articles or blog posts about Large Language Models (LLMs) and their applications in autonomous agents. The content is not particularly cohesive, but it seems to cover various aspects of LLMs, including:\\n\\n1. Introduction to LLMs and their potential as a core controller for autonomous agents.\\n2. Explanation of the different components of an LLM-powered autonomous agent system, including planning, memory, and tool use.\\n3. Discussion of how LLMs can be used to learn from observations and generate high-level questions to answer.\\n4. Examples of proof-of-concept demos, such as AutoGPT, GPT-Engineer, and BabyAGI.\\n\\nThe text does not provide a clear narrative or argument, but rather presents various concepts and ideas related to LLMs and autonomous agents. It appears to be intended for an audience interested in AI and machine learning, particularly those familiar with the basics of language models and their applications.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [509ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"@context\\\": \\\"https://schema.org\\\", \\\"@type\\\": \\\"Question\\\", \\\"name\\\": \\\"What is the main topic of the text?\\\", \\\"acceptedAnswer\\\": {\\\"@type\\\": \\\"Answer\\\", \\\"text\\\": \\\"The main topic of the text appears to be Large Language Models (LLMs) and their applications in autonomous agents.\\\"}}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:22.85460338Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 507458076,\n",
      "          \"load_duration\": 9389879,\n",
      "          \"prompt_eval_count\": 2048,\n",
      "          \"prompt_eval_duration\": 96000000,\n",
      "          \"eval_count\": 69,\n",
      "          \"eval_duration\": 400000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"@context\\\": \\\"https://schema.org\\\", \\\"@type\\\": \\\"Question\\\", \\\"name\\\": \\\"What is the main topic of the text?\\\", \\\"acceptedAnswer\\\": {\\\"@type\\\": \\\"Answer\\\", \\\"text\\\": \\\"The main topic of the text appears to be Large Language Models (LLMs) and their applications in autonomous agents.\\\"}}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:22.85460338Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 507458076,\n",
      "              \"load_duration\": 9389879,\n",
      "              \"prompt_eval_count\": 2048,\n",
      "              \"prompt_eval_duration\": 96000000,\n",
      "              \"eval_count\": 69,\n",
      "              \"eval_duration\": 400000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-6b36f308-58c2-4728-b734-ad361393433c-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"@context\": \"https://schema.org\",\n",
      "  \"@type\": \"Question\",\n",
      "  \"name\": \"What is the main topic of the text?\",\n",
      "  \"acceptedAnswer\": {\n",
      "    \"@type\": \"Answer\",\n",
      "    \"text\": \"The main topic of the text appears to be Large Language Models (LLMs) and their applications in autonomous agents.\"\n",
      "  }\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [510ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"@context\": \"https://schema.org\",\n",
      "  \"@type\": \"Question\",\n",
      "  \"name\": \"What is the main topic of the text?\",\n",
      "  \"acceptedAnswer\": {\n",
      "    \"@type\": \"Answer\",\n",
      "    \"text\": \"The main topic of the text appears to be Large Language Models (LLMs) and their applications in autonomous agents.\"\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'@context': 'https://schema.org',\n",
       " '@type': 'Question',\n",
       " 'name': 'What is the main topic of the text?',\n",
       " 'acceptedAnswer': {'@type': 'Answer',\n",
       "  'text': 'The main topic of the text appears to be Large Language Models (LLMs) and their applications in autonomous agents.'}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Hallucination Grader \n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing whether \n",
    "    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \n",
    "    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \n",
    "    single key 'score' and no preamble or explanation.\n",
    "    \n",
    "    Here are the facts:\n",
    "    {documents} \n",
    "\n",
    "    Here is the answer: \n",
    "    {generation}\n",
    "    \"\"\",\n",
    "    input_variables=[\"generation\", \"documents\"],\n",
    ")\n",
    "\n",
    "hallucination_grader = prompt | llm | JsonOutputParser()\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df9f6944-4fee-4971-b3a7-2b81b44ed433",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"agent memory\",\n",
      "  \"generation\": \"The text appears to be a collection of articles or blog posts about Large Language Models (LLMs) and their applications in autonomous agents. The content is not particularly cohesive, but it seems to cover various aspects of LLMs, including:\\n\\n1. Introduction to LLMs and their potential as a core controller for autonomous agents.\\n2. Explanation of the different components of an LLM-powered autonomous agent system, including planning, memory, and tool use.\\n3. Discussion of how LLMs can be used to learn from observations and generate high-level questions to answer.\\n4. Examples of proof-of-concept demos, such as AutoGPT, GPT-Engineer, and BabyAGI.\\n\\nThe text does not provide a clear narrative or argument, but rather presents various concepts and ideas related to LLMs and autonomous agents. It appears to be intended for an audience interested in AI and machine learning, particularly those familiar with the basics of language models and their applications.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"agent memory\",\n",
      "  \"generation\": \"The text appears to be a collection of articles or blog posts about Large Language Models (LLMs) and their applications in autonomous agents. The content is not particularly cohesive, but it seems to cover various aspects of LLMs, including:\\n\\n1. Introduction to LLMs and their potential as a core controller for autonomous agents.\\n2. Explanation of the different components of an LLM-powered autonomous agent system, including planning, memory, and tool use.\\n3. Discussion of how LLMs can be used to learn from observations and generate high-level questions to answer.\\n4. Examples of proof-of-concept demos, such as AutoGPT, GPT-Engineer, and BabyAGI.\\n\\nThe text does not provide a clear narrative or argument, but rather presents various concepts and ideas related to LLMs and autonomous agents. It appears to be intended for an audience interested in AI and machine learning, particularly those familiar with the basics of language models and their applications.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether an \\n    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is \\n    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\\n     \\n    Here is the answer:\\n    The text appears to be a collection of articles or blog posts about Large Language Models (LLMs) and their applications in autonomous agents. The content is not particularly cohesive, but it seems to cover various aspects of LLMs, including:\\n\\n1. Introduction to LLMs and their potential as a core controller for autonomous agents.\\n2. Explanation of the different components of an LLM-powered autonomous agent system, including planning, memory, and tool use.\\n3. Discussion of how LLMs can be used to learn from observations and generate high-level questions to answer.\\n4. Examples of proof-of-concept demos, such as AutoGPT, GPT-Engineer, and BabyAGI.\\n\\nThe text does not provide a clear narrative or argument, but rather presents various concepts and ideas related to LLMs and autonomous agents. It appears to be intended for an audience interested in AI and machine learning, particularly those familiar with the basics of language models and their applications. \\n\\n    Here is the question: agent memory\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [59ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:22.917813836Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 57291675,\n",
      "          \"load_duration\": 9224418,\n",
      "          \"prompt_eval_count\": 301,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 43000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:22.917813836Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 57291675,\n",
      "              \"load_duration\": 9224418,\n",
      "              \"prompt_eval_count\": 301,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 43000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-645310a4-bfad-4566-bba2-c4a5c0b5cd2d-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [60ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Answer Grader \n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing whether an \n",
    "    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is \n",
    "    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "     \n",
    "    Here is the answer:\n",
    "    {generation} \n",
    "\n",
    "    Here is the question: {question}\n",
    "    \"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    ")\n",
    "\n",
    "answer_grader = prompt | llm | JsonOutputParser()\n",
    "answer_grader.invoke({\"question\": question,\"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9c910c1-738c-4bf7-bf9e-801862b227eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"llm agent memory\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"llm agent memory\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an expert at routing a \\n    user question to a vectorstore or web search. Use the vectorstore for questions on LLM  agents, \\n    prompt engineering, and adversarial attacks. You do not need to be stringent with the keywords \\n    in the question related to these topics. Otherwise, use web-search. Give a binary choice 'web_search' \\n    or 'vectorstore' based on the question. Return the a JSON with a single key 'datasource' and \\n    no premable or explaination. \\n    \\n    Question to route: \\n    llm agent memory\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [61ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"datasource\\\": \\\"vectorstore\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:22.990553691Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 59636891,\n",
      "          \"load_duration\": 8871963,\n",
      "          \"prompt_eval_count\": 146,\n",
      "          \"prompt_eval_duration\": 2000000,\n",
      "          \"eval_count\": 9,\n",
      "          \"eval_duration\": 47000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"datasource\\\": \\\"vectorstore\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:22.990553691Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 59636891,\n",
      "              \"load_duration\": 8871963,\n",
      "              \"prompt_eval_count\": 146,\n",
      "              \"prompt_eval_duration\": 2000000,\n",
      "              \"eval_count\": 9,\n",
      "              \"eval_duration\": 47000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-95d283fa-2796-4699-a4e9-b8a43e164ef6-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"datasource\": \"vectorstore\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [62ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"datasource\": \"vectorstore\"\n",
      "}\n",
      "{'datasource': 'vectorstore'}\n"
     ]
    }
   ],
   "source": [
    "### Router\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are an expert at routing a \n",
    "    user question to a vectorstore or web search. Use the vectorstore for questions on LLM  agents, \n",
    "    prompt engineering, and adversarial attacks. You do not need to be stringent with the keywords \n",
    "    in the question related to these topics. Otherwise, use web-search. Give a binary choice 'web_search' \n",
    "    or 'vectorstore' based on the question. Return the a JSON with a single key 'datasource' and \n",
    "    no premable or explaination. \n",
    "    \n",
    "    Question to route: \n",
    "    {question}\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "question_router = prompt | llm | JsonOutputParser()\n",
    "question = \"llm agent memory\"\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(question_router.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "023ff2db-eb4e-4d44-904c-ea061abc16d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Search\n",
    "import os\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"tvly-key\"\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "web_search_tool = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd59cdf-a04d-4b2e-b9cc-6a1b1e80a6c6",
   "metadata": {},
   "source": [
    "We'll implement these as a control flow in LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07fa3d08-6a86-4705-a28b-e2721070bc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7393df72b470>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "\n",
    "### State\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        web_search: whether to add search\n",
    "        documents: list of documents \n",
    "    \"\"\"\n",
    "    question : str\n",
    "    generation : str\n",
    "    web_search : str\n",
    "    documents : List[str]\n",
    "\n",
    "from langchain.schema import Document\n",
    "\n",
    "### Nodes\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents from vectorstore\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer using RAG on retrieved documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question\n",
    "    If any document is not relevant, we will set a flag to run web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Filtered out irrelevant documents and updated web_search state\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    # documents = state[\"documents\"]\n",
    "    documents = state.get(\"documents\", [])\n",
    "    \n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    web_search = \"No\"\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke({\"question\": question, \"document\": d.page_content})\n",
    "        grade = score['score']\n",
    "        # Document relevant\n",
    "        if grade.lower() == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        # Document not relevant\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            # We do not include the document in filtered_docs\n",
    "            # We set a flag to indicate that we want to run web search\n",
    "            web_search = \"Yes\"\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}\n",
    "    \n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based based on the question\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Appended web results to documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "    # documents = state[\"documents\"]\n",
    "    documents = state.get(\"documents\", [])  # Use .get() to avoid KeyError\n",
    "\n",
    "    # Web search\n",
    "    docs = web_search_tool.invoke({\"query\": question})\n",
    "    \n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    \n",
    "    '''\n",
    "    # Ensure each entry is a dictionary with a \"content\" key\n",
    "    web_results = []\n",
    "    for d in docs:\n",
    "        if isinstance(d, dict) and \"content\" in d:\n",
    "            web_results.append(d[\"content\"])\n",
    "        elif isinstance(d, str):\n",
    "            web_results.append(d)\n",
    "        else:\n",
    "            print(f\"Unexpected format: {d}\")\n",
    "\n",
    "    # Join results into a single document\n",
    "    combined_results = \"\\n\".join(web_results)\n",
    "    web_results_doc = Document(page_content=combined_results)\n",
    "    '''\n",
    "    \n",
    "    if documents is not None:\n",
    "        documents.append(web_results)\n",
    "    else:\n",
    "        documents = [web_results]\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "### Conditional edge\n",
    "\n",
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    Route question to web search or RAG.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ROUTE QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    print(question)\n",
    "    source = question_router.invoke({\"question\": question})  \n",
    "    print(source)\n",
    "    print(source['datasource'])\n",
    "    if source['datasource'] == 'web_search':\n",
    "        print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
    "        return \"websearch\"\n",
    "    elif source['datasource'] == 'vectorstore':\n",
    "        print(\"---ROUTE QUESTION TO RAG---\")\n",
    "        return \"vectorstore\"\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or add web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    question = state[\"question\"]\n",
    "    web_search = state[\"web_search\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\")\n",
    "        return \"websearch\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\"\n",
    "\n",
    "### Conditional edge\n",
    "\n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    score = hallucination_grader.invoke({\"documents\": documents, \"generation\": generation})\n",
    "    grade = score['score']\n",
    "\n",
    "    # Check hallucination\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        # Check question-answering\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "        score = answer_grader.invoke({\"question\": question,\"generation\": generation})\n",
    "        grade = score['score']\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\"\n",
    "\n",
    "from langgraph.graph import END, StateGraph\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"websearch\", web_search) # web search\n",
    "workflow.add_node(\"retrieve\", retrieve) # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents) # grade documents\n",
    "workflow.add_node(\"generate\", generate) # generate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f21594-00d4-48a8-ae2e-4e55a010b540",
   "metadata": {},
   "source": [
    "### Graph Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9a4b9e4-3ba8-47d6-958c-e5a7112ac6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7393df72b470>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build graph\n",
    "workflow.set_conditional_entry_point(\n",
    "    route_question,\n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"vectorstore\": \"retrieve\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"websearch\", \"generate\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",\n",
    "        \"useful\": END,\n",
    "        \"not useful\": \"websearch\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ef95592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "669b25f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13043b0f-17c7-49d3-9ea7-8f2c0f0c8691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:ChannelWrite<question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:ChannelWrite<question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\"\n",
      "}\n",
      "---ROUTE QUESTION---\n",
      "What are the types of agent memory?\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an expert at routing a \\n    user question to a vectorstore or web search. Use the vectorstore for questions on LLM  agents, \\n    prompt engineering, and adversarial attacks. You do not need to be stringent with the keywords \\n    in the question related to these topics. Otherwise, use web-search. Give a binary choice 'web_search' \\n    or 'vectorstore' based on the question. Return the a JSON with a single key 'datasource' and \\n    no premable or explaination. \\n    \\n    Question to route: \\n    What are the types of agent memory?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > llm:ChatOllama] [56ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"datasource\\\": \\\"vectorstore\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:23.099544468Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 54768305,\n",
      "          \"load_duration\": 9029003,\n",
      "          \"prompt_eval_count\": 150,\n",
      "          \"prompt_eval_duration\": 3000000,\n",
      "          \"eval_count\": 9,\n",
      "          \"eval_duration\": 41000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"datasource\\\": \\\"vectorstore\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:23.099544468Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 54768305,\n",
      "              \"load_duration\": 9029003,\n",
      "              \"prompt_eval_count\": 150,\n",
      "              \"prompt_eval_duration\": 3000000,\n",
      "              \"eval_count\": 9,\n",
      "              \"eval_duration\": 41000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-ee8a874f-e55a-4acd-bcc4-47c2f8928d3b-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"datasource\": \"vectorstore\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence] [57ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"datasource\": \"vectorstore\"\n",
      "}\n",
      "{'datasource': 'vectorstore'}\n",
      "vectorstore\n",
      "---ROUTE QUESTION TO RAG---\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question] [57ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"vectorstore\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] [58ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:retrieve] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\"\n",
      "}\n",
      "---RETRIEVE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:retrieve > chain:ChannelWrite<retrieve,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:retrieve > chain:ChannelWrite<retrieve,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:retrieve] [6ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: retrieve:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"document\": \"Each element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"document\": \"Each element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing relevance \\n    of a retrieved document to a user question. If the document contains keywords related to the user question, \\n    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n    \\n    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\\n    Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\\n     \\n    Here is the retrieved document: \\n    Each element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n    \\n    Here is the user question: \\n    What are the types of agent memory?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > llm:ChatOllama] [59ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:23.165861638Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 57975003,\n",
      "          \"load_duration\": 8949364,\n",
      "          \"prompt_eval_count\": 337,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 44000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:23.165861638Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 57975003,\n",
      "              \"load_duration\": 8949364,\n",
      "              \"prompt_eval_count\": 337,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 44000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-8c5b882d-78b8-493a-9e31-d1d27931f299-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence] [60ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"document\": \"Each element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"document\": \"Each element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing relevance \\n    of a retrieved document to a user question. If the document contains keywords related to the user question, \\n    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n    \\n    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\\n    Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\\n     \\n    Here is the retrieved document: \\n    Each element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n    \\n    Here is the user question: \\n    What are the types of agent memory?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > llm:ChatOllama] [51ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:23.217464564Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 49511021,\n",
      "          \"load_duration\": 15082933,\n",
      "          \"prompt_eval_count\": 337,\n",
      "          \"prompt_eval_duration\": 1000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 32000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:23.217464564Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 49511021,\n",
      "              \"load_duration\": 15082933,\n",
      "              \"prompt_eval_count\": 337,\n",
      "              \"prompt_eval_duration\": 1000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 32000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-ccaa768a-da97-4974-8bdf-0115f3cca402-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence] [51ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"document\": \"Each element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"document\": \"Each element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing relevance \\n    of a retrieved document to a user question. If the document contains keywords related to the user question, \\n    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n    \\n    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\\n    Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\\n     \\n    Here is the retrieved document: \\n    Each element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n    \\n    Here is the user question: \\n    What are the types of agent memory?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > llm:ChatOllama] [45ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:23.263117878Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 43728248,\n",
      "          \"load_duration\": 9256964,\n",
      "          \"prompt_eval_count\": 337,\n",
      "          \"prompt_eval_duration\": 1000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 32000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:23.263117878Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 43728248,\n",
      "              \"load_duration\": 9256964,\n",
      "              \"prompt_eval_count\": 337,\n",
      "              \"prompt_eval_duration\": 1000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 32000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-fe06ad6c-4a4c-4107-b893-926904f8100c-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence] [46ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"document\": \"Each element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"document\": \"Each element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing relevance \\n    of a retrieved document to a user question. If the document contains keywords related to the user question, \\n    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n    \\n    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\\n    Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\\n     \\n    Here is the retrieved document: \\n    Each element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n    \\n    Here is the user question: \\n    What are the types of agent memory?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > llm:ChatOllama] [46ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:23.309762988Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 44666438,\n",
      "          \"load_duration\": 9513628,\n",
      "          \"prompt_eval_count\": 337,\n",
      "          \"prompt_eval_duration\": 2000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 32000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:23.309762988Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 44666438,\n",
      "              \"load_duration\": 9513628,\n",
      "              \"prompt_eval_count\": 337,\n",
      "              \"prompt_eval_duration\": 2000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 32000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-2cf061e7-4c3b-4a2b-a108-65516d8a5b33-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:RunnableSequence] [47ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:ChannelWrite<grade_documents,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"documents\": [],\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"web_search\": \"Yes\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:ChannelWrite<grade_documents,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"documents\": [],\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"web_search\": \"Yes\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:decide_to_generate] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"documents\": [],\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"web_search\": \"Yes\"\n",
      "}\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents > chain:decide_to_generate] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"websearch\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:grade_documents] [204ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"documents\": [],\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"web_search\": \"Yes\"\n",
      "}\n",
      "'Finished running: grade_documents:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"web_search\": \"Yes\",\n",
      "  \"documents\": []\n",
      "}\n",
      "---WEB SEARCH---\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch > tool:tavily_search_results_json] Entering Tool run with input:\n",
      "\u001b[0m\"{'query': 'What are the types of agent memory?'}\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch > tool:tavily_search_results_json] [2.43s] Exiting Tool run with output:\n",
      "\u001b[0m\"[{'url': 'https://dev.to/akkiprime/towards-agi-part-1-agents-with-memory-4cp5', 'content': 'Deep dive into various types of Agent Memory STM: Working memory (LLM Context): It is a data structure with multiple parts which are usually represented with a prompt template and relevant variables.Before runtime, the STM is synthesized by replacing the relevant variables in the prompt template with information retrieved from the LTM.'}, {'url': 'https://blog.langchain.dev/memory-for-agents/', 'content': 'Memory for agents Memory for agents At Sequoia’s AI Ascent conference in March, I talked about three limitations for agents: planning, UX, and memory. But what even is memory? While the exact shape of memory that your agent has may differ by application, we do see different high level types of memory. Below is my rough, ELI5 explanation of each type and practical ways for how todays agents may use and update this memory type. Besides just thinking about the type of memory to update in their agents, we also see developers thinking about how to update agent memory. One way to update agent memory is “in the hot path”. Why do we care about memory for agents?'}, {'url': 'https://www.getfrontline.ai/glossary/what-is-ai-agent-memory', 'content': 'It includes short-term memory via context windows and long-term memory through methods like Retrieval-Augmented Generation (RAG), enabling more coherent and informed AI responses. Long-term memory in AI agents aims to address the limitations of short-term memory by providing a mechanism for storing and retrieving information over extended periods. Expanded Knowledge: RAG allows the AI to access a much larger pool of information than what could be included in a context window or model parameters. The interplay between short-term memory (context window) and long-term memory (RAG) is crucial for creating AI agents with more human-like memory capabilities. In conclusion, AI Agent Memory, encompassing both short-term memory via context windows and long-term memory through techniques like RAG, is a critical component in the development of more capable and human-like AI systems.'}, {'url': 'https://www.geeksforgeeks.org/types-of-agents-in-ai/', 'content': 'Types of Agents in AI, agents are the entities that perceive their environment and take actions to achieve specific goals. These agents exhibit diverse behaviours and capabilities, ranging from simple reactive responses to sophisticated decision-making. ... Limited Memory: They typically have limited memory capacity and do not retain'}, {'url': 'https://superagi.com/towards-agi-part-1/', 'content': 'Sign up for Latest SuperAGI Updates\\n\"*\" indicates required fields\\nSuperAGI builds infrastructure components, tools, frameworks and models to enable opensource AGI\\ncommunity@superagi.com\\nFor Developers\\nDocs\\nGitHub\\nReleases\\nRoadmap\\nAPIs\\nCommunity\\nSupport Forum\\nMarketplace\\nSocial Mentions\\nReddit\\nCollectibles\\nResources\\nBlog\\nUse Cases\\nAGI Research Lab\\nTutorials\\nImportant Links\\nSuperAGI Cloud\\nApp Spotlight\\nSuperCoder\\nArchitecture\\n Check it out✨\\nFeatures\\nAction Console\\nResource Manager\\nTrajectory Fine-Tuning\\n\\u200c\\nMultiple Vector DBs\\nMulti-LLM Support\\nAgent Workflows\\nMarketplace\\nAgent Templates\\nDiscord\\nGitHub\\nTwitter\\nReddit\\nYoutube\\nTowards AGI (part 1): Agents with Memory\\nFebruary 6, 2024\\n7 mins read\\nAgents are an emerging class of artificial intelligence (AI) systems that use large language models (LLMs) to interact with the world. In a professional setup like this, the agent is responsible for extracting tasks from conversations and passing them to an employee and once the employee completes the task the agent will convey the output to the user. Then use the solutions of those basic tasks as in-context examples to solve the current task.\\nConclusion & Next Steps\\nIn this blog, we saw that design choices for Memory depend on the end use case. This analogy is better captured in the following table:\\nDeep dive into various types of Agent Memory\\nChoosing the right Memory design in Production\\nSince agents are powered by LLMs, they are inherently probabilistic.'}]\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch > chain:ChannelWrite<websearch,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch > chain:ChannelWrite<websearch,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch] [2.43s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: websearch:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: What are the types of agent memory? \\n    Context: [Document(metadata={}, page_content='Deep dive into various types of Agent Memory STM: Working memory (LLM Context): It is a data structure with multiple parts which are usually represented with a prompt template and relevant variables.Before runtime, the STM is synthesized by replacing the relevant variables in the prompt template with information retrieved from the LTM.\\\\nMemory for agents Memory for agents At Sequoia’s AI Ascent conference in March, I talked about three limitations for agents: planning, UX, and memory. But what even is memory? While the exact shape of memory that your agent has may differ by application, we do see different high level types of memory. Below is my rough, ELI5 explanation of each type and practical ways for how todays agents may use and update this memory type. Besides just thinking about the type of memory to update in their agents, we also see developers thinking about how to update agent memory. One way to update agent memory is “in the hot path”. Why do we care about memory for agents?\\\\nIt includes short-term memory via context windows and long-term memory through methods like Retrieval-Augmented Generation (RAG), enabling more coherent and informed AI responses. Long-term memory in AI agents aims to address the limitations of short-term memory by providing a mechanism for storing and retrieving information over extended periods. Expanded Knowledge: RAG allows the AI to access a much larger pool of information than what could be included in a context window or model parameters. The interplay between short-term memory (context window) and long-term memory (RAG) is crucial for creating AI agents with more human-like memory capabilities. In conclusion, AI Agent Memory, encompassing both short-term memory via context windows and long-term memory through techniques like RAG, is a critical component in the development of more capable and human-like AI systems.\\\\nTypes of Agents in AI, agents are the entities that perceive their environment and take actions to achieve specific goals. These agents exhibit diverse behaviours and capabilities, ranging from simple reactive responses to sophisticated decision-making. ... Limited Memory: They typically have limited memory capacity and do not retain\\\\nSign up for Latest SuperAGI Updates\\\\n\\\"*\\\" indicates required fields\\\\nSuperAGI builds infrastructure components, tools, frameworks and models to enable opensource AGI\\\\ncommunity@superagi.com\\\\nFor Developers\\\\nDocs\\\\nGitHub\\\\nReleases\\\\nRoadmap\\\\nAPIs\\\\nCommunity\\\\nSupport Forum\\\\nMarketplace\\\\nSocial Mentions\\\\nReddit\\\\nCollectibles\\\\nResources\\\\nBlog\\\\nUse Cases\\\\nAGI Research Lab\\\\nTutorials\\\\nImportant Links\\\\nSuperAGI Cloud\\\\nApp Spotlight\\\\nSuperCoder\\\\nArchitecture\\\\n Check it out✨\\\\nFeatures\\\\nAction Console\\\\nResource Manager\\\\nTrajectory Fine-Tuning\\\\n\\\\u200c\\\\nMultiple Vector DBs\\\\nMulti-LLM Support\\\\nAgent Workflows\\\\nMarketplace\\\\nAgent Templates\\\\nDiscord\\\\nGitHub\\\\nTwitter\\\\nReddit\\\\nYoutube\\\\nTowards AGI (part 1): Agents with Memory\\\\nFebruary 6, 2024\\\\n7 mins read\\\\nAgents are an emerging class of artificial intelligence (AI) systems that use large language models (LLMs) to interact with the world. In a professional setup like this, the agent is responsible for extracting tasks from conversations and passing them to an employee and once the employee completes the task the agent will convey the output to the user. Then use the solutions of those basic tasks as in-context examples to solve the current task.\\\\nConclusion & Next Steps\\\\nIn this blog, we saw that design choices for Memory depend on the end use case. This analogy is better captured in the following table:\\\\nDeep dive into various types of Agent Memory\\\\nChoosing the right Memory design in Production\\\\nSince agents are powered by LLMs, they are inherently probabilistic.')] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [483ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Here are three concise sentences:\\n\\nThe two main types of agent memory mentioned in the context are short-term memory (via context windows) and long-term memory (through methods like Retrieval-Augmented Generation (RAG)). Long-term memory aims to address the limitations of short-term memory by providing a mechanism for storing and retrieving information over extended periods. There is also limited memory, which typically has a small capacity and does not retain information.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:26.223839217Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 481618289,\n",
      "          \"load_duration\": 9098631,\n",
      "          \"prompt_eval_count\": 863,\n",
      "          \"prompt_eval_duration\": 31000000,\n",
      "          \"eval_count\": 87,\n",
      "          \"eval_duration\": 440000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Here are three concise sentences:\\n\\nThe two main types of agent memory mentioned in the context are short-term memory (via context windows) and long-term memory (through methods like Retrieval-Augmented Generation (RAG)). Long-term memory aims to address the limitations of short-term memory by providing a mechanism for storing and retrieving information over extended periods. There is also limited memory, which typically has a small capacity and does not retain information.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:26.223839217Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 481618289,\n",
      "              \"load_duration\": 9098631,\n",
      "              \"prompt_eval_count\": 863,\n",
      "              \"prompt_eval_duration\": 31000000,\n",
      "              \"eval_count\": 87,\n",
      "              \"eval_duration\": 440000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-e86c3b58-8c53-4cf6-be42-996035ff7a28-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Here are three concise sentences:\\n\\nThe two main types of agent memory mentioned in the context are short-term memory (via context windows) and long-term memory (through methods like Retrieval-Augmented Generation (RAG)). Long-term memory aims to address the limitations of short-term memory by providing a mechanism for storing and retrieving information over extended periods. There is also limited memory, which typically has a small capacity and does not retain information.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [484ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Here are three concise sentences:\\n\\nThe two main types of agent memory mentioned in the context are short-term memory (via context windows) and long-term memory (through methods like Retrieval-Augmented Generation (RAG)). Long-term memory aims to address the limitations of short-term memory by providing a mechanism for storing and retrieving information over extended periods. There is also limited memory, which typically has a small capacity and does not retain information.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content='Deep dive into various types of Agent Memory STM: Working memory (LLM Context): It is a data structure with multiple parts which are usually represented with a prompt template and relevant variables.Before runtime, the STM is synthesized by replacing the relevant variables in the prompt template with information retrieved from the LTM.\\\\nMemory for agents Memory for agents At Sequoia’s AI Ascent conference in March, I talked about three limitations for agents: planning, UX, and memory. But what even is memory? While the exact shape of memory that your agent has may differ by application, we do see different high level types of memory. Below is my rough, ELI5 explanation of each type and practical ways for how todays agents may use and update this memory type. Besides just thinking about the type of memory to update in their agents, we also see developers thinking about how to update agent memory. One way to update agent memory is “in the hot path”. Why do we care about memory for agents?\\\\nIt includes short-term memory via context windows and long-term memory through methods like Retrieval-Augmented Generation (RAG), enabling more coherent and informed AI responses. Long-term memory in AI agents aims to address the limitations of short-term memory by providing a mechanism for storing and retrieving information over extended periods. Expanded Knowledge: RAG allows the AI to access a much larger pool of information than what could be included in a context window or model parameters. The interplay between short-term memory (context window) and long-term memory (RAG) is crucial for creating AI agents with more human-like memory capabilities. In conclusion, AI Agent Memory, encompassing both short-term memory via context windows and long-term memory through techniques like RAG, is a critical component in the development of more capable and human-like AI systems.\\\\nTypes of Agents in AI, agents are the entities that perceive their environment and take actions to achieve specific goals. These agents exhibit diverse behaviours and capabilities, ranging from simple reactive responses to sophisticated decision-making. ... Limited Memory: They typically have limited memory capacity and do not retain\\\\nSign up for Latest SuperAGI Updates\\\\n\\\"*\\\" indicates required fields\\\\nSuperAGI builds infrastructure components, tools, frameworks and models to enable opensource AGI\\\\ncommunity@superagi.com\\\\nFor Developers\\\\nDocs\\\\nGitHub\\\\nReleases\\\\nRoadmap\\\\nAPIs\\\\nCommunity\\\\nSupport Forum\\\\nMarketplace\\\\nSocial Mentions\\\\nReddit\\\\nCollectibles\\\\nResources\\\\nBlog\\\\nUse Cases\\\\nAGI Research Lab\\\\nTutorials\\\\nImportant Links\\\\nSuperAGI Cloud\\\\nApp Spotlight\\\\nSuperCoder\\\\nArchitecture\\\\n Check it out✨\\\\nFeatures\\\\nAction Console\\\\nResource Manager\\\\nTrajectory Fine-Tuning\\\\n\\\\u200c\\\\nMultiple Vector DBs\\\\nMulti-LLM Support\\\\nAgent Workflows\\\\nMarketplace\\\\nAgent Templates\\\\nDiscord\\\\nGitHub\\\\nTwitter\\\\nReddit\\\\nYoutube\\\\nTowards AGI (part 1): Agents with Memory\\\\nFebruary 6, 2024\\\\n7 mins read\\\\nAgents are an emerging class of artificial intelligence (AI) systems that use large language models (LLMs) to interact with the world. In a professional setup like this, the agent is responsible for extracting tasks from conversations and passing them to an employee and once the employee completes the task the agent will convey the output to the user. Then use the solutions of those basic tasks as in-context examples to solve the current task.\\\\nConclusion & Next Steps\\\\nIn this blog, we saw that design choices for Memory depend on the end use case. This analogy is better captured in the following table:\\\\nDeep dive into various types of Agent Memory\\\\nChoosing the right Memory design in Production\\\\nSince agents are powered by LLMs, they are inherently probabilistic.')] \\n\\n    Here is the answer: \\n    Here are three concise sentences:\\n\\nThe two main types of agent memory mentioned in the context are short-term memory (via context windows) and long-term memory (through methods like Retrieval-Augmented Generation (RAG)). Long-term memory aims to address the limitations of short-term memory by providing a mechanism for storing and retrieving information over extended periods. There is also limited memory, which typically has a small capacity and does not retain information.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [93ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:26.318021136Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 91869682,\n",
      "          \"load_duration\": 9043342,\n",
      "          \"prompt_eval_count\": 967,\n",
      "          \"prompt_eval_duration\": 31000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 51000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:26.318021136Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 91869682,\n",
      "              \"load_duration\": 9043342,\n",
      "              \"prompt_eval_count\": 967,\n",
      "              \"prompt_eval_duration\": 31000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 51000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-b4745f5b-1bbe-47a4-94c5-83d9b5785225-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [94ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"generation\": \"Here are three concise sentences:\\n\\nThe two main types of agent memory mentioned in the context are short-term memory (via context windows) and long-term memory (through methods like Retrieval-Augmented Generation (RAG)). Long-term memory aims to address the limitations of short-term memory by providing a mechanism for storing and retrieving information over extended periods. There is also limited memory, which typically has a small capacity and does not retain information.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the types of agent memory?\",\n",
      "  \"generation\": \"Here are three concise sentences:\\n\\nThe two main types of agent memory mentioned in the context are short-term memory (via context windows) and long-term memory (through methods like Retrieval-Augmented Generation (RAG)). Long-term memory aims to address the limitations of short-term memory by providing a mechanism for storing and retrieving information over extended periods. There is also limited memory, which typically has a small capacity and does not retain information.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether an \\n    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is \\n    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\\n     \\n    Here is the answer:\\n    Here are three concise sentences:\\n\\nThe two main types of agent memory mentioned in the context are short-term memory (via context windows) and long-term memory (through methods like Retrieval-Augmented Generation (RAG)). Long-term memory aims to address the limitations of short-term memory by providing a mechanism for storing and retrieving information over extended periods. There is also limited memory, which typically has a small capacity and does not retain information. \\n\\n    Here is the question: What are the types of agent memory?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [53ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:26.372238693Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 52187907,\n",
      "          \"load_duration\": 9141610,\n",
      "          \"prompt_eval_count\": 197,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 37000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:26.372238693Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 52187907,\n",
      "              \"load_duration\": 9141610,\n",
      "              \"prompt_eval_count\": 197,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 37000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-c4c45158-3c23-43f3-996d-014ce9a9eafb-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [54ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [148ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"useful\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [633ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph] [3.33s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "('Here are three concise sentences:\\n'\n",
      " '\\n'\n",
      " 'The two main types of agent memory mentioned in the context are short-term '\n",
      " 'memory (via context windows) and long-term memory (through methods like '\n",
      " 'Retrieval-Augmented Generation (RAG)). Long-term memory aims to address the '\n",
      " 'limitations of short-term memory by providing a mechanism for storing and '\n",
      " 'retrieving information over extended periods. There is also limited memory, '\n",
      " 'which typically has a small capacity and does not retain information.')\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "from pprint import pprint\n",
    "inputs = {\"question\": \"What are the types of agent memory?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d733ab80-7e7b-4b1a-9519-9242de647eda",
   "metadata": {},
   "source": [
    "Trace: \n",
    "\n",
    "https://smith.langchain.com/public/8d449b67-6bc4-4ecf-9153-759cd21df24f/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbfcec3e-a09a-40b4-9c15-fead97bf4e0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Who are the Bears expected to draft first in the NFL draft?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Who are the Bears expected to draft first in the NFL draft?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:ChannelWrite<question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Who are the Bears expected to draft first in the NFL draft?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:ChannelWrite<question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Who are the Bears expected to draft first in the NFL draft?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Who are the Bears expected to draft first in the NFL draft?\"\n",
      "}\n",
      "---ROUTE QUESTION---\n",
      "Who are the Bears expected to draft first in the NFL draft?\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Who are the Bears expected to draft first in the NFL draft?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Who are the Bears expected to draft first in the NFL draft?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an expert at routing a \\n    user question to a vectorstore or web search. Use the vectorstore for questions on LLM  agents, \\n    prompt engineering, and adversarial attacks. You do not need to be stringent with the keywords \\n    in the question related to these topics. Otherwise, use web-search. Give a binary choice 'web_search' \\n    or 'vectorstore' based on the question. Return the a JSON with a single key 'datasource' and \\n    no premable or explaination. \\n    \\n    Question to route: \\n    Who are the Bears expected to draft first in the NFL draft?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > llm:ChatOllama] [76ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\n  \\\"datasource\\\": \\\"web_search\\\"\\n}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:26.45364116Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 74161968,\n",
      "          \"load_duration\": 8968734,\n",
      "          \"prompt_eval_count\": 155,\n",
      "          \"prompt_eval_duration\": 2000000,\n",
      "          \"eval_count\": 12,\n",
      "          \"eval_duration\": 62000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\n  \\\"datasource\\\": \\\"web_search\\\"\\n}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:26.45364116Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 74161968,\n",
      "              \"load_duration\": 8968734,\n",
      "              \"prompt_eval_count\": 155,\n",
      "              \"prompt_eval_duration\": 2000000,\n",
      "              \"eval_count\": 12,\n",
      "              \"eval_duration\": 62000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-4c384b20-4b57-4446-bab1-dda9c1d215f6-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"datasource\": \"web_search\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence] [76ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"datasource\": \"web_search\"\n",
      "}\n",
      "{'datasource': 'web_search'}\n",
      "web_search\n",
      "---ROUTE QUESTION TO WEB SEARCH---\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question] [77ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"websearch\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] [77ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Who are the Bears expected to draft first in the NFL draft?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Who are the Bears expected to draft first in the NFL draft?\"\n",
      "}\n",
      "---WEB SEARCH---\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch > tool:tavily_search_results_json] Entering Tool run with input:\n",
      "\u001b[0m\"{'query': 'Who are the Bears expected to draft first in the NFL draft?'}\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch > tool:tavily_search_results_json] [2.67s] Exiting Tool run with output:\n",
      "\u001b[0m\"[{'url': 'https://www.usatoday.com/story/sports/nfl/draft/2024/04/17/2024-nfl-draft-first-overall-pick-chicago-bears/73345778007/', 'content': 'The 2024 NFL draft will begin with the first round on Thursday, April 25 (8 p.m. ET). ... The Bears are expected to draft USC star and 2022 Heisman Trophy winner Caleb Williams first overall.'}, {'url': 'https://www.chicagobears.com/news/2024-chicago-bears-nfl-draft-picks-news-photos-highlights', 'content': 'The Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.'}, {'url': 'https://www.nytimes.com/athletic/5373530/2024/04/24/chicago-bears-2024-nfl-draft-picks-needs-predictions-guide/', 'content': 'The Chicago Bears have the first and ninth picks in the NFL Draft when Round 1 begins April 25 in Detroit. The Bears own only four total picks in the seven-round draft , the last coming in the'}, {'url': 'https://bearswire.usatoday.com/story/sports/nfl/bears/2024/04/25/chicago-bears-2024-nfl-draft-first-round-predictions-caleb-williams/75843645007/', 'content': \"The 2024 NFL draft is here, and the Chicago Bears have a pair of first-round selections, including the first pick in the draft.. There's little surprise what the Bears are going to do with the\"}, {'url': 'https://beargoggleson.com/posts/bears-draft-picks-future-list-01hq8tx3pc6a', 'content': \"Round\\nPick\\n1\\n1\\n1\\n9\\n3\\n75\\n4\\n111\\n4\\n123\\n5\\n143\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\n Bears draft picks in 2025\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\n QB Kyler Murray (ARI)\\n2018: QB Baker Mayfield (CLE)\\n2017: QB Myles Garrett (CLE)\\n2016: QB Jared Goff (LAR)\\n2015: QB Jameis Winston (TB)\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\n\"}]\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch > chain:ChannelWrite<websearch,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch > chain:ChannelWrite<websearch,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch] [2.67s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: websearch:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Who are the Bears expected to draft first in the NFL draft? \\n    Context: [Document(metadata={}, page_content=\\\"The 2024 NFL draft will begin with the first round on Thursday, April 25 (8 p.m. ET). ... The Bears are expected to draft USC star and 2022 Heisman Trophy winner Caleb Williams first overall.\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\\nThe Chicago Bears have the first and ninth picks in the NFL Draft when Round 1 begins April 25 in Detroit. The Bears own only four total picks in the seven-round draft , the last coming in the\\\\nThe 2024 NFL draft is here, and the Chicago Bears have a pair of first-round selections, including the first pick in the draft.. There's little surprise what the Bears are going to do with the\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [325ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Caleb Williams is expected to be drafted first by the Chicago Bears in the 2024 NFL draft. The Bears selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:29.453645221Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 324206164,\n",
      "          \"load_duration\": 9300093,\n",
      "          \"prompt_eval_count\": 513,\n",
      "          \"prompt_eval_duration\": 7000000,\n",
      "          \"eval_count\": 60,\n",
      "          \"eval_duration\": 306000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Caleb Williams is expected to be drafted first by the Chicago Bears in the 2024 NFL draft. The Bears selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:29.453645221Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 324206164,\n",
      "              \"load_duration\": 9300093,\n",
      "              \"prompt_eval_count\": 513,\n",
      "              \"prompt_eval_duration\": 7000000,\n",
      "              \"eval_count\": 60,\n",
      "              \"eval_duration\": 306000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-bbc5f12a-72b5-46cb-aaf0-48b92d748ed7-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Caleb Williams is expected to be drafted first by the Chicago Bears in the 2024 NFL draft. The Bears selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [326ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Caleb Williams is expected to be drafted first by the Chicago Bears in the 2024 NFL draft. The Bears selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"The 2024 NFL draft will begin with the first round on Thursday, April 25 (8 p.m. ET). ... The Bears are expected to draft USC star and 2022 Heisman Trophy winner Caleb Williams first overall.\\\\nThe Bears on Thursday, as expected, selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\\\\nThe Chicago Bears have the first and ninth picks in the NFL Draft when Round 1 begins April 25 in Detroit. The Bears own only four total picks in the seven-round draft , the last coming in the\\\\nThe 2024 NFL draft is here, and the Chicago Bears have a pair of first-round selections, including the first pick in the draft.. There's little surprise what the Bears are going to do with the\\\\nRound\\\\nPick\\\\n1\\\\n1\\\\n1\\\\n9\\\\n3\\\\n75\\\\n4\\\\n111\\\\n4\\\\n123\\\\n5\\\\n143\\\\nThe extra first-round pick comes by way of Carolina, who would have otherwise had the first overall selection.\\\\n Bears draft picks in 2025\\\\nThe only change in 2025 picks is the Chase Claypool trade, which sent Miami a seventh-rounder along with the wide receiver for a sixth-round pick from the Dolphins.\\\\n Bears draft picks in 2024, 2025 & Beyond: Full list\\\\nWelcome to the 2024 offseason; the offseason where Ryan Poles and the Chicago Bears own all of the power.\\\\n QB Kyler Murray (ARI)\\\\n2018: QB Baker Mayfield (CLE)\\\\n2017: QB Myles Garrett (CLE)\\\\n2016: QB Jared Goff (LAR)\\\\n2015: QB Jameis Winston (TB)\\\\n The Bears not only own the no. 1 overall pick in the 2024 NFL Draft, but also have the league's third-highest amount of cap space.\\\\n\\\")] \\n\\n    Here is the answer: \\n    Caleb Williams is expected to be drafted first by the Chicago Bears in the 2024 NFL draft. The Bears selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [77ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:29.531532422Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 75431031,\n",
      "          \"load_duration\": 10701010,\n",
      "          \"prompt_eval_count\": 584,\n",
      "          \"prompt_eval_duration\": 28000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 36000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:29.531532422Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 75431031,\n",
      "              \"load_duration\": 10701010,\n",
      "              \"prompt_eval_count\": 584,\n",
      "              \"prompt_eval_duration\": 28000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 36000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-5f2c75f1-d1b1-410c-bf0b-dcf823456fb8-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [77ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Who are the Bears expected to draft first in the NFL draft?\",\n",
      "  \"generation\": \"Caleb Williams is expected to be drafted first by the Chicago Bears in the 2024 NFL draft. The Bears selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Who are the Bears expected to draft first in the NFL draft?\",\n",
      "  \"generation\": \"Caleb Williams is expected to be drafted first by the Chicago Bears in the 2024 NFL draft. The Bears selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether an \\n    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is \\n    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\\n     \\n    Here is the answer:\\n    Caleb Williams is expected to be drafted first by the Chicago Bears in the 2024 NFL draft. The Bears selected USC quarterback Caleb Williams with the No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top prospect in a draft class loaded with talented quarterbacks. \\n\\n    Here is the question: Who are the Bears expected to draft first in the NFL draft?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [51ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:29.583751455Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 50374641,\n",
      "          \"load_duration\": 9119374,\n",
      "          \"prompt_eval_count\": 174,\n",
      "          \"prompt_eval_duration\": 2000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 38000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"yes\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:29.583751455Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 50374641,\n",
      "              \"load_duration\": 9119374,\n",
      "              \"prompt_eval_count\": 174,\n",
      "              \"prompt_eval_duration\": 2000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 38000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-0bb05b97-e797-483a-9a03-b42a885c4b48-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [52ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"yes\"\n",
      "}\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [130ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"useful\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [457ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph] [3.21s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "('Caleb Williams is expected to be drafted first by the Chicago Bears in the '\n",
      " '2024 NFL draft. The Bears selected USC quarterback Caleb Williams with the '\n",
      " 'No. 1 pick in the 2024 NFL Draft. Williams was widely considered the top '\n",
      " 'prospect in a draft class loaded with talented quarterbacks.')\n"
     ]
    }
   ],
   "source": [
    "# Compile\n",
    "app = workflow.compile()\n",
    "\n",
    "# Test\n",
    "from pprint import pprint\n",
    "inputs = {\"question\": \"Who are the Bears expected to draft first in the NFL draft?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9051bea-13fa-4eb3-b671-16f59755931d",
   "metadata": {},
   "source": [
    "Trace: \n",
    "\n",
    "https://smith.langchain.com/public/c785f9c0-f519-4a38-ad5a-febb59a2139c/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ac34852-3b21-477a-a576-45466722171b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Did Emmanuel Macron visit Germany recently?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Did Emmanuel Macron visit Germany recently?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:ChannelWrite<question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Did Emmanuel Macron visit Germany recently?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:ChannelWrite<question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Did Emmanuel Macron visit Germany recently?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Did Emmanuel Macron visit Germany recently?\"\n",
      "}\n",
      "---ROUTE QUESTION---\n",
      "Did Emmanuel Macron visit Germany recently?\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Did Emmanuel Macron visit Germany recently?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Did Emmanuel Macron visit Germany recently?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an expert at routing a \\n    user question to a vectorstore or web search. Use the vectorstore for questions on LLM  agents, \\n    prompt engineering, and adversarial attacks. You do not need to be stringent with the keywords \\n    in the question related to these topics. Otherwise, use web-search. Give a binary choice 'web_search' \\n    or 'vectorstore' based on the question. Return the a JSON with a single key 'datasource' and \\n    no premable or explaination. \\n    \\n    Question to route: \\n    Did Emmanuel Macron visit Germany recently?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > llm:ChatOllama] [77ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\n  \\\"datasource\\\": \\\"web_search\\\"\\n}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:29.666326082Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 74862738,\n",
      "          \"load_duration\": 9105755,\n",
      "          \"prompt_eval_count\": 149,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 12,\n",
      "          \"eval_duration\": 60000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\n  \\\"datasource\\\": \\\"web_search\\\"\\n}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:29.666326082Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 74862738,\n",
      "              \"load_duration\": 9105755,\n",
      "              \"prompt_eval_count\": 149,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 12,\n",
      "              \"eval_duration\": 60000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-675b612b-ceca-4aec-8909-191999b9f0c8-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"datasource\": \"web_search\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question > chain:RunnableSequence] [77ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"datasource\": \"web_search\"\n",
      "}\n",
      "{'datasource': 'web_search'}\n",
      "web_search\n",
      "---ROUTE QUESTION TO WEB SEARCH---\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__ > chain:route_question] [78ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"websearch\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] [78ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Did Emmanuel Macron visit Germany recently?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Did Emmanuel Macron visit Germany recently?\"\n",
      "}\n",
      "---WEB SEARCH---\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch > tool:tavily_search_results_json] Entering Tool run with input:\n",
      "\u001b[0m\"{'query': 'Did Emmanuel Macron visit Germany recently?'}\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch > tool:tavily_search_results_json] [2.44s] Exiting Tool run with output:\n",
      "\u001b[0m\"[{'url': 'https://www.straitstimes.com/world/europe/macron-heads-to-germany-in-first-french-presidential-state-visit-in-24-years', 'content': 'PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and'}, {'url': 'https://www.yahoo.com/news/french-president-macron-arrives-germany-134404014.html', 'content': 'Emmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco'}, {'url': 'https://apnews.com/article/germany-france-macron-state-visit-fc930bc6069fa21980de8e39972ade24', 'content': \"BERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\"}, {'url': 'https://www.reuters.com/world/europe/macron-heads-germany-first-french-presidential-state-visit-24-years-2024-05-26/', 'content': \"French President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\"}, {'url': 'https://www.lemonde.fr/en/international/article/2024/05/26/macron-begins-first-state-visit-to-germany-by-a-french-president-in-24-years_6672731_4.html', 'content': 'President Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the'}]\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch > chain:ChannelWrite<websearch,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch > chain:ChannelWrite<websearch,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:websearch] [2.44s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: websearch:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Did Emmanuel Macron visit Germany recently? \\n    Context: [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [270ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:32.375295947Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 268262299,\n",
      "          \"load_duration\": 9087192,\n",
      "          \"prompt_eval_count\": 328,\n",
      "          \"prompt_eval_duration\": 5000000,\n",
      "          \"eval_count\": 51,\n",
      "          \"eval_duration\": 253000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:32.375295947Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 268262299,\n",
      "              \"load_duration\": 9087192,\n",
      "              \"prompt_eval_count\": 328,\n",
      "              \"prompt_eval_duration\": 5000000,\n",
      "              \"eval_count\": 51,\n",
      "              \"eval_duration\": 253000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-ecff0a2f-46f6-4d1a-a789-f83ba7f1e06f-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [271ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n\\n    Here is the answer: \\n    Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [63ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:32.438942276Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 61356141,\n",
      "          \"load_duration\": 9186153,\n",
      "          \"prompt_eval_count\": 397,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 46000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:32.438942276Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 61356141,\n",
      "              \"load_duration\": 9186153,\n",
      "              \"prompt_eval_count\": 397,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 46000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-0803254a-bf57-45f0-9ee1-a7ae9b694c5e-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [64ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [64ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [335ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Did Emmanuel Macron visit Germany recently? \\n    Context: [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [272ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:32.71322877Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 270618214,\n",
      "          \"load_duration\": 14035890,\n",
      "          \"prompt_eval_count\": 328,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 51,\n",
      "          \"eval_duration\": 251000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:32.71322877Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 270618214,\n",
      "              \"load_duration\": 14035890,\n",
      "              \"prompt_eval_count\": 328,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 51,\n",
      "              \"eval_duration\": 251000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-5963bcd8-792b-42b2-b69f-d43be8114cd7-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [273ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n\\n    Here is the answer: \\n    Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [62ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:32.775962795Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 60224927,\n",
      "          \"load_duration\": 9200002,\n",
      "          \"prompt_eval_count\": 397,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 45000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:32.775962795Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 60224927,\n",
      "              \"load_duration\": 9200002,\n",
      "              \"prompt_eval_count\": 397,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 45000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-24db30a7-1a05-4521-afca-df243ccddca1-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [62ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [62ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [336ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Did Emmanuel Macron visit Germany recently? \\n    Context: [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [263ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:33.040149142Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 261974197,\n",
      "          \"load_duration\": 9620914,\n",
      "          \"prompt_eval_count\": 328,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 51,\n",
      "          \"eval_duration\": 247000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:33.040149142Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 261974197,\n",
      "              \"load_duration\": 9620914,\n",
      "              \"prompt_eval_count\": 328,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 51,\n",
      "              \"eval_duration\": 247000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-b43c3db3-35d1-4a3f-86ba-bdcf7d485736-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [264ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n\\n    Here is the answer: \\n    Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [69ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:33.110739447Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 67977285,\n",
      "          \"load_duration\": 16196796,\n",
      "          \"prompt_eval_count\": 397,\n",
      "          \"prompt_eval_duration\": 5000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 45000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:33.110739447Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 67977285,\n",
      "              \"load_duration\": 16196796,\n",
      "              \"prompt_eval_count\": 397,\n",
      "              \"prompt_eval_duration\": 5000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 45000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-25de3745-9f1f-4c23-932f-e8dd454ab33c-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [70ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [71ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [335ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Did Emmanuel Macron visit Germany recently? \\n    Context: [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [267ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:33.379351324Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 265329502,\n",
      "          \"load_duration\": 9154662,\n",
      "          \"prompt_eval_count\": 328,\n",
      "          \"prompt_eval_duration\": 5000000,\n",
      "          \"eval_count\": 51,\n",
      "          \"eval_duration\": 250000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:33.379351324Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 265329502,\n",
      "              \"load_duration\": 9154662,\n",
      "              \"prompt_eval_count\": 328,\n",
      "              \"prompt_eval_duration\": 5000000,\n",
      "              \"eval_count\": 51,\n",
      "              \"eval_duration\": 250000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-cef88314-c27d-4a7a-bd20-f408b3391afb-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [268ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n\\n    Here is the answer: \\n    Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [67ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:33.448044155Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 65253334,\n",
      "          \"load_duration\": 13169837,\n",
      "          \"prompt_eval_count\": 397,\n",
      "          \"prompt_eval_duration\": 6000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 45000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:33.448044155Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 65253334,\n",
      "              \"load_duration\": 13169837,\n",
      "              \"prompt_eval_count\": 397,\n",
      "              \"prompt_eval_duration\": 6000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 45000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-c0a4a574-9401-446b-b593-79dc70b0826e-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [68ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [68ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [337ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Did Emmanuel Macron visit Germany recently? \\n    Context: [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [264ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:33.713997989Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 263147998,\n",
      "          \"load_duration\": 9046459,\n",
      "          \"prompt_eval_count\": 328,\n",
      "          \"prompt_eval_duration\": 5000000,\n",
      "          \"eval_count\": 51,\n",
      "          \"eval_duration\": 248000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:33.713997989Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 263147998,\n",
      "              \"load_duration\": 9046459,\n",
      "              \"prompt_eval_count\": 328,\n",
      "              \"prompt_eval_duration\": 5000000,\n",
      "              \"eval_count\": 51,\n",
      "              \"eval_duration\": 248000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-c342e7b6-1806-437e-9164-720ea8145c16-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [265ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n\\n    Here is the answer: \\n    Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [61ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:33.77626995Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 59987350,\n",
      "          \"load_duration\": 9110424,\n",
      "          \"prompt_eval_count\": 397,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 45000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:33.77626995Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 59987350,\n",
      "              \"load_duration\": 9110424,\n",
      "              \"prompt_eval_count\": 397,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 45000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-dbc6a4dd-727a-45d8-9c27-78fb046774d5-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [62ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [62ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [328ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Did Emmanuel Macron visit Germany recently? \\n    Context: [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [269ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:34.046886172Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 268124593,\n",
      "          \"load_duration\": 9157318,\n",
      "          \"prompt_eval_count\": 328,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 51,\n",
      "          \"eval_duration\": 254000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:34.046886172Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 268124593,\n",
      "              \"load_duration\": 9157318,\n",
      "              \"prompt_eval_count\": 328,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 51,\n",
      "              \"eval_duration\": 254000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-1e7b660c-bf94-417e-8816-c55df4d86b87-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [270ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n\\n    Here is the answer: \\n    Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [61ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:34.109933862Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 60429732,\n",
      "          \"load_duration\": 9054195,\n",
      "          \"prompt_eval_count\": 397,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 46000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:34.109933862Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 60429732,\n",
      "              \"load_duration\": 9054195,\n",
      "              \"prompt_eval_count\": 397,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 46000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-f925201c-684f-4514-9f74-aebcf05b513d-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [62ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [62ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [333ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Did Emmanuel Macron visit Germany recently? \\n    Context: [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [267ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:34.377690033Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 265547198,\n",
      "          \"load_duration\": 9073873,\n",
      "          \"prompt_eval_count\": 328,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 51,\n",
      "          \"eval_duration\": 251000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:34.377690033Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 265547198,\n",
      "              \"load_duration\": 9073873,\n",
      "              \"prompt_eval_count\": 328,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 51,\n",
      "              \"eval_duration\": 251000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-1aa24728-0f4b-44f8-a4d0-ab3606182a2b-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [268ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n\\n    Here is the answer: \\n    Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [65ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:34.444143573Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 63901266,\n",
      "          \"load_duration\": 12145619,\n",
      "          \"prompt_eval_count\": 397,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 46000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:34.444143573Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 63901266,\n",
      "              \"load_duration\": 12145619,\n",
      "              \"prompt_eval_count\": 397,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 46000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-ec1b7d3f-dc91-4766-9a98-d486bf668678-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [66ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [67ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [335ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Did Emmanuel Macron visit Germany recently? \\n    Context: [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [267ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:34.713505308Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 265974055,\n",
      "          \"load_duration\": 9058274,\n",
      "          \"prompt_eval_count\": 328,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 51,\n",
      "          \"eval_duration\": 252000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:34.713505308Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 265974055,\n",
      "              \"load_duration\": 9058274,\n",
      "              \"prompt_eval_count\": 328,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 51,\n",
      "              \"eval_duration\": 252000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-a5e3dce9-23f8-4334-b107-b43e84ba8bdf-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [268ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n\\n    Here is the answer: \\n    Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [63ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:34.777230808Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 61241956,\n",
      "          \"load_duration\": 9502908,\n",
      "          \"prompt_eval_count\": 397,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 46000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:34.777230808Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 61241956,\n",
      "              \"load_duration\": 9502908,\n",
      "              \"prompt_eval_count\": 397,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 46000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-ab00093c-d95b-433a-b38a-7063e70e7e89-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [64ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [64ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [333ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Did Emmanuel Macron visit Germany recently? \\n    Context: [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [270ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:35.048912572Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 268221982,\n",
      "          \"load_duration\": 10825540,\n",
      "          \"prompt_eval_count\": 328,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 51,\n",
      "          \"eval_duration\": 252000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:35.048912572Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 268221982,\n",
      "              \"load_duration\": 10825540,\n",
      "              \"prompt_eval_count\": 328,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 51,\n",
      "              \"eval_duration\": 252000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-30989e96-3e84-4ea7-a8f9-477cef61293d-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [271ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n\\n    Here is the answer: \\n    Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [61ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:35.111332578Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 60133066,\n",
      "          \"load_duration\": 9160821,\n",
      "          \"prompt_eval_count\": 397,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 45000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:35.111332578Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 60133066,\n",
      "              \"load_duration\": 9160821,\n",
      "              \"prompt_eval_count\": 397,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 45000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-1704f290-0729-4e65-b27a-a183cbbfee23-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [62ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [62ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [333ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Did Emmanuel Macron visit Germany recently? \\n    Context: [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [260ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:35.372984131Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 259373978,\n",
      "          \"load_duration\": 9297346,\n",
      "          \"prompt_eval_count\": 328,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 51,\n",
      "          \"eval_duration\": 245000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:35.372984131Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 259373978,\n",
      "              \"load_duration\": 9297346,\n",
      "              \"prompt_eval_count\": 328,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 51,\n",
      "              \"eval_duration\": 245000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-a0caf20a-df26-4b6f-b2b4-4a5e464db5a9-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [261ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n\\n    Here is the answer: \\n    Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [64ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:35.438138224Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 62746549,\n",
      "          \"load_duration\": 10948387,\n",
      "          \"prompt_eval_count\": 397,\n",
      "          \"prompt_eval_duration\": 5000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 46000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:35.438138224Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 62746549,\n",
      "              \"load_duration\": 10948387,\n",
      "              \"prompt_eval_count\": 397,\n",
      "              \"prompt_eval_duration\": 5000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 46000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-bd993de0-5631-4fab-864b-031b86e493be-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [65ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [65ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [326ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Did Emmanuel Macron visit Germany recently? \\n    Context: [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [264ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:35.703396374Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 263094846,\n",
      "          \"load_duration\": 9043287,\n",
      "          \"prompt_eval_count\": 328,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 51,\n",
      "          \"eval_duration\": 249000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:35.703396374Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 263094846,\n",
      "              \"load_duration\": 9043287,\n",
      "              \"prompt_eval_count\": 328,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 51,\n",
      "              \"eval_duration\": 249000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-baff74bd-fa4d-40f3-97e6-7b174f39c060-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [265ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n\\n    Here is the answer: \\n    Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [63ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:35.76765968Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 62000793,\n",
      "          \"load_duration\": 9948674,\n",
      "          \"prompt_eval_count\": 397,\n",
      "          \"prompt_eval_duration\": 5000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 45000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:35.76765968Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 62000793,\n",
      "              \"load_duration\": 9948674,\n",
      "              \"prompt_eval_count\": 397,\n",
      "              \"prompt_eval_duration\": 5000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 45000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-21f20f26-c87b-4faa-ae0b-b01323e29aa4-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [64ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [64ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [330ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Did Emmanuel Macron visit Germany recently? \\n    Context: [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [267ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:36.036457363Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 265916922,\n",
      "          \"load_duration\": 15885784,\n",
      "          \"prompt_eval_count\": 328,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 51,\n",
      "          \"eval_duration\": 245000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:36.036457363Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 265916922,\n",
      "              \"load_duration\": 15885784,\n",
      "              \"prompt_eval_count\": 328,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 51,\n",
      "              \"eval_duration\": 245000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-73b68c28-2645-488d-a8ed-f4cb17391719-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [268ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n\\n    Here is the answer: \\n    Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [64ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:36.101159175Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 62412161,\n",
      "          \"load_duration\": 10848430,\n",
      "          \"prompt_eval_count\": 397,\n",
      "          \"prompt_eval_duration\": 5000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 46000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:36.101159175Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 62412161,\n",
      "              \"load_duration\": 10848430,\n",
      "              \"prompt_eval_count\": 397,\n",
      "              \"prompt_eval_duration\": 5000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 46000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-5de81f0a-47b0-49ad-826e-c80e57956f9a-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [64ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [65ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [333ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Did Emmanuel Macron visit Germany recently? \\n    Context: [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [267ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:36.369181475Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 265644726,\n",
      "          \"load_duration\": 9280097,\n",
      "          \"prompt_eval_count\": 328,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 51,\n",
      "          \"eval_duration\": 251000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:36.369181475Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 265644726,\n",
      "              \"load_duration\": 9280097,\n",
      "              \"prompt_eval_count\": 328,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 51,\n",
      "              \"eval_duration\": 251000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-197d9174-3534-47a2-8299-fa9a64749f9b-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [268ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n\\n    Here is the answer: \\n    Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [62ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:36.433332122Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 60802893,\n",
      "          \"load_duration\": 9220219,\n",
      "          \"prompt_eval_count\": 397,\n",
      "          \"prompt_eval_duration\": 5000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 45000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:36.433332122Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 60802893,\n",
      "              \"load_duration\": 9220219,\n",
      "              \"prompt_eval_count\": 397,\n",
      "              \"prompt_eval_duration\": 5000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 45000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-06d933df-b245-4aca-a45e-5e825b7ad725-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [63ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [63ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [332ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Did Emmanuel Macron visit Germany recently? \\n    Context: [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [266ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:36.700695568Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 265151925,\n",
      "          \"load_duration\": 9477026,\n",
      "          \"prompt_eval_count\": 328,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 51,\n",
      "          \"eval_duration\": 251000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:36.700695568Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 265151925,\n",
      "              \"load_duration\": 9477026,\n",
      "              \"prompt_eval_count\": 328,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 51,\n",
      "              \"eval_duration\": 251000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-a75b518b-e3e2-450a-b1c9-95be961851b1-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [267ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n\\n    Here is the answer: \\n    Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [64ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:36.766849696Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 62835470,\n",
      "          \"load_duration\": 11309584,\n",
      "          \"prompt_eval_count\": 397,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 46000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:36.766849696Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 62835470,\n",
      "              \"load_duration\": 11309584,\n",
      "              \"prompt_eval_count\": 397,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 46000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-e5b2758d-1241-4f1d-841c-04095a62027f-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [65ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [66ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [333ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Did Emmanuel Macron visit Germany recently? \\n    Context: [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [268ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:37.036410249Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 267180380,\n",
      "          \"load_duration\": 10653150,\n",
      "          \"prompt_eval_count\": 328,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 51,\n",
      "          \"eval_duration\": 251000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:37.036410249Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 267180380,\n",
      "              \"load_duration\": 10653150,\n",
      "              \"prompt_eval_count\": 328,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 51,\n",
      "              \"eval_duration\": 251000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-049b6471-d761-43eb-8a4a-ffe1a358b148-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [269ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n\\n    Here is the answer: \\n    Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [63ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:37.100069385Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 61456391,\n",
      "          \"load_duration\": 9981102,\n",
      "          \"prompt_eval_count\": 397,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 46000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:37.100069385Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 61456391,\n",
      "              \"load_duration\": 9981102,\n",
      "              \"prompt_eval_count\": 397,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 46000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-57b7b90b-d9b2-4a50-bec0-4af5b02aa5a6-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [64ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [64ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [333ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Did Emmanuel Macron visit Germany recently? \\n    Context: [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [271ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:37.372680227Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 269302509,\n",
      "          \"load_duration\": 11162800,\n",
      "          \"prompt_eval_count\": 328,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 51,\n",
      "          \"eval_duration\": 253000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:37.372680227Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 269302509,\n",
      "              \"load_duration\": 11162800,\n",
      "              \"prompt_eval_count\": 328,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 51,\n",
      "              \"eval_duration\": 253000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-27ae096c-dbc3-4ca7-97a1-843ecc784906-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [272ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n\\n    Here is the answer: \\n    Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [65ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:37.439197542Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 64005253,\n",
      "          \"load_duration\": 11998509,\n",
      "          \"prompt_eval_count\": 397,\n",
      "          \"prompt_eval_duration\": 6000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 45000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:37.439197542Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 64005253,\n",
      "              \"load_duration\": 11998509,\n",
      "              \"prompt_eval_count\": 397,\n",
      "              \"prompt_eval_duration\": 6000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 45000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-4a11d06a-897e-4cbb-83d1-054f95b7e020-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [66ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [66ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [338ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Did Emmanuel Macron visit Germany recently? \\n    Context: [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [267ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:37.706668482Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 265165129,\n",
      "          \"load_duration\": 12948833,\n",
      "          \"prompt_eval_count\": 328,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 51,\n",
      "          \"eval_duration\": 247000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:37.706668482Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 265165129,\n",
      "              \"load_duration\": 12948833,\n",
      "              \"prompt_eval_count\": 328,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 51,\n",
      "              \"eval_duration\": 247000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-565400b5-1d01-41e1-ad27-a813c031d821-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [267ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n\\n    Here is the answer: \\n    Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [61ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:37.76937394Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 60197235,\n",
      "          \"load_duration\": 9154790,\n",
      "          \"prompt_eval_count\": 397,\n",
      "          \"prompt_eval_duration\": 5000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 45000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:37.76937394Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 60197235,\n",
      "              \"load_duration\": 9154790,\n",
      "              \"prompt_eval_count\": 397,\n",
      "              \"prompt_eval_duration\": 5000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 45000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-5fe2e4e5-051c-424d-910a-28b3adb0ab04-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [62ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [62ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [330ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Did Emmanuel Macron visit Germany recently? \\n    Context: [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [265ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:38.035283866Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 263513593,\n",
      "          \"load_duration\": 9121598,\n",
      "          \"prompt_eval_count\": 328,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 51,\n",
      "          \"eval_duration\": 249000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:38.035283866Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 263513593,\n",
      "              \"load_duration\": 9121598,\n",
      "              \"prompt_eval_count\": 328,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 51,\n",
      "              \"eval_duration\": 249000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-c46b1763-ca80-4873-91aa-08241a444144-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [265ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n\\n    Here is the answer: \\n    Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [62ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:38.098657085Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 61012279,\n",
      "          \"load_duration\": 9072840,\n",
      "          \"prompt_eval_count\": 397,\n",
      "          \"prompt_eval_duration\": 6000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 45000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:38.098657085Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 61012279,\n",
      "              \"load_duration\": 9072840,\n",
      "              \"prompt_eval_count\": 397,\n",
      "              \"prompt_eval_duration\": 6000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 45000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-444b4f15-942a-4f38-b7b4-270bc66a2239-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [63ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [63ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [329ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Did Emmanuel Macron visit Germany recently? \\n    Context: [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [263ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:38.362264416Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 261358577,\n",
      "          \"load_duration\": 9155140,\n",
      "          \"prompt_eval_count\": 328,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 51,\n",
      "          \"eval_duration\": 247000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:38.362264416Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 261358577,\n",
      "              \"load_duration\": 9155140,\n",
      "              \"prompt_eval_count\": 328,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 51,\n",
      "              \"eval_duration\": 247000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-1d5e00ef-61b6-4756-853f-9042146dac34-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [263ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n\\n    Here is the answer: \\n    Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [62ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:38.425543282Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 60567978,\n",
      "          \"load_duration\": 9113722,\n",
      "          \"prompt_eval_count\": 397,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 46000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:38.425543282Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 60567978,\n",
      "              \"load_duration\": 9113722,\n",
      "              \"prompt_eval_count\": 397,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 46000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-c90d8b6f-024d-4cdb-b200-f726c658dd03-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [63ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [63ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [327ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Did Emmanuel Macron visit Germany recently? \\n    Context: [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [267ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:38.694393119Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 266460445,\n",
      "          \"load_duration\": 9060430,\n",
      "          \"prompt_eval_count\": 328,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 51,\n",
      "          \"eval_duration\": 252000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:38.694393119Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 266460445,\n",
      "              \"load_duration\": 9060430,\n",
      "              \"prompt_eval_count\": 328,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 51,\n",
      "              \"eval_duration\": 252000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-904e1904-edf2-46c9-b3c7-42c93de77823-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [268ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n\\n    Here is the answer: \\n    Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [62ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:38.756868281Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 60330921,\n",
      "          \"load_duration\": 9111335,\n",
      "          \"prompt_eval_count\": 397,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 45000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:38.756868281Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 60330921,\n",
      "              \"load_duration\": 9111335,\n",
      "              \"prompt_eval_count\": 397,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 45000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-c8eb9be4-08a2-44f9-88d0-86bd1d2fdfd3-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [62ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [62ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [331ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Did Emmanuel Macron visit Germany recently? \\n    Context: [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [273ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:39.031129615Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 271810593,\n",
      "          \"load_duration\": 16006241,\n",
      "          \"prompt_eval_count\": 328,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 51,\n",
      "          \"eval_duration\": 251000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:39.031129615Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 271810593,\n",
      "              \"load_duration\": 16006241,\n",
      "              \"prompt_eval_count\": 328,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 51,\n",
      "              \"eval_duration\": 251000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-81becf94-b1dd-4ddc-8d22-43d8414fbd53-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [274ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n\\n    Here is the answer: \\n    Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [68ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:39.100389112Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 65882927,\n",
      "          \"load_duration\": 13781781,\n",
      "          \"prompt_eval_count\": 397,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 46000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:39.100389112Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 65882927,\n",
      "              \"load_duration\": 13781781,\n",
      "              \"prompt_eval_count\": 397,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 46000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-d04923f0-b13b-4c81-ae77-fa93bd70bc23-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [69ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [69ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [344ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Did Emmanuel Macron visit Germany recently? \\n    Context: [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [270ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:39.372046006Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 268185374,\n",
      "          \"load_duration\": 10086646,\n",
      "          \"prompt_eval_count\": 328,\n",
      "          \"prompt_eval_duration\": 5000000,\n",
      "          \"eval_count\": 51,\n",
      "          \"eval_duration\": 252000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:39.372046006Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 268185374,\n",
      "              \"load_duration\": 10086646,\n",
      "              \"prompt_eval_count\": 328,\n",
      "              \"prompt_eval_duration\": 5000000,\n",
      "              \"eval_count\": 51,\n",
      "              \"eval_duration\": 252000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-9d8431a9-360c-43be-bfc8-3e9deb02483c-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [271ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n\\n    Here is the answer: \\n    Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [63ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:39.436641844Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 61246212,\n",
      "          \"load_duration\": 9710065,\n",
      "          \"prompt_eval_count\": 397,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 46000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:39.436641844Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 61246212,\n",
      "              \"load_duration\": 9710065,\n",
      "              \"prompt_eval_count\": 397,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 46000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-c408ad29-1e75-436e-a278-82569085b9ce-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [64ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [64ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [335ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Did Emmanuel Macron visit Germany recently? \\n    Context: [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [266ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:39.703508945Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 264544893,\n",
      "          \"load_duration\": 8984250,\n",
      "          \"prompt_eval_count\": 328,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 51,\n",
      "          \"eval_duration\": 250000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:39.703508945Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 264544893,\n",
      "              \"load_duration\": 8984250,\n",
      "              \"prompt_eval_count\": 328,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 51,\n",
      "              \"eval_duration\": 250000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-1d62d9b2-524c-4472-8638-4c47c2ef193f-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [266ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n\\n    Here is the answer: \\n    Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [63ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:39.767189612Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 61399740,\n",
      "          \"load_duration\": 9259047,\n",
      "          \"prompt_eval_count\": 397,\n",
      "          \"prompt_eval_duration\": 6000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 45000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:39.767189612Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 61399740,\n",
      "              \"load_duration\": 9259047,\n",
      "              \"prompt_eval_count\": 397,\n",
      "              \"prompt_eval_duration\": 6000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 45000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-612ed851-7a85-437d-97a4-e356489ee581-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [64ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [64ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [331ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATE---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant for question-answering tasks. \\n    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \\n    Use three sentences maximum and keep the answer concise:\\n    Question: Did Emmanuel Macron visit Germany recently? \\n    Context: [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n    Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:ChatOllama] [261ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:40.030256968Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 259644380,\n",
      "          \"load_duration\": 9063470,\n",
      "          \"prompt_eval_count\": 328,\n",
      "          \"prompt_eval_duration\": 4000000,\n",
      "          \"eval_count\": 51,\n",
      "          \"eval_duration\": 245000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:40.030256968Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 259644380,\n",
      "              \"load_duration\": 9063470,\n",
      "              \"prompt_eval_count\": 328,\n",
      "              \"prompt_eval_duration\": 4000000,\n",
      "              \"eval_count\": 51,\n",
      "              \"eval_duration\": 245000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-12a60c52-88bc-45a5-b1f8-36b6f97d5eea-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [262ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,question,generation,web_search,documents>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECK HALLUCINATIONS---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a grader assessing whether \\n    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \\n    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \\n    single key 'score' and no preamble or explanation.\\n    \\n    Here are the facts:\\n    [Document(metadata={}, page_content=\\\"PARIS/BERLIN - French President Emmanuel Macron arrived in Berlin on May 26 on the first state visit to Germany by a French president in a quarter of a century, seeking to ease recent tensions and\\\\nEmmanuel Macron arrived in Berlin on Sunday for the first state visit to Germany by a French president in 24 years, a pomp-filled three-day trip that is being described as a tribute to the Franco\\\\nBERLIN (AP) — President Emmanuel Macron on Sunday started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the European Union's traditional leading powers ahead of European Parliament elections in which far-right parties in both countries hope for gains.\\\\nFrench President Emmanuel Macron landed in Germany on Sunday for a three-day state visit followed by a bilateral cabinet meeting as the European Union's two biggest powers seek to show unity ahead\\\\nPresident Emmanuel Macron on Sunday, May 26, started the first state visit to Germany by a French head of state in 24 years, a three-day trip meant to underline the strong ties between the\\\")] \\n\\n    Here is the answer: \\n    Yes, Emmanuel Macron visited Germany recently. He arrived in Berlin on May 26 for a three-day state visit, which was his first as French president in 24 years. The visit aimed to ease recent tensions and strengthen ties between France and Germany.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > llm:ChatOllama] [61ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b\",\n",
      "          \"created_at\": \"2024-12-08T14:20:40.092597274Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 60228050,\n",
      "          \"load_duration\": 9027088,\n",
      "          \"prompt_eval_count\": 397,\n",
      "          \"prompt_eval_duration\": 5000000,\n",
      "          \"eval_count\": 7,\n",
      "          \"eval_duration\": 44000000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"score\\\": \\\"no\\\"}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b\",\n",
      "              \"created_at\": \"2024-12-08T14:20:40.092597274Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 60228050,\n",
      "              \"load_duration\": 9027088,\n",
      "              \"prompt_eval_count\": 397,\n",
      "              \"prompt_eval_duration\": 5000000,\n",
      "              \"eval_count\": 7,\n",
      "              \"eval_duration\": 44000000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-4fe97e0c-665e-4f32-bcb8-e68bb8c291e4-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question > chain:RunnableSequence] [62ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"score\": \"no\"\n",
      "}\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:grade_generation_v_documents_and_question] [63ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"not supported\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [325ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "'Finished running: generate:'\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[chain:LangGraph] [10.51s] Chain run errored with error:\n",
      "\u001b[0m\"GraphRecursionError('Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\\\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT')Traceback (most recent call last):\\n\\n\\n  File \\\"/home/ollama_platform/miniconda3/envs/AgenticRAG/lib/python3.12/site-packages/langgraph/pregel/__init__.py\\\", line 1669, in stream\\n    raise GraphRecursionError(msg)\\n\\n\\nlanggraph.errors.GraphRecursionError: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT\"\n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGraphRecursionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpprint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pprint\n\u001b[1;32m      3\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDid Emmanuel Macron visit Germany recently?\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpprint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFinished running: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/AgenticRAG/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1669\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_of_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1661\u001b[0m     msg \u001b[38;5;241m=\u001b[39m create_error_message(\n\u001b[1;32m   1662\u001b[0m         message\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1663\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m reached \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1667\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mGRAPH_RECURSION_LIMIT,\n\u001b[1;32m   1668\u001b[0m     )\n\u001b[0;32m-> 1669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(msg)\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[1;32m   1671\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(loop\u001b[38;5;241m.\u001b[39moutput)\n",
      "\u001b[0;31mGraphRecursionError\u001b[0m: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "from pprint import pprint\n",
    "inputs = {\"question\": \"Did Emmanuel Macron visit Germany recently?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AgenticRAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
