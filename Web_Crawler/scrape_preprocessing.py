# -*- coding: utf-8 -*-
"""scrape_preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SFquIHQglcnUBna2x1u4eSZebUv8Azu8
"""

pip install emoji

import emoji
def emoji_to_word(data):
  for thread in data.get("thread",[]):
    if "text" in thread:
        thread["text"] = emoji.demojize(thread["text"])

#全形 -> 半形
def fullwidth_to_halfwidth(text):
  return ''.join(
      chr(ord(c) - 0xFEE0) if '\uFF01' <= c <= '\uFF5E' else c for c in text
    )

import re
def data_cleaning(text):
  if text is None:
    return ""
  new_text = fullwidth_to_halfwidth(text)
  REMOVE_CHARS = ".,!?！？-_@#$%^&*()[]{}<>【】~`|\\/;:\"'\n\r\t"
  for char in REMOVE_CHARS:
    text = text.replace(char, "")
  return text.replace(" ", "")

import json

input_file_path = "/content/drive/MyDrive/ColabNotebooks/NLP/output_json/data_1209_1024.json"
output_file_path = "/content/drive/MyDrive/ColabNotebooks/NLP/output_json/data_1209_1024_check.json"

with open(input_file_path, "r", encoding="utf-8") as input_file:
  data = json.load(input_file)

emoji_to_word(data)

for thread in data.get("thread", []):
  if "text" in thread:
    original_text = thread["text"]
    cleaned_text = data_cleaning(original_text)
    thread["text"] = cleaned_text  # 更新为清理后的文本


with open(output_file_path, "w", encoding="utf-8") as output_file:
  json.dump(data, output_file, ensure_ascii=False, indent=4)
  print(f"{output_file} saving complete...")