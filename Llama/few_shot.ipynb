{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d4c37b126d4032a0126f7f1e1a6f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "model_name = 'taide/Llama3-TAIDE-LX-8B-Chat-Alpha1'\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir='/HDD/model_cache/'\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    padding_side='left',\n",
    "    cache_dir='/HDD/model_cache/'\n",
    ")\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'category'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from datasets import Dataset\n",
    "\n",
    "example_input = json.loads(Path('./labeled_datasets/example.json').read_text())['input']\n",
    "example_output = json.loads(Path('./labeled_datasets/example.json').read_text())['output']\n",
    "#27712\n",
    "train_data = json.loads(Path('./dataset/combined_data_unique.json').read_text())\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ä½ æ˜¯ä¸€å€‹è²¼æ–‡å¯©æŸ¥å°ˆå®¶ï¼Œä½ çš„ä»»å‹™æ˜¯åˆ¤æ–·çµ¦å®šçš„è²¼æ–‡æ˜¯å¦ç‚ºè©é¨™ï¼Œ\n",
      "ä½ åªèƒ½æ ¹æ“šè¼¸å…¥å…§å®¹ç”Ÿæˆä»¥ä¸‹æ ¼å¼çš„å–®å€‹ JSONï¼š\n",
      "{\n",
      "    \"text\": \"<è²¼æ–‡å…§å®¹>\",\n",
      "    \"label\": \"<æ¨™è¨˜çµæœ (0 æˆ– 1)>\",\n",
      "    \"explination\": \"<æ¨™è¨˜ç†ç”±>\"\n",
      "}\n",
      "é™¤äº†ä¸Šè¿° JSON çµæœï¼Œè«‹å‹¿ç”Ÿæˆä»»ä½•å…¶ä»–å…§å®¹ã€‚\n",
      "è¼¸å…¥è¼¸å‡ºåƒè€ƒä»¥ä¸‹ç¯„ä¾‹:\n",
      "è¼¸å…¥: {'text': 'æˆ‘å€‘é€™é‚Šæœ‰ç¼ºå‘¦womanraisinghandlightskintoneåœ¨å®¶å·¥ä½œè¼•é¬†è³ºé£½é£½'}\n",
      "è¼¸å‡º: {'label': 1, 'explination': 'é€™å‰‡è²¼æ–‡åˆ©ç”¨å¸å¼•äººçš„èªå¥ï¼Œæ‰¿è«¾åœ¨å®¶è¼•é¬†è³ºéŒ¢ï¼Œæœªæä¾›å…·é«”è·æ¥­è³‡è¨Šï¼Œå¸¸è¦‹æ–¼è©é¨™è¨Šæ¯ä»¥å¸å¼•ä¸çŸ¥æƒ…çš„å—å®³è€…ã€‚'}\n",
      "\n",
      "è¼¸å…¥: {'text': 'Japaneseacceptablebuttonä¸é™å¹³å°ç§å¸¶äº‹ç”±ç™¾å®¶æ¨‚ç§å¸¶ç¾¤å¸¶é€£å€’äº”å¤©å™´äº†å…©è¬æœ¬é‡‘5000ç²åˆ©32000å…§æ–‡æ”¾ç•™è¨€'}\n",
      "è¼¸å‡º: {'label': 1, 'explination': 'è²¼æ–‡å…§å®¹æåŠç§å¸¶ç™¾å®¶æ¨‚ç¾¤çµ„ä¸¦å®£ç¨±é«˜é¡ç²åˆ©ï¼Œé€™æ˜¯å¸¸è¦‹çš„è©é¨™æ¨¡å¼ï¼Œèª˜å°ç”¨æˆ¶åŠ å…¥éæ³•è³­åšæˆ–è©é¨™ç¾¤çµ„ï¼Œæ²’æœ‰å¯ä¿¡åº¦ã€‚'}\n",
      "\n",
      "è¼¸å…¥: {'text': 'äººå¾ˆå¥‡æ€ªæœ‰æ™‚å€™å¾ˆæƒ³æ‰¾äººèŠå¤©æœ‰æ™‚å€™åˆæƒ³å®‰å®‰éœéœçš„æ²‰æµ¸åœ¨è‡ªå·±çš„ä¸–ç•Œ'}\n",
      "è¼¸å‡º: {'label': 0, 'explination': 'é€™å‰‡è²¼æ–‡è¡¨é”çš„æ˜¯å€‹äººæƒ…æ„Ÿèˆ‡æ—¥å¸¸å¿ƒæƒ…åˆ†äº«ï¼Œä¸¦ç„¡ä»»ä½•èª˜å°æ€§æˆ–è©é¨™ç‰¹å¾µï¼Œå±¬æ–¼æ™®é€šçš„ç¤¾äº¤è²¼æ–‡ã€‚'}\n",
      "\n",
      "è¼¸å…¥: {'text': 'èƒ½å¾µå‹æ–‡è„†å‹å–®èº«ä¾†èªè­˜ä¸€ä¸‹æ¡ƒåœ’æ–°ç«¹éƒ½èƒ½æ¥å—ç•°åœ°æˆ‘83å¹´æ¬¡16053ä½†å¸Œæœ›æœ‰äººè¿½è¹¤æˆ‘ç›¸äº’ç­è§£salutingfaceå¸Œæœ›é¤˜ç”Ÿæœ‰å¹¸èƒ½å¤šå¤šæŒ‡æ•™è¦èŠå¤©å“€å±…å¯†æˆ‘å›è¦†å–²facewithpeekingeye'}\n",
      "è¼¸å‡º: {'label': 1, 'explination': 'è²¼æ–‡ä»¥äº¤å‹ç‚ºåå¸å¼•ç›®æ¨™ï¼Œè¦æ±‚ç§è¨Šè¿½è¹¤ï¼Œä½†å…§å®¹ç¼ºä¹çœŸå¯¦æ€§ä¸”å¸¶æœ‰æ½›åœ¨èª˜å°æ€§ï¼Œå¯èƒ½æ¶‰åŠäº¤å‹è©é¨™æˆ–å…¶ä»–ä¸ç•¶è¡Œç‚ºã€‚'}\n",
      "\n",
      "è¼¸å…¥: {'text': 'å°è‚¡ä»Šå¤©ç¹¼çºŒæ¼²chartincreasingä½†æ˜¯æ«ƒè²·å°±æ²’é€™éº¼å¥½BBUæ—ç¾¤å…¨é¢é‡æŒ«æ˜¯å¦æ‹‰å›æ‰¾è²·é»èˆ¹å’Œé£›æ©Ÿè¡¨ç¾ä¸éŒ¯ä½†æ˜¯AIè»Ÿé«”è‚¡æ›´äº®çœ¼ICè¨­è¨ˆä»Šå¤©ä¹Ÿæ˜¯æœ‰é»æ„æ€æ¥è‘—è©²æ€éº¼åšç›¤é¢å¥½åƒä¸€å †ä¸»æµåˆå¥½åƒæ²’æœ‰ä¸»æµèª°æ˜¯çœŸçš„èª°æ˜¯å‡çš„è®“æˆ‘å€‘ç¹¼çºŒçœ‹ä¸‹å»é‚„å¥½æˆ‘çš„è‚¡éƒ½æ˜¯ç´…çš„ä½†ä¸€æ¨£åšäº†é»èª¿æ•´è‚¡ç¥¨æŠ•è³‡'}\n",
      "è¼¸å‡º: {'label': 0, 'explination': 'è²¼æ–‡åˆ†äº«çš„æ˜¯è‚¡å¸‚çš„åˆ†æèˆ‡å€‹äººè§€é»ï¼Œä¸¦æœªæä¾›èª‡å¼µçš„ç²åˆ©æ‰¿è«¾æˆ–èª˜å°æ€§è¨Šæ¯ï¼Œå±¬æ–¼æ™®é€šçš„æŠ•è³‡è¨è«–å…§å®¹ã€‚'}\n",
      "\n",
      "è¼¸å…¥: {'text': 'æœ¬é€±ä¸‹è»Šç²åˆ©æƒ…æ³åˆ†äº«é †é”86è¬æ¿±å·30è¬ä¸–ç´€100è¬ç¥æº–50è¬å‘½é‹çš„é½’è¼ªå†æ¬¡è½‰å‹•è²¡å¯Œè‡ªç”±ä¹‹è·¯æ­£å¼é–‹å•Ÿä»Šæ—¥æ¨è–¦è‚¡ç¥¨ä¸Šå‡è¶¨å‹¢æ˜é¡¯è¿‘æœŸé‡å¢æ˜¯å¹³æ—¥çš„34å€å™´ç™¼æ¦‚ç‡æå‡æ˜æ—¥é–‹ç›¤å³å¯è²·å…¥è¿‘å¹¾æ—¥æ¨è–¦çš„è‚¡ç¥¨è„†å‹å€‘éƒ½æœ‰ä¸Šè»Šé€£æ¼²ä¸€é€±é–‹å§‹å°æœ‰ç²åˆ©æ˜æ—¥é–‹ç›¤æƒ³è¦ä¸€èµ·ä¸Šè»Šçš„çœ‹ä¸‹é¢ç•™è¨€backhandindexpointingdown'}\n",
      "è¼¸å‡º: {'label': 1, 'explination': 'è²¼æ–‡èª‡å¤§äº†è‚¡ç¥¨æŠ•è³‡çš„é«˜é¡ç²åˆ©ä¸¦ä»¥èª˜å°æ€§èªå¥å¸å¼•äººç•™è¨€æˆ–åƒèˆ‡ï¼Œé€™æ˜¯å¸¸è¦‹çš„æŠ•è³‡è©é¨™æ‰‹æ³•ï¼Œè©¦åœ–å¸å¼•ç›®æ¨™é€²ä¸€æ­¥äº’å‹•æˆ–è³¼è²·æœå‹™ã€‚'}\n",
      "\n",
      "è¼¸å…¥: {'text': 'æœ‰æ‰“å°±éŒ„ï¼Œæ˜¯èªªé€™è£¡å·²ç¶“è®Šåœè»Šå ´äº†ğŸ˜®\\u200dğŸ’¨\\nå¤§å”ç±ƒçƒ'}\n",
      "è¼¸å‡º: {'label': 0, 'explination': 'è²¼æ–‡æ˜¯å°ç±ƒçƒå ´åœ°ç¾æ³çš„è¼•é¬†åæ§½ï¼Œå±¬æ–¼æ™®é€šçš„ç”Ÿæ´»åˆ†äº«å…§å®¹ï¼Œä¸¦ç„¡ä»»ä½•è©é¨™ç‰¹å¾µæˆ–èª˜å°æ€§ã€‚'}\n",
      "\n",
      "è¼¸å…¥: {'text': 'å…«æ–¹é›²é›†ç‚ºä»€éº¼è¦æ”¾æŠ–éŸ³æ…¢æ–ï¼Œè½åˆ°å¤©èŠ±æ¿ä¸€ç›´å’šå’šå’šï¼Œæˆ‘éƒ½è¦ºå¾—æˆ‘çš„é‹è²¼åœ¨æ–èŠ±æ‰‹ã€‚'}\n",
      "è¼¸å‡º: {'label': 0, 'explination': 'è²¼æ–‡å¹½é»˜åœ°æŠ±æ€¨ç”¨é¤ç’°å¢ƒçš„èƒŒæ™¯éŸ³æ¨‚ï¼Œå±¬æ–¼æ—¥å¸¸ç”Ÿæ´»ç¶“é©—åˆ†äº«ï¼Œä¸¦ç„¡è©é¨™æˆ–èª˜å°æ€§å…§å®¹ã€‚'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "instruction = f'''\n",
    "ä½ æ˜¯ä¸€å€‹è²¼æ–‡å¯©æŸ¥å°ˆå®¶ï¼Œä½ çš„ä»»å‹™æ˜¯åˆ¤æ–·çµ¦å®šçš„è²¼æ–‡æ˜¯å¦ç‚ºè©é¨™ï¼Œ\n",
    "ä½ åªèƒ½æ ¹æ“šè¼¸å…¥å…§å®¹ç”Ÿæˆä»¥ä¸‹æ ¼å¼çš„å–®å€‹ JSONï¼š\n",
    "{{\n",
    "    \"text\": \"<è²¼æ–‡å…§å®¹>\",\n",
    "    \"label\": \"<æ¨™è¨˜çµæœ (0 æˆ– 1)>\",\n",
    "    \"explination\": \"<æ¨™è¨˜ç†ç”±>\"\n",
    "}}\n",
    "é™¤äº†ä¸Šè¿° JSON çµæœï¼Œè«‹å‹¿ç”Ÿæˆä»»ä½•å…¶ä»–å…§å®¹ã€‚\n",
    "è¼¸å…¥è¼¸å‡ºåƒè€ƒä»¥ä¸‹ç¯„ä¾‹:\n",
    "è¼¸å…¥: {example_input[0]}\n",
    "è¼¸å‡º: {example_output[0]}\n",
    "\n",
    "è¼¸å…¥: {example_input[1]}\n",
    "è¼¸å‡º: {example_output[1]}\n",
    "\n",
    "è¼¸å…¥: {example_input[2]}\n",
    "è¼¸å‡º: {example_output[2]}\n",
    "\n",
    "è¼¸å…¥: {example_input[3]}\n",
    "è¼¸å‡º: {example_output[3]}\n",
    "\n",
    "è¼¸å…¥: {example_input[4]}\n",
    "è¼¸å‡º: {example_output[4]}\n",
    "\n",
    "è¼¸å…¥: {example_input[5]}\n",
    "è¼¸å‡º: {example_output[5]}\n",
    "\n",
    "è¼¸å…¥: {example_input[6]}\n",
    "è¼¸å‡º: {example_output[6]}\n",
    "\n",
    "è¼¸å…¥: {example_input[7]}\n",
    "è¼¸å‡º: {example_output[7]}\n",
    "\n",
    "'''\n",
    "sys = f'''{instruction}'''\n",
    "print(sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline(\n",
    "    model=model, \n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    device='cuda:1',\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_prompt(datapoint):\n",
    "    text = datapoint['text']\n",
    "    query = f'è¼¸å…¥: {{\"text\": \"{text}\"}}'\n",
    "    message = [\n",
    "        {\"role\": \"system\", \"content\": sys},\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        message,\n",
    "        tokenize=False,\n",
    "        max_new_tokens=128,\n",
    "        min_new_tokens=64\n",
    "    )\n",
    "    if prompt is None:\n",
    "        raise ValueError(f\"Prompt generation failed for text: {text}\")\n",
    "    datapoint['prompt'] = prompt\n",
    "    return datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 10. Reducing num_proc to 10 for dataset of size 10.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456ca07ecbaa46b69016768716b5791c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=10):   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'category', 'prompt'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataset = train_dataset.map(prepare_prompt, batched=False, num_proc=32)\n",
    "dataloader = DataLoader(train_dataset, batch_size=16, shuffle=False)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.55s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "result_dataset = {\n",
    "    'text': [],\n",
    "    'output': [],\n",
    "}\n",
    "\n",
    "for batch in tqdm(dataloader):\n",
    "    prompts = batch['prompt'] \n",
    "    texts = batch['text']   \n",
    "    \n",
    "    outputs = generator(\n",
    "        prompts, \n",
    "        max_new_tokens=64, \n",
    "        min_new_tokens=32,\n",
    "        stop_strings=\"}\",\n",
    "        tokenizer = tokenizer,\n",
    "        return_full_text=False,\n",
    "    )\n",
    "    \n",
    "    result_dataset['text'].extend(texts)\n",
    "    result_dataset['output'].extend(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_dataset['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(result_dataset).to_csv('dataset1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>æµé‡å¯†ç¢¼</td>\n",
       "      <td>[{'generated_text': \"è¼¸å‡ºï¼š{'label': 0, 'explinat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19æ­²çŸ¥é“ç”·å‹æ‰‹æ©Ÿå¯†ç¢¼å¾ˆæœ‰å®‰å…¨æ„Ÿ29æ­²æˆ¶é ­æœ‰200è¬å¾ˆæœ‰å®‰å…¨æ„Ÿ</td>\n",
       "      <td>[{'generated_text': 'è¼¸å‡ºï¼š\\n{\\n\"label\": 1,\\n\"exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>å¥½åƒæ˜¯æ¬¸æ˜Œè‘£çš„è»Šæ˜¯æµé‡å¯†ç¢¼thumbsup</td>\n",
       "      <td>[{'generated_text': 'æˆ‘é€™é‚Šå°±æ˜¯æŠŠè¼¸å…¥çš„JSONæ ¼å¼çš„å­—å…¸ï¼Œå°è¼¸å…¥çš„ã€Œt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ä¾‹å¦‚ä»€éº¼è®“æˆ‘å´è€³å‚¾è½redheartæµé‡å¯†ç¢¼åœ¨å“ªè£¡</td>\n",
       "      <td>[{'generated_text': \"è¼¸å‡ºï¼š{'label': 1, 'explinat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>æŸ¥å´—æ‰‹æ©Ÿæ‹¿ä¾†æ´›ç‡æ¼«ä¸ç¶“å¿ƒåœ°å°‡æ‰‹æ©Ÿæ”¾åœ¨ä»–æ‰‹å¿ƒä¸Šå¯†ç¢¼æˆ‘ç”Ÿæ—¥ç®—äº†æˆ‘æŒºç›¸ä¿¡ä½ çš„èªªç½·ä¾¿å°‡æ‰‹æ©Ÿé‚„çµ¦äº†ä»–ä½ ...</td>\n",
       "      <td>[{'generated_text': \"è¼¸å‡ºï¼š\\n{'label': 0, 'explin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15842</th>\n",
       "      <td>å¥½å¥½å·¥ä½œè³ºéŒ¢å§</td>\n",
       "      <td>[{'generated_text': 'é€™å€‹è¼¸å…¥æ²’æœ‰å½¢æˆä¸€å€‹æœ‰æ•ˆçš„å•é¡Œï¼Œå› æ­¤ç„¡æ³•æ ¹æ“šè©²è¼¸å…¥...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15843</th>\n",
       "      <td>åœ‹ä¸€å¤§å®‰é«˜å·¥oré•·åºšè­·å°ˆå›é ­çœ‹è¦ºå¾—åœ‹ä¸€å¿—é¡˜è¨­é€™å…©å€‹è¶…ä¸é©åˆè‡ªå·±åœ‹äºŒå¤§å®‰é«˜å·¥å¸«å¤§é™„ä¸­è¨±é¡˜è®€çš„é«˜...</td>\n",
       "      <td>[{'generated_text': 'è¼¸å‡ºï¼š\\n{\\n\"label\": 0,\\n\"exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15844</th>\n",
       "      <td>ä¸­ç²‰éƒ½ä¸ç”¨è³ºéŒ¢ä¸ç”¨ä¸Šç­å—</td>\n",
       "      <td>[{'generated_text': \"è¼¸å‡º: {'label': 1, 'explina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15845</th>\n",
       "      <td>åŸä¾†å¯æ˜¯æˆ‘ä¹Ÿç–‘æƒ‘å«ŒçŠ¯å·åˆ°æ‰‹æ©Ÿæ€éº¼æ²’ç™»å…¥å“ˆå“ˆ</td>\n",
       "      <td>[{'generated_text': \"è¼¸å‡ºï¼š{'label': 0, 'explinat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15846</th>\n",
       "      <td>å› ç‚ºå­¸è³ºéŒ¢ä¸æ˜¯å­¸æ ¡æ•™è‚²çš„ç›®çš„æ¢ç´¢è‡ªå·±æ‰¾åˆ°èˆˆè¶£åšå€‹å°ç¤¾æœƒæœ‰è²¢ç»çš„äººæ¯”è¼ƒé‡è¦</td>\n",
       "      <td>[{'generated_text': 'é€™å€‹è²¼æ–‡çš„æ¨™è¨˜çµæœç‚ºä½•ï¼Ÿ\\nè¼¸å‡º:\\n{\\n\"la...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15847 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0                                                   æµé‡å¯†ç¢¼   \n",
       "1                        19æ­²çŸ¥é“ç”·å‹æ‰‹æ©Ÿå¯†ç¢¼å¾ˆæœ‰å®‰å…¨æ„Ÿ29æ­²æˆ¶é ­æœ‰200è¬å¾ˆæœ‰å®‰å…¨æ„Ÿ   \n",
       "2                                  å¥½åƒæ˜¯æ¬¸æ˜Œè‘£çš„è»Šæ˜¯æµé‡å¯†ç¢¼thumbsup   \n",
       "3                              ä¾‹å¦‚ä»€éº¼è®“æˆ‘å´è€³å‚¾è½redheartæµé‡å¯†ç¢¼åœ¨å“ªè£¡   \n",
       "4      æŸ¥å´—æ‰‹æ©Ÿæ‹¿ä¾†æ´›ç‡æ¼«ä¸ç¶“å¿ƒåœ°å°‡æ‰‹æ©Ÿæ”¾åœ¨ä»–æ‰‹å¿ƒä¸Šå¯†ç¢¼æˆ‘ç”Ÿæ—¥ç®—äº†æˆ‘æŒºç›¸ä¿¡ä½ çš„èªªç½·ä¾¿å°‡æ‰‹æ©Ÿé‚„çµ¦äº†ä»–ä½ ...   \n",
       "...                                                  ...   \n",
       "15842                                            å¥½å¥½å·¥ä½œè³ºéŒ¢å§   \n",
       "15843  åœ‹ä¸€å¤§å®‰é«˜å·¥oré•·åºšè­·å°ˆå›é ­çœ‹è¦ºå¾—åœ‹ä¸€å¿—é¡˜è¨­é€™å…©å€‹è¶…ä¸é©åˆè‡ªå·±åœ‹äºŒå¤§å®‰é«˜å·¥å¸«å¤§é™„ä¸­è¨±é¡˜è®€çš„é«˜...   \n",
       "15844                                       ä¸­ç²‰éƒ½ä¸ç”¨è³ºéŒ¢ä¸ç”¨ä¸Šç­å—   \n",
       "15845                              åŸä¾†å¯æ˜¯æˆ‘ä¹Ÿç–‘æƒ‘å«ŒçŠ¯å·åˆ°æ‰‹æ©Ÿæ€éº¼æ²’ç™»å…¥å“ˆå“ˆ   \n",
       "15846               å› ç‚ºå­¸è³ºéŒ¢ä¸æ˜¯å­¸æ ¡æ•™è‚²çš„ç›®çš„æ¢ç´¢è‡ªå·±æ‰¾åˆ°èˆˆè¶£åšå€‹å°ç¤¾æœƒæœ‰è²¢ç»çš„äººæ¯”è¼ƒé‡è¦   \n",
       "\n",
       "                                                  output  \n",
       "0      [{'generated_text': \"è¼¸å‡ºï¼š{'label': 0, 'explinat...  \n",
       "1      [{'generated_text': 'è¼¸å‡ºï¼š\\n{\\n\"label\": 1,\\n\"exp...  \n",
       "2      [{'generated_text': 'æˆ‘é€™é‚Šå°±æ˜¯æŠŠè¼¸å…¥çš„JSONæ ¼å¼çš„å­—å…¸ï¼Œå°è¼¸å…¥çš„ã€Œt...  \n",
       "3      [{'generated_text': \"è¼¸å‡ºï¼š{'label': 1, 'explinat...  \n",
       "4      [{'generated_text': \"è¼¸å‡ºï¼š\\n{'label': 0, 'explin...  \n",
       "...                                                  ...  \n",
       "15842  [{'generated_text': 'é€™å€‹è¼¸å…¥æ²’æœ‰å½¢æˆä¸€å€‹æœ‰æ•ˆçš„å•é¡Œï¼Œå› æ­¤ç„¡æ³•æ ¹æ“šè©²è¼¸å…¥...  \n",
       "15843  [{'generated_text': 'è¼¸å‡ºï¼š\\n{\\n\"label\": 0,\\n\"exp...  \n",
       "15844  [{'generated_text': \"è¼¸å‡º: {'label': 1, 'explina...  \n",
       "15845  [{'generated_text': \"è¼¸å‡ºï¼š{'label': 0, 'explinat...  \n",
       "15846  [{'generated_text': 'é€™å€‹è²¼æ–‡çš„æ¨™è¨˜çµæœç‚ºä½•ï¼Ÿ\\nè¼¸å‡º:\\n{\\n\"la...  \n",
       "\n",
       "[15847 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "labeled_data = pd.read_csv('dataset.csv').drop(['Unnamed: 0'], axis=1)\n",
    "labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_label(output):\n",
    "    label_pattern = r\"(label.*(1|0).*,)\"\n",
    "    match = re.search(label_pattern, output)\n",
    "    return int(match.group(2))\n",
    "def get_explination(output):\n",
    "    label_pattern = r\"(explination.*:([^}\\\"]*))\"\n",
    "    match = re.search(label_pattern, output)\n",
    "    return match.group(2).strip().replace(\"'\",'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "success_extract = []\n",
    "failed_extract = []\n",
    "for text, output in zip(labeled_data['text'], labeled_data['output']):\n",
    "    try:\n",
    "        label = get_label(output)\n",
    "        explination = get_explination(output)\n",
    "        success_extract.append({\n",
    "            \"text\": text,\n",
    "            \"label\": label,\n",
    "            \"explination\": explination\n",
    "        })\n",
    "    except:\n",
    "        failed_extract.append({\n",
    "            \"text\": text,\n",
    "            \"output\": output\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# output_path = Path('./dataset/training.json')\n",
    "# with output_path.open('w', encoding='utf-8') as f:\n",
    "#     json.dump(success_extract, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
