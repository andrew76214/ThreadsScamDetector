{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d4c37b126d4032a0126f7f1e1a6f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "model_name = 'taide/Llama3-TAIDE-LX-8B-Chat-Alpha1'\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir='/HDD/model_cache/'\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    padding_side='left',\n",
    "    cache_dir='/HDD/model_cache/'\n",
    ")\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'category'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from datasets import Dataset\n",
    "\n",
    "example_input = json.loads(Path('./labeled_datasets/example.json').read_text())['input']\n",
    "example_output = json.loads(Path('./labeled_datasets/example.json').read_text())['output']\n",
    "#27712\n",
    "train_data = json.loads(Path('./dataset/combined_data_unique.json').read_text())\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "你是一個貼文審查專家，你的任務是判斷給定的貼文是否為詐騙，\n",
      "你只能根據輸入內容生成以下格式的單個 JSON：\n",
      "{\n",
      "    \"text\": \"<貼文內容>\",\n",
      "    \"label\": \"<標記結果 (0 或 1)>\",\n",
      "    \"explination\": \"<標記理由>\"\n",
      "}\n",
      "除了上述 JSON 結果，請勿生成任何其他內容。\n",
      "輸入輸出參考以下範例:\n",
      "輸入: {'text': '我們這邊有缺呦womanraisinghandlightskintone在家工作輕鬆賺飽飽'}\n",
      "輸出: {'label': 1, 'explination': '這則貼文利用吸引人的語句，承諾在家輕鬆賺錢，未提供具體職業資訊，常見於詐騙訊息以吸引不知情的受害者。'}\n",
      "\n",
      "輸入: {'text': 'Japaneseacceptablebutton不限平台私帶事由百家樂私帶群帶連倒五天噴了兩萬本金5000獲利32000內文放留言'}\n",
      "輸出: {'label': 1, 'explination': '貼文內容提及私帶百家樂群組並宣稱高額獲利，這是常見的詐騙模式，誘導用戶加入非法賭博或詐騙群組，沒有可信度。'}\n",
      "\n",
      "輸入: {'text': '人很奇怪有時候很想找人聊天有時候又想安安靜靜的沉浸在自己的世界'}\n",
      "輸出: {'label': 0, 'explination': '這則貼文表達的是個人情感與日常心情分享，並無任何誘導性或詐騙特徵，屬於普通的社交貼文。'}\n",
      "\n",
      "輸入: {'text': '能徵友文脆友單身來認識一下桃園新竹都能接受異地我83年次16053但希望有人追蹤我相互瞭解salutingface希望餘生有幸能多多指教要聊天哀居密我回覆喲facewithpeekingeye'}\n",
      "輸出: {'label': 1, 'explination': '貼文以交友為名吸引目標，要求私訊追蹤，但內容缺乏真實性且帶有潛在誘導性，可能涉及交友詐騙或其他不當行為。'}\n",
      "\n",
      "輸入: {'text': '台股今天繼續漲chartincreasing但是櫃買就沒這麼好BBU族群全面重挫是否拉回找買點船和飛機表現不錯但是AI軟體股更亮眼IC設計今天也是有點意思接著該怎麼做盤面好像一堆主流又好像沒有主流誰是真的誰是假的讓我們繼續看下去還好我的股都是紅的但一樣做了點調整股票投資'}\n",
      "輸出: {'label': 0, 'explination': '貼文分享的是股市的分析與個人觀點，並未提供誇張的獲利承諾或誘導性訊息，屬於普通的投資討論內容。'}\n",
      "\n",
      "輸入: {'text': '本週下車獲利情況分享順達86萬濱川30萬世紀100萬神準50萬命運的齒輪再次轉動財富自由之路正式開啟今日推薦股票上升趨勢明顯近期量增是平日的34倍噴發概率提升明日開盤即可買入近幾日推薦的股票脆友們都有上車連漲一週開始小有獲利明日開盤想要一起上車的看下面留言backhandindexpointingdown'}\n",
      "輸出: {'label': 1, 'explination': '貼文誇大了股票投資的高額獲利並以誘導性語句吸引人留言或參與，這是常見的投資詐騙手法，試圖吸引目標進一步互動或購買服務。'}\n",
      "\n",
      "輸入: {'text': '有打就錄，是說這裡已經變停車場了😮\\u200d💨\\n大叔籃球'}\n",
      "輸出: {'label': 0, 'explination': '貼文是對籃球場地現況的輕鬆吐槽，屬於普通的生活分享內容，並無任何詐騙特徵或誘導性。'}\n",
      "\n",
      "輸入: {'text': '八方雲集為什麼要放抖音慢搖，聽到天花板一直咚咚咚，我都覺得我的鍋貼在搖花手。'}\n",
      "輸出: {'label': 0, 'explination': '貼文幽默地抱怨用餐環境的背景音樂，屬於日常生活經驗分享，並無詐騙或誘導性內容。'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "instruction = f'''\n",
    "你是一個貼文審查專家，你的任務是判斷給定的貼文是否為詐騙，\n",
    "你只能根據輸入內容生成以下格式的單個 JSON：\n",
    "{{\n",
    "    \"text\": \"<貼文內容>\",\n",
    "    \"label\": \"<標記結果 (0 或 1)>\",\n",
    "    \"explination\": \"<標記理由>\"\n",
    "}}\n",
    "除了上述 JSON 結果，請勿生成任何其他內容。\n",
    "輸入輸出參考以下範例:\n",
    "輸入: {example_input[0]}\n",
    "輸出: {example_output[0]}\n",
    "\n",
    "輸入: {example_input[1]}\n",
    "輸出: {example_output[1]}\n",
    "\n",
    "輸入: {example_input[2]}\n",
    "輸出: {example_output[2]}\n",
    "\n",
    "輸入: {example_input[3]}\n",
    "輸出: {example_output[3]}\n",
    "\n",
    "輸入: {example_input[4]}\n",
    "輸出: {example_output[4]}\n",
    "\n",
    "輸入: {example_input[5]}\n",
    "輸出: {example_output[5]}\n",
    "\n",
    "輸入: {example_input[6]}\n",
    "輸出: {example_output[6]}\n",
    "\n",
    "輸入: {example_input[7]}\n",
    "輸出: {example_output[7]}\n",
    "\n",
    "'''\n",
    "sys = f'''{instruction}'''\n",
    "print(sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline(\n",
    "    model=model, \n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    device='cuda:1',\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_prompt(datapoint):\n",
    "    text = datapoint['text']\n",
    "    query = f'輸入: {{\"text\": \"{text}\"}}'\n",
    "    message = [\n",
    "        {\"role\": \"system\", \"content\": sys},\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        message,\n",
    "        tokenize=False,\n",
    "        max_new_tokens=128,\n",
    "        min_new_tokens=64\n",
    "    )\n",
    "    if prompt is None:\n",
    "        raise ValueError(f\"Prompt generation failed for text: {text}\")\n",
    "    datapoint['prompt'] = prompt\n",
    "    return datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 10. Reducing num_proc to 10 for dataset of size 10.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456ca07ecbaa46b69016768716b5791c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=10):   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'category', 'prompt'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataset = train_dataset.map(prepare_prompt, batched=False, num_proc=32)\n",
    "dataloader = DataLoader(train_dataset, batch_size=16, shuffle=False)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:16<00:00, 16.55s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "result_dataset = {\n",
    "    'text': [],\n",
    "    'output': [],\n",
    "}\n",
    "\n",
    "for batch in tqdm(dataloader):\n",
    "    prompts = batch['prompt'] \n",
    "    texts = batch['text']   \n",
    "    \n",
    "    outputs = generator(\n",
    "        prompts, \n",
    "        max_new_tokens=64, \n",
    "        min_new_tokens=32,\n",
    "        stop_strings=\"}\",\n",
    "        tokenizer = tokenizer,\n",
    "        return_full_text=False,\n",
    "    )\n",
    "    \n",
    "    result_dataset['text'].extend(texts)\n",
    "    result_dataset['output'].extend(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_dataset['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(result_dataset).to_csv('dataset1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>流量密碼</td>\n",
       "      <td>[{'generated_text': \"輸出：{'label': 0, 'explinat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19歲知道男友手機密碼很有安全感29歲戶頭有200萬很有安全感</td>\n",
       "      <td>[{'generated_text': '輸出：\\n{\\n\"label\": 1,\\n\"exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>好像是欸昌董的車是流量密碼thumbsup</td>\n",
       "      <td>[{'generated_text': '我這邊就是把輸入的JSON格式的字典，對輸入的「t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>例如什麼讓我側耳傾聽redheart流量密碼在哪裡</td>\n",
       "      <td>[{'generated_text': \"輸出：{'label': 1, 'explinat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>查崗手機拿來洛燁漫不經心地將手機放在他手心上密碼我生日算了我挺相信你的說罷便將手機還給了他你...</td>\n",
       "      <td>[{'generated_text': \"輸出：\\n{'label': 0, 'explin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15842</th>\n",
       "      <td>好好工作賺錢吧</td>\n",
       "      <td>[{'generated_text': '這個輸入沒有形成一個有效的問題，因此無法根據該輸入...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15843</th>\n",
       "      <td>國一大安高工or長庚護專回頭看覺得國一志願設這兩個超不適合自己國二大安高工師大附中許願讀的高...</td>\n",
       "      <td>[{'generated_text': '輸出：\\n{\\n\"label\": 0,\\n\"exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15844</th>\n",
       "      <td>中粉都不用賺錢不用上班嗎</td>\n",
       "      <td>[{'generated_text': \"輸出: {'label': 1, 'explina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15845</th>\n",
       "      <td>原來可是我也疑惑嫌犯偷到手機怎麼沒登入哈哈</td>\n",
       "      <td>[{'generated_text': \"輸出：{'label': 0, 'explinat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15846</th>\n",
       "      <td>因為學賺錢不是學校教育的目的探索自己找到興趣做個對社會有貢獻的人比較重要</td>\n",
       "      <td>[{'generated_text': '這個貼文的標記結果為何？\\n輸出:\\n{\\n\"la...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15847 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0                                                   流量密碼   \n",
       "1                        19歲知道男友手機密碼很有安全感29歲戶頭有200萬很有安全感   \n",
       "2                                  好像是欸昌董的車是流量密碼thumbsup   \n",
       "3                              例如什麼讓我側耳傾聽redheart流量密碼在哪裡   \n",
       "4      查崗手機拿來洛燁漫不經心地將手機放在他手心上密碼我生日算了我挺相信你的說罷便將手機還給了他你...   \n",
       "...                                                  ...   \n",
       "15842                                            好好工作賺錢吧   \n",
       "15843  國一大安高工or長庚護專回頭看覺得國一志願設這兩個超不適合自己國二大安高工師大附中許願讀的高...   \n",
       "15844                                       中粉都不用賺錢不用上班嗎   \n",
       "15845                              原來可是我也疑惑嫌犯偷到手機怎麼沒登入哈哈   \n",
       "15846               因為學賺錢不是學校教育的目的探索自己找到興趣做個對社會有貢獻的人比較重要   \n",
       "\n",
       "                                                  output  \n",
       "0      [{'generated_text': \"輸出：{'label': 0, 'explinat...  \n",
       "1      [{'generated_text': '輸出：\\n{\\n\"label\": 1,\\n\"exp...  \n",
       "2      [{'generated_text': '我這邊就是把輸入的JSON格式的字典，對輸入的「t...  \n",
       "3      [{'generated_text': \"輸出：{'label': 1, 'explinat...  \n",
       "4      [{'generated_text': \"輸出：\\n{'label': 0, 'explin...  \n",
       "...                                                  ...  \n",
       "15842  [{'generated_text': '這個輸入沒有形成一個有效的問題，因此無法根據該輸入...  \n",
       "15843  [{'generated_text': '輸出：\\n{\\n\"label\": 0,\\n\"exp...  \n",
       "15844  [{'generated_text': \"輸出: {'label': 1, 'explina...  \n",
       "15845  [{'generated_text': \"輸出：{'label': 0, 'explinat...  \n",
       "15846  [{'generated_text': '這個貼文的標記結果為何？\\n輸出:\\n{\\n\"la...  \n",
       "\n",
       "[15847 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "labeled_data = pd.read_csv('dataset.csv').drop(['Unnamed: 0'], axis=1)\n",
    "labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_label(output):\n",
    "    label_pattern = r\"(label.*(1|0).*,)\"\n",
    "    match = re.search(label_pattern, output)\n",
    "    return int(match.group(2))\n",
    "def get_explination(output):\n",
    "    label_pattern = r\"(explination.*:([^}\\\"]*))\"\n",
    "    match = re.search(label_pattern, output)\n",
    "    return match.group(2).strip().replace(\"'\",'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "success_extract = []\n",
    "failed_extract = []\n",
    "for text, output in zip(labeled_data['text'], labeled_data['output']):\n",
    "    try:\n",
    "        label = get_label(output)\n",
    "        explination = get_explination(output)\n",
    "        success_extract.append({\n",
    "            \"text\": text,\n",
    "            \"label\": label,\n",
    "            \"explination\": explination\n",
    "        })\n",
    "    except:\n",
    "        failed_extract.append({\n",
    "            \"text\": text,\n",
    "            \"output\": output\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# output_path = Path('./dataset/training.json')\n",
    "# with output_path.open('w', encoding='utf-8') as f:\n",
    "#     json.dump(success_extract, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
