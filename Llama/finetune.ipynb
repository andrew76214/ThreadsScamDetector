{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import yaml\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "# with open(\"config.yaml\", \"r\") as file:\n",
    "#     hp = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 10808\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2702\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_json(\"dataset/training.json\").drop(['explination'], axis = 1)\n",
    "dataset = Dataset.from_pandas(dataset).train_test_split(test_size=0.2)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb863c614d34b8baf0d924daf3b82f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at taide/Llama3-TAIDE-LX-8B-Chat-Alpha1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig, AutoModelForSequenceClassification\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "import torch\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True, \n",
    "    bnb_4bit_quant_type = 'nf4',\n",
    "    bnb_4bit_use_double_quant = True, \n",
    "    bnb_4bit_compute_dtype = torch.float16 \n",
    ")\n",
    "model_name = 'taide/Llama3-TAIDE-LX-8B-Chat-Alpha1'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quantization_config,\n",
    "    num_labels=2,\n",
    "    device_map='auto',\n",
    "    cache_dir = '/HDD/model_cache'\n",
    ")\n",
    "lora_config = LoraConfig(\n",
    "    r = 4, \n",
    "    lora_alpha = 8,\n",
    "    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n",
    "    lora_dropout = 0.1, \n",
    "    bias = 'none',\n",
    "    task_type = 'SEQ_CLS'\n",
    ")\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8be4ad75fc465aa09c9388f9986d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10808 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069a97ded4a7461397bc19139ab94ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2702 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 10808\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2702\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_preprocesing(row):\n",
    "    return tokenizer(row['text'], truncation=True, max_length=512)\n",
    "\n",
    "tokenized_data = dataset.map(data_preprocesing, batched=True, \n",
    "remove_columns=['text'])\n",
    "tokenized_data.set_format(\"torch\")\n",
    "tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return f1_metric.compute(predictions=predictions, references=labels, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = 'checkpoint',\n",
    "    learning_rate = 1e-4,\n",
    "    per_device_train_batch_size = 32,\n",
    "    per_device_eval_batch_size = 32,\n",
    "    max_steps = 1000,\n",
    "    logging_steps = 1,\n",
    "    weight_decay = 0.01,\n",
    "    eval_strategy = 'steps',\n",
    "    save_strategy = 'steps',\n",
    "    eval_steps = 200,\n",
    "    save_steps = 200,\n",
    "    warmup_steps=100,\n",
    "    load_best_model_at_end = True,\n",
    "    report_to=\"none\",\n",
    "    optim=\"adamw_torch\"\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data['train'],\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer, padding=True),\n",
    "    eval_dataset=tokenized_data['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637595c3fe2446e6b4528d9ccd20ba46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/HDD/anaconda3/envs/AIS/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/HDD/anaconda3/envs/AIS/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6735, 'grad_norm': 22.211551666259766, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}\n",
      "{'loss': 1.2963, 'grad_norm': 19.946990966796875, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.01}\n",
      "{'loss': 1.8183, 'grad_norm': 20.949831008911133, 'learning_rate': 3e-06, 'epoch': 0.01}\n",
      "{'loss': 1.2384, 'grad_norm': 18.321680068969727, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.01}\n",
      "{'loss': 1.9452, 'grad_norm': 23.996442794799805, 'learning_rate': 5e-06, 'epoch': 0.01}\n",
      "{'loss': 1.3556, 'grad_norm': 20.176342010498047, 'learning_rate': 6e-06, 'epoch': 0.02}\n",
      "{'loss': 1.7919, 'grad_norm': 27.254220962524414, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.02}\n",
      "{'loss': 1.5388, 'grad_norm': 22.652318954467773, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.02}\n",
      "{'loss': 1.0209, 'grad_norm': 17.912622451782227, 'learning_rate': 9e-06, 'epoch': 0.03}\n",
      "{'loss': 1.5022, 'grad_norm': 22.779104232788086, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 2.6335, 'grad_norm': 29.530105590820312, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.03}\n",
      "{'loss': 1.3532, 'grad_norm': 18.57292366027832, 'learning_rate': 1.2e-05, 'epoch': 0.04}\n",
      "{'loss': 1.3605, 'grad_norm': 21.671531677246094, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.04}\n",
      "{'loss': 1.516, 'grad_norm': 22.636213302612305, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.04}\n",
      "{'loss': 2.0729, 'grad_norm': 22.407745361328125, 'learning_rate': 1.5e-05, 'epoch': 0.04}\n",
      "{'loss': 1.7764, 'grad_norm': 21.301959991455078, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.05}\n",
      "{'loss': 1.0455, 'grad_norm': 17.435413360595703, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.05}\n",
      "{'loss': 1.3484, 'grad_norm': 20.443613052368164, 'learning_rate': 1.8e-05, 'epoch': 0.05}\n",
      "{'loss': 1.3439, 'grad_norm': 25.654754638671875, 'learning_rate': 1.9e-05, 'epoch': 0.06}\n",
      "{'loss': 1.5458, 'grad_norm': 28.777830123901367, 'learning_rate': 2e-05, 'epoch': 0.06}\n",
      "{'loss': 1.2278, 'grad_norm': 18.995643615722656, 'learning_rate': 2.1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.1045, 'grad_norm': 25.51059341430664, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.07}\n",
      "{'loss': 1.1367, 'grad_norm': 20.80504035949707, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.07}\n",
      "{'loss': 1.7458, 'grad_norm': 21.4252872467041, 'learning_rate': 2.4e-05, 'epoch': 0.07}\n",
      "{'loss': 1.1004, 'grad_norm': 23.98760223388672, 'learning_rate': 2.5e-05, 'epoch': 0.07}\n",
      "{'loss': 1.1186, 'grad_norm': 17.599119186401367, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.08}\n",
      "{'loss': 1.5443, 'grad_norm': 27.01323890686035, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.08}\n",
      "{'loss': 1.3778, 'grad_norm': 25.94693374633789, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8398, 'grad_norm': 29.232376098632812, 'learning_rate': 2.9e-05, 'epoch': 0.09}\n",
      "{'loss': 0.9086, 'grad_norm': 19.6041259765625, 'learning_rate': 3e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8603, 'grad_norm': 23.36215591430664, 'learning_rate': 3.1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.4295, 'grad_norm': 18.98417854309082, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.09}\n",
      "{'loss': 1.2906, 'grad_norm': 20.325035095214844, 'learning_rate': 3.3e-05, 'epoch': 0.1}\n",
      "{'loss': 1.4475, 'grad_norm': 24.27019500732422, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.1}\n",
      "{'loss': 0.7369, 'grad_norm': 18.53763198852539, 'learning_rate': 3.5e-05, 'epoch': 0.1}\n",
      "{'loss': 1.1613, 'grad_norm': 18.129043579101562, 'learning_rate': 3.6e-05, 'epoch': 0.11}\n",
      "{'loss': 1.1012, 'grad_norm': 15.548529624938965, 'learning_rate': 3.7e-05, 'epoch': 0.11}\n",
      "{'loss': 1.6159, 'grad_norm': 23.43958282470703, 'learning_rate': 3.8e-05, 'epoch': 0.11}\n",
      "{'loss': 0.9485, 'grad_norm': 19.240970611572266, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.12}\n",
      "{'loss': 1.0693, 'grad_norm': 16.861215591430664, 'learning_rate': 4e-05, 'epoch': 0.12}\n",
      "{'loss': 0.8909, 'grad_norm': 16.941072463989258, 'learning_rate': 4.1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.8439, 'grad_norm': 24.06138801574707, 'learning_rate': 4.2e-05, 'epoch': 0.12}\n",
      "{'loss': 1.1475, 'grad_norm': 19.757593154907227, 'learning_rate': 4.3e-05, 'epoch': 0.13}\n",
      "{'loss': 1.5156, 'grad_norm': 30.788692474365234, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.13}\n",
      "{'loss': 0.6413, 'grad_norm': 14.794995307922363, 'learning_rate': 4.5e-05, 'epoch': 0.13}\n",
      "{'loss': 1.2037, 'grad_norm': 18.796207427978516, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.14}\n",
      "{'loss': 1.1197, 'grad_norm': 24.351428985595703, 'learning_rate': 4.7e-05, 'epoch': 0.14}\n",
      "{'loss': 1.2537, 'grad_norm': 20.290790557861328, 'learning_rate': 4.8e-05, 'epoch': 0.14}\n",
      "{'loss': 1.1177, 'grad_norm': 24.410911560058594, 'learning_rate': 4.9e-05, 'epoch': 0.14}\n",
      "{'loss': 0.9163, 'grad_norm': 20.79570198059082, 'learning_rate': 5e-05, 'epoch': 0.15}\n",
      "{'loss': 0.9187, 'grad_norm': 24.700439453125, 'learning_rate': 5.1000000000000006e-05, 'epoch': 0.15}\n",
      "{'loss': 1.197, 'grad_norm': 19.485570907592773, 'learning_rate': 5.2000000000000004e-05, 'epoch': 0.15}\n",
      "{'loss': 1.293, 'grad_norm': 30.692367553710938, 'learning_rate': 5.300000000000001e-05, 'epoch': 0.16}\n",
      "{'loss': 0.7055, 'grad_norm': 17.232152938842773, 'learning_rate': 5.4000000000000005e-05, 'epoch': 0.16}\n",
      "{'loss': 1.0984, 'grad_norm': 21.816360473632812, 'learning_rate': 5.500000000000001e-05, 'epoch': 0.16}\n",
      "{'loss': 0.9479, 'grad_norm': 15.32544231414795, 'learning_rate': 5.6000000000000006e-05, 'epoch': 0.17}\n",
      "{'loss': 1.2808, 'grad_norm': 22.224931716918945, 'learning_rate': 5.6999999999999996e-05, 'epoch': 0.17}\n",
      "{'loss': 1.1391, 'grad_norm': 18.67548179626465, 'learning_rate': 5.8e-05, 'epoch': 0.17}\n",
      "{'loss': 0.878, 'grad_norm': 18.52233123779297, 'learning_rate': 5.9e-05, 'epoch': 0.17}\n",
      "{'loss': 1.3118, 'grad_norm': 16.925508499145508, 'learning_rate': 6e-05, 'epoch': 0.18}\n",
      "{'loss': 0.7838, 'grad_norm': 15.353885650634766, 'learning_rate': 6.1e-05, 'epoch': 0.18}\n",
      "{'loss': 0.9563, 'grad_norm': 17.41800308227539, 'learning_rate': 6.2e-05, 'epoch': 0.18}\n",
      "{'loss': 0.7768, 'grad_norm': 18.179994583129883, 'learning_rate': 6.3e-05, 'epoch': 0.19}\n",
      "{'loss': 1.0529, 'grad_norm': 19.926254272460938, 'learning_rate': 6.400000000000001e-05, 'epoch': 0.19}\n",
      "{'loss': 0.9665, 'grad_norm': 16.522979736328125, 'learning_rate': 6.500000000000001e-05, 'epoch': 0.19}\n",
      "{'loss': 1.0782, 'grad_norm': 18.258800506591797, 'learning_rate': 6.6e-05, 'epoch': 0.2}\n",
      "{'loss': 1.2585, 'grad_norm': 22.63654899597168, 'learning_rate': 6.7e-05, 'epoch': 0.2}\n",
      "{'loss': 1.1335, 'grad_norm': 17.430761337280273, 'learning_rate': 6.800000000000001e-05, 'epoch': 0.2}\n",
      "{'loss': 0.8308, 'grad_norm': 15.307483673095703, 'learning_rate': 6.9e-05, 'epoch': 0.2}\n",
      "{'loss': 0.5027, 'grad_norm': 13.269716262817383, 'learning_rate': 7e-05, 'epoch': 0.21}\n",
      "{'loss': 1.3314, 'grad_norm': 20.85302734375, 'learning_rate': 7.1e-05, 'epoch': 0.21}\n",
      "{'loss': 0.6612, 'grad_norm': 17.873809814453125, 'learning_rate': 7.2e-05, 'epoch': 0.21}\n",
      "{'loss': 0.7947, 'grad_norm': 21.420974731445312, 'learning_rate': 7.3e-05, 'epoch': 0.22}\n",
      "{'loss': 0.7815, 'grad_norm': 21.614524841308594, 'learning_rate': 7.4e-05, 'epoch': 0.22}\n",
      "{'loss': 0.9414, 'grad_norm': 16.690961837768555, 'learning_rate': 7.500000000000001e-05, 'epoch': 0.22}\n",
      "{'loss': 0.6152, 'grad_norm': 16.16910171508789, 'learning_rate': 7.6e-05, 'epoch': 0.22}\n",
      "{'loss': 1.0507, 'grad_norm': 21.209314346313477, 'learning_rate': 7.7e-05, 'epoch': 0.23}\n",
      "{'loss': 0.6176, 'grad_norm': 11.525507926940918, 'learning_rate': 7.800000000000001e-05, 'epoch': 0.23}\n",
      "{'loss': 0.9928, 'grad_norm': 23.681154251098633, 'learning_rate': 7.900000000000001e-05, 'epoch': 0.23}\n",
      "{'loss': 0.7468, 'grad_norm': 20.04336929321289, 'learning_rate': 8e-05, 'epoch': 0.24}\n",
      "{'loss': 1.2386, 'grad_norm': 37.32530975341797, 'learning_rate': 8.1e-05, 'epoch': 0.24}\n",
      "{'loss': 0.7531, 'grad_norm': 19.799724578857422, 'learning_rate': 8.2e-05, 'epoch': 0.24}\n",
      "{'loss': 0.9375, 'grad_norm': 19.94658851623535, 'learning_rate': 8.3e-05, 'epoch': 0.25}\n",
      "{'loss': 1.0127, 'grad_norm': 26.672332763671875, 'learning_rate': 8.4e-05, 'epoch': 0.25}\n",
      "{'loss': 1.4593, 'grad_norm': 53.115074157714844, 'learning_rate': 8.5e-05, 'epoch': 0.25}\n",
      "{'loss': 1.0116, 'grad_norm': 25.3491153717041, 'learning_rate': 8.6e-05, 'epoch': 0.25}\n",
      "{'loss': 0.7513, 'grad_norm': 28.927919387817383, 'learning_rate': 8.7e-05, 'epoch': 0.26}\n",
      "{'loss': 0.6248, 'grad_norm': 18.790910720825195, 'learning_rate': 8.800000000000001e-05, 'epoch': 0.26}\n",
      "{'loss': 0.9155, 'grad_norm': 38.06151580810547, 'learning_rate': 8.900000000000001e-05, 'epoch': 0.26}\n",
      "{'loss': 0.6053, 'grad_norm': 15.489053726196289, 'learning_rate': 9e-05, 'epoch': 0.27}\n",
      "{'loss': 0.8576, 'grad_norm': 17.379257202148438, 'learning_rate': 9.1e-05, 'epoch': 0.27}\n",
      "{'loss': 0.6041, 'grad_norm': 14.758151054382324, 'learning_rate': 9.200000000000001e-05, 'epoch': 0.27}\n",
      "{'loss': 0.9659, 'grad_norm': 23.219106674194336, 'learning_rate': 9.300000000000001e-05, 'epoch': 0.28}\n",
      "{'loss': 0.5852, 'grad_norm': 13.20745849609375, 'learning_rate': 9.4e-05, 'epoch': 0.28}\n",
      "{'loss': 0.8948, 'grad_norm': 24.193273544311523, 'learning_rate': 9.5e-05, 'epoch': 0.28}\n",
      "{'loss': 0.6138, 'grad_norm': 10.973201751708984, 'learning_rate': 9.6e-05, 'epoch': 0.28}\n",
      "{'loss': 0.9486, 'grad_norm': 16.370216369628906, 'learning_rate': 9.7e-05, 'epoch': 0.29}\n",
      "{'loss': 0.7025, 'grad_norm': 14.524144172668457, 'learning_rate': 9.8e-05, 'epoch': 0.29}\n",
      "{'loss': 0.6587, 'grad_norm': 10.698314666748047, 'learning_rate': 9.900000000000001e-05, 'epoch': 0.29}\n",
      "{'loss': 1.0624, 'grad_norm': 16.60822296142578, 'learning_rate': 0.0001, 'epoch': 0.3}\n",
      "{'loss': 0.5732, 'grad_norm': 15.696709632873535, 'learning_rate': 9.98888888888889e-05, 'epoch': 0.3}\n",
      "{'loss': 0.388, 'grad_norm': 11.082806587219238, 'learning_rate': 9.977777777777779e-05, 'epoch': 0.3}\n",
      "{'loss': 0.6328, 'grad_norm': 20.646385192871094, 'learning_rate': 9.966666666666667e-05, 'epoch': 0.3}\n",
      "{'loss': 0.5383, 'grad_norm': 28.180387496948242, 'learning_rate': 9.955555555555556e-05, 'epoch': 0.31}\n",
      "{'loss': 0.6869, 'grad_norm': 14.106657981872559, 'learning_rate': 9.944444444444446e-05, 'epoch': 0.31}\n",
      "{'loss': 0.4357, 'grad_norm': 13.143486976623535, 'learning_rate': 9.933333333333334e-05, 'epoch': 0.31}\n",
      "{'loss': 0.3811, 'grad_norm': 16.687437057495117, 'learning_rate': 9.922222222222222e-05, 'epoch': 0.32}\n",
      "{'loss': 0.6142, 'grad_norm': 25.845239639282227, 'learning_rate': 9.911111111111112e-05, 'epoch': 0.32}\n",
      "{'loss': 0.4901, 'grad_norm': 21.949872970581055, 'learning_rate': 9.900000000000001e-05, 'epoch': 0.32}\n",
      "{'loss': 0.6421, 'grad_norm': 13.931879997253418, 'learning_rate': 9.888888888888889e-05, 'epoch': 0.33}\n",
      "{'loss': 0.4593, 'grad_norm': 12.752617835998535, 'learning_rate': 9.877777777777778e-05, 'epoch': 0.33}\n",
      "{'loss': 0.5402, 'grad_norm': 11.336732864379883, 'learning_rate': 9.866666666666668e-05, 'epoch': 0.33}\n",
      "{'loss': 0.5017, 'grad_norm': 32.26960754394531, 'learning_rate': 9.855555555555556e-05, 'epoch': 0.33}\n",
      "{'loss': 0.4549, 'grad_norm': 11.166725158691406, 'learning_rate': 9.844444444444444e-05, 'epoch': 0.34}\n",
      "{'loss': 0.4214, 'grad_norm': 28.836929321289062, 'learning_rate': 9.833333333333333e-05, 'epoch': 0.34}\n",
      "{'loss': 0.5038, 'grad_norm': 31.149211883544922, 'learning_rate': 9.822222222222223e-05, 'epoch': 0.34}\n",
      "{'loss': 0.4769, 'grad_norm': 24.650968551635742, 'learning_rate': 9.811111111111113e-05, 'epoch': 0.35}\n",
      "{'loss': 0.492, 'grad_norm': 14.88450813293457, 'learning_rate': 9.8e-05, 'epoch': 0.35}\n",
      "{'loss': 0.4342, 'grad_norm': 8.363090515136719, 'learning_rate': 9.78888888888889e-05, 'epoch': 0.35}\n",
      "{'loss': 0.6927, 'grad_norm': 31.36142349243164, 'learning_rate': 9.777777777777778e-05, 'epoch': 0.36}\n",
      "{'loss': 0.4253, 'grad_norm': 8.790650367736816, 'learning_rate': 9.766666666666668e-05, 'epoch': 0.36}\n",
      "{'loss': 0.4725, 'grad_norm': 30.125890731811523, 'learning_rate': 9.755555555555555e-05, 'epoch': 0.36}\n",
      "{'loss': 0.6265, 'grad_norm': 17.188201904296875, 'learning_rate': 9.744444444444445e-05, 'epoch': 0.36}\n",
      "{'loss': 0.3663, 'grad_norm': 7.2083563804626465, 'learning_rate': 9.733333333333335e-05, 'epoch': 0.37}\n",
      "{'loss': 0.5519, 'grad_norm': 39.987709045410156, 'learning_rate': 9.722222222222223e-05, 'epoch': 0.37}\n",
      "{'loss': 0.6846, 'grad_norm': 31.758316040039062, 'learning_rate': 9.711111111111111e-05, 'epoch': 0.37}\n",
      "{'loss': 0.4455, 'grad_norm': 19.05049705505371, 'learning_rate': 9.7e-05, 'epoch': 0.38}\n",
      "{'loss': 0.3256, 'grad_norm': 6.818401336669922, 'learning_rate': 9.68888888888889e-05, 'epoch': 0.38}\n",
      "{'loss': 0.4206, 'grad_norm': 10.47630500793457, 'learning_rate': 9.677777777777778e-05, 'epoch': 0.38}\n",
      "{'loss': 0.5055, 'grad_norm': 9.832338333129883, 'learning_rate': 9.666666666666667e-05, 'epoch': 0.38}\n",
      "{'loss': 0.3823, 'grad_norm': 11.309091567993164, 'learning_rate': 9.655555555555555e-05, 'epoch': 0.39}\n",
      "{'loss': 0.6417, 'grad_norm': 20.557687759399414, 'learning_rate': 9.644444444444445e-05, 'epoch': 0.39}\n",
      "{'loss': 0.2983, 'grad_norm': 15.629961013793945, 'learning_rate': 9.633333333333335e-05, 'epoch': 0.39}\n",
      "{'loss': 0.721, 'grad_norm': 10.222354888916016, 'learning_rate': 9.622222222222222e-05, 'epoch': 0.4}\n",
      "{'loss': 0.6283, 'grad_norm': 32.20022201538086, 'learning_rate': 9.611111111111112e-05, 'epoch': 0.4}\n",
      "{'loss': 0.5504, 'grad_norm': 30.180450439453125, 'learning_rate': 9.6e-05, 'epoch': 0.4}\n",
      "{'loss': 0.3877, 'grad_norm': 23.83266258239746, 'learning_rate': 9.58888888888889e-05, 'epoch': 0.41}\n",
      "{'loss': 0.3869, 'grad_norm': 15.429587364196777, 'learning_rate': 9.577777777777777e-05, 'epoch': 0.41}\n",
      "{'loss': 0.3535, 'grad_norm': 5.273977756500244, 'learning_rate': 9.566666666666667e-05, 'epoch': 0.41}\n",
      "{'loss': 0.4291, 'grad_norm': 24.357446670532227, 'learning_rate': 9.555555555555557e-05, 'epoch': 0.41}\n",
      "{'loss': 0.4733, 'grad_norm': 20.22315216064453, 'learning_rate': 9.544444444444445e-05, 'epoch': 0.42}\n",
      "{'loss': 0.4394, 'grad_norm': 33.871490478515625, 'learning_rate': 9.533333333333334e-05, 'epoch': 0.42}\n",
      "{'loss': 0.4195, 'grad_norm': 7.766560077667236, 'learning_rate': 9.522222222222222e-05, 'epoch': 0.42}\n",
      "{'loss': 0.315, 'grad_norm': 7.853053569793701, 'learning_rate': 9.511111111111112e-05, 'epoch': 0.43}\n",
      "{'loss': 0.5545, 'grad_norm': 21.383710861206055, 'learning_rate': 9.5e-05, 'epoch': 0.43}\n",
      "{'loss': 0.383, 'grad_norm': 11.753957748413086, 'learning_rate': 9.488888888888889e-05, 'epoch': 0.43}\n",
      "{'loss': 0.4816, 'grad_norm': 22.34054946899414, 'learning_rate': 9.477777777777779e-05, 'epoch': 0.43}\n",
      "{'loss': 0.6292, 'grad_norm': 22.194137573242188, 'learning_rate': 9.466666666666667e-05, 'epoch': 0.44}\n",
      "{'loss': 0.2713, 'grad_norm': 20.33242416381836, 'learning_rate': 9.455555555555556e-05, 'epoch': 0.44}\n",
      "{'loss': 0.4112, 'grad_norm': 10.733471870422363, 'learning_rate': 9.444444444444444e-05, 'epoch': 0.44}\n",
      "{'loss': 0.4243, 'grad_norm': 6.591946125030518, 'learning_rate': 9.433333333333334e-05, 'epoch': 0.45}\n",
      "{'loss': 0.3678, 'grad_norm': 9.391668319702148, 'learning_rate': 9.422222222222223e-05, 'epoch': 0.45}\n",
      "{'loss': 0.4326, 'grad_norm': 23.510379791259766, 'learning_rate': 9.411111111111111e-05, 'epoch': 0.45}\n",
      "{'loss': 0.5688, 'grad_norm': 13.939745903015137, 'learning_rate': 9.4e-05, 'epoch': 0.46}\n",
      "{'loss': 0.4655, 'grad_norm': 14.26662540435791, 'learning_rate': 9.388888888888889e-05, 'epoch': 0.46}\n",
      "{'loss': 0.4001, 'grad_norm': 12.841784477233887, 'learning_rate': 9.377777777777779e-05, 'epoch': 0.46}\n",
      "{'loss': 0.5152, 'grad_norm': 8.023334503173828, 'learning_rate': 9.366666666666668e-05, 'epoch': 0.46}\n",
      "{'loss': 0.6559, 'grad_norm': 19.76276206970215, 'learning_rate': 9.355555555555556e-05, 'epoch': 0.47}\n",
      "{'loss': 0.2462, 'grad_norm': 12.521737098693848, 'learning_rate': 9.344444444444444e-05, 'epoch': 0.47}\n",
      "{'loss': 0.4537, 'grad_norm': 17.703105926513672, 'learning_rate': 9.333333333333334e-05, 'epoch': 0.47}\n",
      "{'loss': 0.6004, 'grad_norm': 20.93304443359375, 'learning_rate': 9.322222222222223e-05, 'epoch': 0.48}\n",
      "{'loss': 0.2628, 'grad_norm': 10.782471656799316, 'learning_rate': 9.311111111111111e-05, 'epoch': 0.48}\n",
      "{'loss': 0.7735, 'grad_norm': 24.381118774414062, 'learning_rate': 9.300000000000001e-05, 'epoch': 0.48}\n",
      "{'loss': 0.5594, 'grad_norm': 20.181901931762695, 'learning_rate': 9.28888888888889e-05, 'epoch': 0.49}\n",
      "{'loss': 0.4772, 'grad_norm': 18.011245727539062, 'learning_rate': 9.277777777777778e-05, 'epoch': 0.49}\n",
      "{'loss': 0.4543, 'grad_norm': 6.90850305557251, 'learning_rate': 9.266666666666666e-05, 'epoch': 0.49}\n",
      "{'loss': 0.3806, 'grad_norm': 21.99909019470215, 'learning_rate': 9.255555555555556e-05, 'epoch': 0.49}\n",
      "{'loss': 0.294, 'grad_norm': 5.835131645202637, 'learning_rate': 9.244444444444445e-05, 'epoch': 0.5}\n",
      "{'loss': 0.4978, 'grad_norm': 32.58689880371094, 'learning_rate': 9.233333333333333e-05, 'epoch': 0.5}\n",
      "{'loss': 0.4799, 'grad_norm': 29.217491149902344, 'learning_rate': 9.222222222222223e-05, 'epoch': 0.5}\n",
      "{'loss': 0.5496, 'grad_norm': 35.36026382446289, 'learning_rate': 9.211111111111112e-05, 'epoch': 0.51}\n",
      "{'loss': 0.5662, 'grad_norm': 27.973426818847656, 'learning_rate': 9.200000000000001e-05, 'epoch': 0.51}\n",
      "{'loss': 0.421, 'grad_norm': 16.716842651367188, 'learning_rate': 9.188888888888888e-05, 'epoch': 0.51}\n",
      "{'loss': 0.4023, 'grad_norm': 7.501719951629639, 'learning_rate': 9.177777777777778e-05, 'epoch': 0.51}\n",
      "{'loss': 0.4535, 'grad_norm': 21.78666114807129, 'learning_rate': 9.166666666666667e-05, 'epoch': 0.52}\n",
      "{'loss': 0.616, 'grad_norm': 36.32202911376953, 'learning_rate': 9.155555555555557e-05, 'epoch': 0.52}\n",
      "{'loss': 0.5577, 'grad_norm': 35.81504440307617, 'learning_rate': 9.144444444444444e-05, 'epoch': 0.52}\n",
      "{'loss': 0.6143, 'grad_norm': 36.066898345947266, 'learning_rate': 9.133333333333334e-05, 'epoch': 0.53}\n",
      "{'loss': 0.6634, 'grad_norm': 33.43552780151367, 'learning_rate': 9.122222222222223e-05, 'epoch': 0.53}\n",
      "{'loss': 0.4685, 'grad_norm': 26.5207462310791, 'learning_rate': 9.111111111111112e-05, 'epoch': 0.53}\n",
      "{'loss': 0.4676, 'grad_norm': 15.136285781860352, 'learning_rate': 9.1e-05, 'epoch': 0.54}\n",
      "{'loss': 0.4215, 'grad_norm': 11.798226356506348, 'learning_rate': 9.088888888888889e-05, 'epoch': 0.54}\n",
      "{'loss': 0.1811, 'grad_norm': 12.036467552185059, 'learning_rate': 9.077777777777779e-05, 'epoch': 0.54}\n",
      "{'loss': 0.5781, 'grad_norm': 32.27779006958008, 'learning_rate': 9.066666666666667e-05, 'epoch': 0.54}\n",
      "{'loss': 0.2965, 'grad_norm': 17.410367965698242, 'learning_rate': 9.055555555555556e-05, 'epoch': 0.55}\n",
      "{'loss': 0.6038, 'grad_norm': 27.929946899414062, 'learning_rate': 9.044444444444445e-05, 'epoch': 0.55}\n",
      "{'loss': 0.8693, 'grad_norm': 38.81850814819336, 'learning_rate': 9.033333333333334e-05, 'epoch': 0.55}\n",
      "{'loss': 0.3262, 'grad_norm': 18.803653717041016, 'learning_rate': 9.022222222222224e-05, 'epoch': 0.56}\n",
      "{'loss': 0.4137, 'grad_norm': 7.23056697845459, 'learning_rate': 9.011111111111111e-05, 'epoch': 0.56}\n",
      "{'loss': 0.6814, 'grad_norm': 9.727849006652832, 'learning_rate': 9e-05, 'epoch': 0.56}\n",
      "{'loss': 0.3861, 'grad_norm': 6.863548755645752, 'learning_rate': 8.988888888888889e-05, 'epoch': 0.57}\n",
      "{'loss': 0.5775, 'grad_norm': 23.84091567993164, 'learning_rate': 8.977777777777779e-05, 'epoch': 0.57}\n",
      "{'loss': 0.5283, 'grad_norm': 22.692378997802734, 'learning_rate': 8.966666666666666e-05, 'epoch': 0.57}\n",
      "{'loss': 0.5387, 'grad_norm': 12.720211029052734, 'learning_rate': 8.955555555555556e-05, 'epoch': 0.57}\n",
      "{'loss': 0.3875, 'grad_norm': 12.64838981628418, 'learning_rate': 8.944444444444446e-05, 'epoch': 0.58}\n",
      "{'loss': 0.5131, 'grad_norm': 5.657516002655029, 'learning_rate': 8.933333333333334e-05, 'epoch': 0.58}\n",
      "{'loss': 0.5091, 'grad_norm': 10.798750877380371, 'learning_rate': 8.922222222222223e-05, 'epoch': 0.58}\n",
      "{'loss': 0.4082, 'grad_norm': 18.486038208007812, 'learning_rate': 8.911111111111111e-05, 'epoch': 0.59}\n",
      "{'loss': 0.3839, 'grad_norm': 20.06865119934082, 'learning_rate': 8.900000000000001e-05, 'epoch': 0.59}\n",
      "{'loss': 0.5158, 'grad_norm': 37.79427719116211, 'learning_rate': 8.888888888888889e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6950b347a0ef45c69b20b8cae8b63a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.43283793330192566, 'eval_f1': 0.7838638045891931, 'eval_runtime': 846.1197, 'eval_samples_per_second': 3.193, 'eval_steps_per_second': 0.1, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/HDD/anaconda3/envs/AIS/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/HDD/anaconda3/envs/AIS/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3593, 'grad_norm': 14.374088287353516, 'learning_rate': 8.877777777777778e-05, 'epoch': 0.59}\n",
      "{'loss': 0.474, 'grad_norm': 8.691773414611816, 'learning_rate': 8.866666666666668e-05, 'epoch': 0.6}\n",
      "{'loss': 0.5121, 'grad_norm': 9.720526695251465, 'learning_rate': 8.855555555555556e-05, 'epoch': 0.6}\n",
      "{'loss': 0.3244, 'grad_norm': 11.505767822265625, 'learning_rate': 8.844444444444445e-05, 'epoch': 0.6}\n",
      "{'loss': 0.416, 'grad_norm': 15.675796508789062, 'learning_rate': 8.833333333333333e-05, 'epoch': 0.61}\n",
      "{'loss': 0.3911, 'grad_norm': 33.70933532714844, 'learning_rate': 8.822222222222223e-05, 'epoch': 0.61}\n",
      "{'loss': 0.4375, 'grad_norm': 16.429153442382812, 'learning_rate': 8.811111111111111e-05, 'epoch': 0.61}\n",
      "{'loss': 0.307, 'grad_norm': 11.342657089233398, 'learning_rate': 8.800000000000001e-05, 'epoch': 0.62}\n",
      "{'loss': 0.3204, 'grad_norm': 13.880233764648438, 'learning_rate': 8.78888888888889e-05, 'epoch': 0.62}\n",
      "{'loss': 0.3631, 'grad_norm': 7.644885063171387, 'learning_rate': 8.777777777777778e-05, 'epoch': 0.62}\n",
      "{'loss': 0.5335, 'grad_norm': 23.59906768798828, 'learning_rate': 8.766666666666668e-05, 'epoch': 0.62}\n",
      "{'loss': 0.6304, 'grad_norm': 31.84025764465332, 'learning_rate': 8.755555555555556e-05, 'epoch': 0.63}\n",
      "{'loss': 0.8045, 'grad_norm': 58.18147277832031, 'learning_rate': 8.744444444444445e-05, 'epoch': 0.63}\n",
      "{'loss': 0.3758, 'grad_norm': 24.74924087524414, 'learning_rate': 8.733333333333333e-05, 'epoch': 0.63}\n",
      "{'loss': 0.5696, 'grad_norm': 44.420196533203125, 'learning_rate': 8.722222222222223e-05, 'epoch': 0.64}\n",
      "{'loss': 0.326, 'grad_norm': 9.3460054397583, 'learning_rate': 8.711111111111112e-05, 'epoch': 0.64}\n",
      "{'loss': 0.4258, 'grad_norm': 11.52466106414795, 'learning_rate': 8.7e-05, 'epoch': 0.64}\n",
      "{'loss': 0.3109, 'grad_norm': 13.500703811645508, 'learning_rate': 8.68888888888889e-05, 'epoch': 0.64}\n",
      "{'loss': 0.2901, 'grad_norm': 9.882283210754395, 'learning_rate': 8.677777777777778e-05, 'epoch': 0.65}\n",
      "{'loss': 0.6976, 'grad_norm': 36.09031677246094, 'learning_rate': 8.666666666666667e-05, 'epoch': 0.65}\n",
      "{'loss': 0.3748, 'grad_norm': 15.291451454162598, 'learning_rate': 8.655555555555555e-05, 'epoch': 0.65}\n",
      "{'loss': 0.3231, 'grad_norm': 6.638250827789307, 'learning_rate': 8.644444444444445e-05, 'epoch': 0.66}\n",
      "{'loss': 0.5361, 'grad_norm': 11.07454776763916, 'learning_rate': 8.633333333333334e-05, 'epoch': 0.66}\n",
      "{'loss': 0.4138, 'grad_norm': 7.91278600692749, 'learning_rate': 8.622222222222222e-05, 'epoch': 0.66}\n",
      "{'loss': 0.3325, 'grad_norm': 8.201932907104492, 'learning_rate': 8.611111111111112e-05, 'epoch': 0.67}\n",
      "{'loss': 0.2963, 'grad_norm': 13.61376667022705, 'learning_rate': 8.6e-05, 'epoch': 0.67}\n",
      "{'loss': 0.5066, 'grad_norm': 17.478384017944336, 'learning_rate': 8.58888888888889e-05, 'epoch': 0.67}\n",
      "{'loss': 0.2654, 'grad_norm': 4.908803462982178, 'learning_rate': 8.577777777777777e-05, 'epoch': 0.67}\n",
      "{'loss': 0.4429, 'grad_norm': 10.324496269226074, 'learning_rate': 8.566666666666667e-05, 'epoch': 0.68}\n",
      "{'loss': 0.2716, 'grad_norm': 10.123213768005371, 'learning_rate': 8.555555555555556e-05, 'epoch': 0.68}\n",
      "{'loss': 0.668, 'grad_norm': 31.91421890258789, 'learning_rate': 8.544444444444445e-05, 'epoch': 0.68}\n",
      "{'loss': 0.2489, 'grad_norm': 13.177154541015625, 'learning_rate': 8.533333333333334e-05, 'epoch': 0.69}\n",
      "{'loss': 0.338, 'grad_norm': 9.276524543762207, 'learning_rate': 8.522222222222222e-05, 'epoch': 0.69}\n",
      "{'loss': 0.5623, 'grad_norm': 15.532658576965332, 'learning_rate': 8.511111111111112e-05, 'epoch': 0.69}\n",
      "{'loss': 0.3548, 'grad_norm': 18.093793869018555, 'learning_rate': 8.5e-05, 'epoch': 0.7}\n",
      "{'loss': 0.4079, 'grad_norm': 8.278322219848633, 'learning_rate': 8.488888888888889e-05, 'epoch': 0.7}\n",
      "{'loss': 0.2656, 'grad_norm': 13.1012601852417, 'learning_rate': 8.477777777777778e-05, 'epoch': 0.7}\n",
      "{'loss': 0.5166, 'grad_norm': 8.381584167480469, 'learning_rate': 8.466666666666667e-05, 'epoch': 0.7}\n",
      "{'loss': 0.6194, 'grad_norm': 6.770927906036377, 'learning_rate': 8.455555555555556e-05, 'epoch': 0.71}\n",
      "{'loss': 0.2977, 'grad_norm': 17.471881866455078, 'learning_rate': 8.444444444444444e-05, 'epoch': 0.71}\n",
      "{'loss': 0.3984, 'grad_norm': 30.705751419067383, 'learning_rate': 8.433333333333334e-05, 'epoch': 0.71}\n",
      "{'loss': 0.4678, 'grad_norm': 27.73416519165039, 'learning_rate': 8.422222222222223e-05, 'epoch': 0.72}\n",
      "{'loss': 0.3556, 'grad_norm': 8.23481273651123, 'learning_rate': 8.411111111111112e-05, 'epoch': 0.72}\n",
      "{'loss': 0.2993, 'grad_norm': 9.429988861083984, 'learning_rate': 8.4e-05, 'epoch': 0.72}\n",
      "{'loss': 0.3897, 'grad_norm': 6.844078063964844, 'learning_rate': 8.38888888888889e-05, 'epoch': 0.72}\n",
      "{'loss': 0.5398, 'grad_norm': 25.473478317260742, 'learning_rate': 8.377777777777778e-05, 'epoch': 0.73}\n",
      "{'loss': 0.5056, 'grad_norm': 43.07306671142578, 'learning_rate': 8.366666666666668e-05, 'epoch': 0.73}\n",
      "{'loss': 0.7077, 'grad_norm': 50.819087982177734, 'learning_rate': 8.355555555555556e-05, 'epoch': 0.73}\n",
      "{'loss': 0.6541, 'grad_norm': 41.38740158081055, 'learning_rate': 8.344444444444445e-05, 'epoch': 0.74}\n",
      "{'loss': 0.6917, 'grad_norm': 46.83804702758789, 'learning_rate': 8.333333333333334e-05, 'epoch': 0.74}\n",
      "{'loss': 0.4694, 'grad_norm': 31.681720733642578, 'learning_rate': 8.322222222222223e-05, 'epoch': 0.74}\n",
      "{'loss': 0.377, 'grad_norm': 14.877830505371094, 'learning_rate': 8.311111111111111e-05, 'epoch': 0.75}\n",
      "{'loss': 0.2869, 'grad_norm': 5.892602920532227, 'learning_rate': 8.3e-05, 'epoch': 0.75}\n",
      "{'loss': 0.3162, 'grad_norm': 19.865493774414062, 'learning_rate': 8.28888888888889e-05, 'epoch': 0.75}\n",
      "{'loss': 0.322, 'grad_norm': 7.1670145988464355, 'learning_rate': 8.277777777777778e-05, 'epoch': 0.75}\n",
      "{'loss': 0.336, 'grad_norm': 8.36125659942627, 'learning_rate': 8.266666666666667e-05, 'epoch': 0.76}\n",
      "{'loss': 0.5588, 'grad_norm': 37.889652252197266, 'learning_rate': 8.255555555555556e-05, 'epoch': 0.76}\n",
      "{'loss': 0.5063, 'grad_norm': 20.745481491088867, 'learning_rate': 8.244444444444445e-05, 'epoch': 0.76}\n",
      "{'loss': 0.4953, 'grad_norm': 17.770294189453125, 'learning_rate': 8.233333333333333e-05, 'epoch': 0.77}\n",
      "{'loss': 0.3003, 'grad_norm': 15.184377670288086, 'learning_rate': 8.222222222222222e-05, 'epoch': 0.77}\n",
      "{'loss': 0.4701, 'grad_norm': 15.01895809173584, 'learning_rate': 8.211111111111112e-05, 'epoch': 0.77}\n",
      "{'loss': 0.2254, 'grad_norm': 4.763072967529297, 'learning_rate': 8.2e-05, 'epoch': 0.78}\n",
      "{'loss': 0.6261, 'grad_norm': 35.94666290283203, 'learning_rate': 8.18888888888889e-05, 'epoch': 0.78}\n",
      "{'loss': 0.3857, 'grad_norm': 7.581346035003662, 'learning_rate': 8.177777777777778e-05, 'epoch': 0.78}\n",
      "{'loss': 0.5206, 'grad_norm': 43.33891296386719, 'learning_rate': 8.166666666666667e-05, 'epoch': 0.78}\n",
      "{'loss': 0.3561, 'grad_norm': 14.968406677246094, 'learning_rate': 8.155555555555557e-05, 'epoch': 0.79}\n",
      "{'loss': 0.4217, 'grad_norm': 24.65123748779297, 'learning_rate': 8.144444444444445e-05, 'epoch': 0.79}\n",
      "{'loss': 0.3238, 'grad_norm': 10.867180824279785, 'learning_rate': 8.133333333333334e-05, 'epoch': 0.79}\n",
      "{'loss': 0.3297, 'grad_norm': 5.971838474273682, 'learning_rate': 8.122222222222222e-05, 'epoch': 0.8}\n",
      "{'loss': 0.1909, 'grad_norm': 4.690010070800781, 'learning_rate': 8.111111111111112e-05, 'epoch': 0.8}\n",
      "{'loss': 0.3484, 'grad_norm': 14.265203475952148, 'learning_rate': 8.1e-05, 'epoch': 0.8}\n",
      "{'loss': 0.2961, 'grad_norm': 26.064950942993164, 'learning_rate': 8.088888888888889e-05, 'epoch': 0.8}\n",
      "{'loss': 0.1751, 'grad_norm': 7.95871639251709, 'learning_rate': 8.077777777777779e-05, 'epoch': 0.81}\n",
      "{'loss': 0.4187, 'grad_norm': 25.544736862182617, 'learning_rate': 8.066666666666667e-05, 'epoch': 0.81}\n",
      "{'loss': 0.524, 'grad_norm': 36.29960632324219, 'learning_rate': 8.055555555555556e-05, 'epoch': 0.81}\n",
      "{'loss': 0.772, 'grad_norm': 12.219381332397461, 'learning_rate': 8.044444444444444e-05, 'epoch': 0.82}\n",
      "{'loss': 0.4915, 'grad_norm': 5.937285900115967, 'learning_rate': 8.033333333333334e-05, 'epoch': 0.82}\n",
      "{'loss': 0.3394, 'grad_norm': 12.435013771057129, 'learning_rate': 8.022222222222222e-05, 'epoch': 0.82}\n",
      "{'loss': 0.5339, 'grad_norm': 25.520782470703125, 'learning_rate': 8.011111111111111e-05, 'epoch': 0.83}\n",
      "{'loss': 0.3721, 'grad_norm': 9.219657897949219, 'learning_rate': 8e-05, 'epoch': 0.83}\n",
      "{'loss': 0.2984, 'grad_norm': 5.547691345214844, 'learning_rate': 7.988888888888889e-05, 'epoch': 0.83}\n",
      "{'loss': 0.4926, 'grad_norm': 14.225980758666992, 'learning_rate': 7.977777777777779e-05, 'epoch': 0.83}\n",
      "{'loss': 0.3057, 'grad_norm': 5.699151515960693, 'learning_rate': 7.966666666666666e-05, 'epoch': 0.84}\n",
      "{'loss': 0.3611, 'grad_norm': 8.188150405883789, 'learning_rate': 7.955555555555556e-05, 'epoch': 0.84}\n",
      "{'loss': 0.4898, 'grad_norm': 13.688826560974121, 'learning_rate': 7.944444444444444e-05, 'epoch': 0.84}\n",
      "{'loss': 0.2912, 'grad_norm': 4.859918594360352, 'learning_rate': 7.933333333333334e-05, 'epoch': 0.85}\n",
      "{'loss': 0.3492, 'grad_norm': 7.823125839233398, 'learning_rate': 7.922222222222223e-05, 'epoch': 0.85}\n",
      "{'loss': 0.1397, 'grad_norm': 3.397994041442871, 'learning_rate': 7.911111111111111e-05, 'epoch': 0.85}\n",
      "{'loss': 0.4949, 'grad_norm': 5.870070457458496, 'learning_rate': 7.900000000000001e-05, 'epoch': 0.86}\n",
      "{'loss': 0.6439, 'grad_norm': 16.109739303588867, 'learning_rate': 7.88888888888889e-05, 'epoch': 0.86}\n",
      "{'loss': 0.5663, 'grad_norm': 7.834517955780029, 'learning_rate': 7.877777777777778e-05, 'epoch': 0.86}\n",
      "{'loss': 0.2814, 'grad_norm': 6.3990302085876465, 'learning_rate': 7.866666666666666e-05, 'epoch': 0.86}\n",
      "{'loss': 0.3503, 'grad_norm': 31.03528594970703, 'learning_rate': 7.855555555555556e-05, 'epoch': 0.87}\n",
      "{'loss': 0.3237, 'grad_norm': 6.768885612487793, 'learning_rate': 7.844444444444446e-05, 'epoch': 0.87}\n",
      "{'loss': 0.4205, 'grad_norm': 4.601791858673096, 'learning_rate': 7.833333333333333e-05, 'epoch': 0.87}\n",
      "{'loss': 0.5481, 'grad_norm': 18.6062068939209, 'learning_rate': 7.822222222222223e-05, 'epoch': 0.88}\n",
      "{'loss': 0.2529, 'grad_norm': 9.428988456726074, 'learning_rate': 7.811111111111111e-05, 'epoch': 0.88}\n",
      "{'loss': 0.2504, 'grad_norm': 6.872365951538086, 'learning_rate': 7.800000000000001e-05, 'epoch': 0.88}\n",
      "{'loss': 0.5854, 'grad_norm': 6.748022079467773, 'learning_rate': 7.788888888888888e-05, 'epoch': 0.88}\n",
      "{'loss': 0.2865, 'grad_norm': 15.53945541381836, 'learning_rate': 7.777777777777778e-05, 'epoch': 0.89}\n",
      "{'loss': 0.4101, 'grad_norm': 8.3460693359375, 'learning_rate': 7.766666666666667e-05, 'epoch': 0.89}\n",
      "{'loss': 0.3381, 'grad_norm': 4.968965530395508, 'learning_rate': 7.755555555555556e-05, 'epoch': 0.89}\n",
      "{'loss': 0.4611, 'grad_norm': 23.62838363647461, 'learning_rate': 7.744444444444445e-05, 'epoch': 0.9}\n",
      "{'loss': 0.5246, 'grad_norm': 10.85982608795166, 'learning_rate': 7.733333333333333e-05, 'epoch': 0.9}\n",
      "{'loss': 0.5258, 'grad_norm': 26.551761627197266, 'learning_rate': 7.722222222222223e-05, 'epoch': 0.9}\n",
      "{'loss': 0.3206, 'grad_norm': 4.094178676605225, 'learning_rate': 7.711111111111112e-05, 'epoch': 0.91}\n",
      "{'loss': 0.412, 'grad_norm': 18.94940757751465, 'learning_rate': 7.7e-05, 'epoch': 0.91}\n",
      "{'loss': 0.448, 'grad_norm': 6.480178356170654, 'learning_rate': 7.688888888888889e-05, 'epoch': 0.91}\n",
      "{'loss': 0.3698, 'grad_norm': 7.669583320617676, 'learning_rate': 7.677777777777778e-05, 'epoch': 0.91}\n",
      "{'loss': 0.2291, 'grad_norm': 3.6042840480804443, 'learning_rate': 7.666666666666667e-05, 'epoch': 0.92}\n",
      "{'loss': 0.2618, 'grad_norm': 4.312412738800049, 'learning_rate': 7.655555555555555e-05, 'epoch': 0.92}\n",
      "{'loss': 0.2859, 'grad_norm': 3.837697982788086, 'learning_rate': 7.644444444444445e-05, 'epoch': 0.92}\n",
      "{'loss': 0.3496, 'grad_norm': 8.06421184539795, 'learning_rate': 7.633333333333334e-05, 'epoch': 0.93}\n",
      "{'loss': 0.4074, 'grad_norm': 4.571985721588135, 'learning_rate': 7.622222222222223e-05, 'epoch': 0.93}\n",
      "{'loss': 0.2442, 'grad_norm': 9.59351634979248, 'learning_rate': 7.61111111111111e-05, 'epoch': 0.93}\n",
      "{'loss': 0.2646, 'grad_norm': 8.222508430480957, 'learning_rate': 7.6e-05, 'epoch': 0.93}\n",
      "{'loss': 0.1783, 'grad_norm': 12.958645820617676, 'learning_rate': 7.588888888888889e-05, 'epoch': 0.94}\n",
      "{'loss': 0.4167, 'grad_norm': 19.58175277709961, 'learning_rate': 7.577777777777779e-05, 'epoch': 0.94}\n",
      "{'loss': 0.4835, 'grad_norm': 25.911623001098633, 'learning_rate': 7.566666666666667e-05, 'epoch': 0.94}\n",
      "{'loss': 0.4732, 'grad_norm': 10.987204551696777, 'learning_rate': 7.555555555555556e-05, 'epoch': 0.95}\n",
      "{'loss': 0.4288, 'grad_norm': 7.150502681732178, 'learning_rate': 7.544444444444445e-05, 'epoch': 0.95}\n",
      "{'loss': 0.5403, 'grad_norm': 16.44178009033203, 'learning_rate': 7.533333333333334e-05, 'epoch': 0.95}\n",
      "{'loss': 0.4953, 'grad_norm': 7.2254109382629395, 'learning_rate': 7.522222222222222e-05, 'epoch': 0.96}\n",
      "{'loss': 0.3401, 'grad_norm': 14.296753883361816, 'learning_rate': 7.511111111111111e-05, 'epoch': 0.96}\n",
      "{'loss': 0.3918, 'grad_norm': 18.228063583374023, 'learning_rate': 7.500000000000001e-05, 'epoch': 0.96}\n",
      "{'loss': 0.4592, 'grad_norm': 7.318781852722168, 'learning_rate': 7.488888888888889e-05, 'epoch': 0.96}\n",
      "{'loss': 0.4835, 'grad_norm': 17.443218231201172, 'learning_rate': 7.477777777777778e-05, 'epoch': 0.97}\n",
      "{'loss': 0.4193, 'grad_norm': 10.65082836151123, 'learning_rate': 7.466666666666667e-05, 'epoch': 0.97}\n",
      "{'loss': 0.5153, 'grad_norm': 27.76019859313965, 'learning_rate': 7.455555555555556e-05, 'epoch': 0.97}\n",
      "{'loss': 0.4667, 'grad_norm': 25.091711044311523, 'learning_rate': 7.444444444444444e-05, 'epoch': 0.98}\n",
      "{'loss': 0.3914, 'grad_norm': 13.004405975341797, 'learning_rate': 7.433333333333333e-05, 'epoch': 0.98}\n",
      "{'loss': 0.3539, 'grad_norm': 16.402029037475586, 'learning_rate': 7.422222222222223e-05, 'epoch': 0.98}\n",
      "{'loss': 0.5479, 'grad_norm': 13.056619644165039, 'learning_rate': 7.411111111111113e-05, 'epoch': 0.99}\n",
      "{'loss': 0.3674, 'grad_norm': 21.595962524414062, 'learning_rate': 7.4e-05, 'epoch': 0.99}\n",
      "{'loss': 0.479, 'grad_norm': 4.985814094543457, 'learning_rate': 7.38888888888889e-05, 'epoch': 0.99}\n",
      "{'loss': 0.4097, 'grad_norm': 6.8696770668029785, 'learning_rate': 7.377777777777778e-05, 'epoch': 0.99}\n",
      "{'loss': 0.5314, 'grad_norm': 29.64308738708496, 'learning_rate': 7.366666666666668e-05, 'epoch': 1.0}\n",
      "{'loss': 0.602, 'grad_norm': 30.62681770324707, 'learning_rate': 7.355555555555556e-05, 'epoch': 1.0}\n",
      "{'loss': 0.62, 'grad_norm': 30.413692474365234, 'learning_rate': 7.344444444444445e-05, 'epoch': 1.0}\n",
      "{'loss': 0.5318, 'grad_norm': 37.60581588745117, 'learning_rate': 7.333333333333333e-05, 'epoch': 1.01}\n",
      "{'loss': 0.4833, 'grad_norm': 32.253578186035156, 'learning_rate': 7.322222222222223e-05, 'epoch': 1.01}\n",
      "{'loss': 0.4764, 'grad_norm': 29.12710189819336, 'learning_rate': 7.311111111111111e-05, 'epoch': 1.01}\n",
      "{'loss': 0.2331, 'grad_norm': 4.3411431312561035, 'learning_rate': 7.3e-05, 'epoch': 1.01}\n",
      "{'loss': 0.2249, 'grad_norm': 6.797842979431152, 'learning_rate': 7.28888888888889e-05, 'epoch': 1.02}\n",
      "{'loss': 0.459, 'grad_norm': 14.194808959960938, 'learning_rate': 7.277777777777778e-05, 'epoch': 1.02}\n",
      "{'loss': 0.3127, 'grad_norm': 18.852283477783203, 'learning_rate': 7.266666666666667e-05, 'epoch': 1.02}\n",
      "{'loss': 0.2337, 'grad_norm': 7.789654731750488, 'learning_rate': 7.255555555555555e-05, 'epoch': 1.03}\n",
      "{'loss': 0.3051, 'grad_norm': 19.567657470703125, 'learning_rate': 7.244444444444445e-05, 'epoch': 1.03}\n",
      "{'loss': 0.3756, 'grad_norm': 11.876765251159668, 'learning_rate': 7.233333333333335e-05, 'epoch': 1.03}\n",
      "{'loss': 0.3833, 'grad_norm': 16.044340133666992, 'learning_rate': 7.222222222222222e-05, 'epoch': 1.04}\n",
      "{'loss': 0.4143, 'grad_norm': 18.966320037841797, 'learning_rate': 7.211111111111112e-05, 'epoch': 1.04}\n",
      "{'loss': 0.4733, 'grad_norm': 15.026349067687988, 'learning_rate': 7.2e-05, 'epoch': 1.04}\n",
      "{'loss': 0.24, 'grad_norm': 4.355819225311279, 'learning_rate': 7.18888888888889e-05, 'epoch': 1.04}\n",
      "{'loss': 0.3443, 'grad_norm': 5.851226806640625, 'learning_rate': 7.177777777777777e-05, 'epoch': 1.05}\n",
      "{'loss': 0.349, 'grad_norm': 17.776844024658203, 'learning_rate': 7.166666666666667e-05, 'epoch': 1.05}\n",
      "{'loss': 0.3609, 'grad_norm': 7.555634498596191, 'learning_rate': 7.155555555555555e-05, 'epoch': 1.05}\n",
      "{'loss': 0.2533, 'grad_norm': 4.297874450683594, 'learning_rate': 7.144444444444445e-05, 'epoch': 1.06}\n",
      "{'loss': 0.3626, 'grad_norm': 5.323823928833008, 'learning_rate': 7.133333333333334e-05, 'epoch': 1.06}\n",
      "{'loss': 0.2795, 'grad_norm': 16.765348434448242, 'learning_rate': 7.122222222222222e-05, 'epoch': 1.06}\n",
      "{'loss': 0.2263, 'grad_norm': 7.038523197174072, 'learning_rate': 7.111111111111112e-05, 'epoch': 1.07}\n",
      "{'loss': 0.1859, 'grad_norm': 3.547231674194336, 'learning_rate': 7.1e-05, 'epoch': 1.07}\n",
      "{'loss': 0.4444, 'grad_norm': 11.88514518737793, 'learning_rate': 7.088888888888889e-05, 'epoch': 1.07}\n",
      "{'loss': 0.2558, 'grad_norm': 7.646377086639404, 'learning_rate': 7.077777777777777e-05, 'epoch': 1.07}\n",
      "{'loss': 0.3952, 'grad_norm': 18.640905380249023, 'learning_rate': 7.066666666666667e-05, 'epoch': 1.08}\n",
      "{'loss': 0.509, 'grad_norm': 22.846555709838867, 'learning_rate': 7.055555555555556e-05, 'epoch': 1.08}\n",
      "{'loss': 0.2868, 'grad_norm': 6.523923397064209, 'learning_rate': 7.044444444444444e-05, 'epoch': 1.08}\n",
      "{'loss': 0.3457, 'grad_norm': 13.071812629699707, 'learning_rate': 7.033333333333334e-05, 'epoch': 1.09}\n",
      "{'loss': 0.5943, 'grad_norm': 17.710636138916016, 'learning_rate': 7.022222222222222e-05, 'epoch': 1.09}\n",
      "{'loss': 0.2988, 'grad_norm': 7.7051801681518555, 'learning_rate': 7.011111111111112e-05, 'epoch': 1.09}\n",
      "{'loss': 0.2601, 'grad_norm': 6.8365607261657715, 'learning_rate': 7e-05, 'epoch': 1.09}\n",
      "{'loss': 0.6174, 'grad_norm': 22.769819259643555, 'learning_rate': 6.988888888888889e-05, 'epoch': 1.1}\n",
      "{'loss': 0.2658, 'grad_norm': 6.543917655944824, 'learning_rate': 6.977777777777779e-05, 'epoch': 1.1}\n",
      "{'loss': 0.4486, 'grad_norm': 21.642105102539062, 'learning_rate': 6.966666666666668e-05, 'epoch': 1.1}\n",
      "{'loss': 0.357, 'grad_norm': 14.491005897521973, 'learning_rate': 6.955555555555556e-05, 'epoch': 1.11}\n",
      "{'loss': 0.3247, 'grad_norm': 18.49091339111328, 'learning_rate': 6.944444444444444e-05, 'epoch': 1.11}\n",
      "{'loss': 0.3069, 'grad_norm': 22.68976593017578, 'learning_rate': 6.933333333333334e-05, 'epoch': 1.11}\n",
      "{'loss': 0.2193, 'grad_norm': 8.20805835723877, 'learning_rate': 6.922222222222223e-05, 'epoch': 1.12}\n",
      "{'loss': 0.3492, 'grad_norm': 8.183125495910645, 'learning_rate': 6.911111111111111e-05, 'epoch': 1.12}\n",
      "{'loss': 0.3255, 'grad_norm': 11.854727745056152, 'learning_rate': 6.9e-05, 'epoch': 1.12}\n",
      "{'loss': 0.2501, 'grad_norm': 10.480786323547363, 'learning_rate': 6.88888888888889e-05, 'epoch': 1.12}\n",
      "{'loss': 0.1543, 'grad_norm': 11.77822494506836, 'learning_rate': 6.877777777777778e-05, 'epoch': 1.13}\n",
      "{'loss': 0.571, 'grad_norm': 37.98259735107422, 'learning_rate': 6.866666666666666e-05, 'epoch': 1.13}\n",
      "{'loss': 0.4819, 'grad_norm': 6.4268059730529785, 'learning_rate': 6.855555555555556e-05, 'epoch': 1.13}\n",
      "{'loss': 0.4972, 'grad_norm': 33.59580993652344, 'learning_rate': 6.844444444444445e-05, 'epoch': 1.14}\n",
      "{'loss': 0.26, 'grad_norm': 23.090456008911133, 'learning_rate': 6.833333333333333e-05, 'epoch': 1.14}\n",
      "{'loss': 0.2267, 'grad_norm': 7.323073387145996, 'learning_rate': 6.822222222222222e-05, 'epoch': 1.14}\n",
      "{'loss': 0.2807, 'grad_norm': 5.425501823425293, 'learning_rate': 6.811111111111111e-05, 'epoch': 1.14}\n",
      "{'loss': 0.3284, 'grad_norm': 7.165482044219971, 'learning_rate': 6.800000000000001e-05, 'epoch': 1.15}\n",
      "{'loss': 0.4949, 'grad_norm': 31.86278533935547, 'learning_rate': 6.788888888888888e-05, 'epoch': 1.15}\n",
      "{'loss': 0.3992, 'grad_norm': 6.184212684631348, 'learning_rate': 6.777777777777778e-05, 'epoch': 1.15}\n",
      "{'loss': 0.1769, 'grad_norm': 8.414566993713379, 'learning_rate': 6.766666666666667e-05, 'epoch': 1.16}\n",
      "{'loss': 0.5807, 'grad_norm': 34.40129470825195, 'learning_rate': 6.755555555555557e-05, 'epoch': 1.16}\n",
      "{'loss': 0.3573, 'grad_norm': 11.370756149291992, 'learning_rate': 6.744444444444445e-05, 'epoch': 1.16}\n",
      "{'loss': 0.4415, 'grad_norm': 12.993728637695312, 'learning_rate': 6.733333333333333e-05, 'epoch': 1.17}\n",
      "{'loss': 0.4308, 'grad_norm': 15.681729316711426, 'learning_rate': 6.722222222222223e-05, 'epoch': 1.17}\n",
      "{'loss': 0.497, 'grad_norm': 6.81679630279541, 'learning_rate': 6.711111111111112e-05, 'epoch': 1.17}\n",
      "{'loss': 0.4578, 'grad_norm': 14.628998756408691, 'learning_rate': 6.7e-05, 'epoch': 1.17}\n",
      "{'loss': 0.2446, 'grad_norm': 7.343197345733643, 'learning_rate': 6.688888888888889e-05, 'epoch': 1.18}\n",
      "{'loss': 0.5437, 'grad_norm': 17.117977142333984, 'learning_rate': 6.677777777777779e-05, 'epoch': 1.18}\n",
      "{'loss': 0.2795, 'grad_norm': 10.723343849182129, 'learning_rate': 6.666666666666667e-05, 'epoch': 1.18}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675362f1699946f6874dedb8dabe4274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.344729483127594, 'eval_f1': 0.843819393042191, 'eval_runtime': 846.4905, 'eval_samples_per_second': 3.192, 'eval_steps_per_second': 0.1, 'epoch': 1.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/HDD/anaconda3/envs/AIS/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/HDD/anaconda3/envs/AIS/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3692, 'grad_norm': 10.36331558227539, 'learning_rate': 6.655555555555555e-05, 'epoch': 1.19}\n",
      "{'loss': 0.2332, 'grad_norm': 4.724290370941162, 'learning_rate': 6.644444444444444e-05, 'epoch': 1.19}\n",
      "{'loss': 0.5197, 'grad_norm': 7.217120170593262, 'learning_rate': 6.633333333333334e-05, 'epoch': 1.19}\n",
      "{'loss': 0.1892, 'grad_norm': 15.670944213867188, 'learning_rate': 6.622222222222224e-05, 'epoch': 1.2}\n",
      "{'loss': 0.1368, 'grad_norm': 2.4594459533691406, 'learning_rate': 6.611111111111111e-05, 'epoch': 1.2}\n",
      "{'loss': 0.2583, 'grad_norm': 15.292116165161133, 'learning_rate': 6.6e-05, 'epoch': 1.2}\n",
      "{'loss': 0.14, 'grad_norm': 2.8132176399230957, 'learning_rate': 6.588888888888889e-05, 'epoch': 1.2}\n",
      "{'loss': 0.426, 'grad_norm': 19.32234764099121, 'learning_rate': 6.577777777777779e-05, 'epoch': 1.21}\n",
      "{'loss': 0.3453, 'grad_norm': 15.108917236328125, 'learning_rate': 6.566666666666666e-05, 'epoch': 1.21}\n",
      "{'loss': 0.3208, 'grad_norm': 25.405073165893555, 'learning_rate': 6.555555555555556e-05, 'epoch': 1.21}\n",
      "{'loss': 0.2003, 'grad_norm': 8.726738929748535, 'learning_rate': 6.544444444444446e-05, 'epoch': 1.22}\n",
      "{'loss': 0.2105, 'grad_norm': 10.888503074645996, 'learning_rate': 6.533333333333334e-05, 'epoch': 1.22}\n",
      "{'loss': 0.259, 'grad_norm': 17.630956649780273, 'learning_rate': 6.522222222222222e-05, 'epoch': 1.22}\n",
      "{'loss': 0.3931, 'grad_norm': 19.126182556152344, 'learning_rate': 6.511111111111111e-05, 'epoch': 1.22}\n",
      "{'loss': 0.2232, 'grad_norm': 17.980775833129883, 'learning_rate': 6.500000000000001e-05, 'epoch': 1.23}\n",
      "{'loss': 0.4485, 'grad_norm': 25.69281578063965, 'learning_rate': 6.488888888888889e-05, 'epoch': 1.23}\n",
      "{'loss': 0.4334, 'grad_norm': 23.823505401611328, 'learning_rate': 6.477777777777778e-05, 'epoch': 1.23}\n",
      "{'loss': 0.4664, 'grad_norm': 10.614347457885742, 'learning_rate': 6.466666666666666e-05, 'epoch': 1.24}\n",
      "{'loss': 0.1668, 'grad_norm': 4.699669361114502, 'learning_rate': 6.455555555555556e-05, 'epoch': 1.24}\n",
      "{'loss': 0.2689, 'grad_norm': 15.942492485046387, 'learning_rate': 6.444444444444446e-05, 'epoch': 1.24}\n",
      "{'loss': 0.1788, 'grad_norm': 11.579452514648438, 'learning_rate': 6.433333333333333e-05, 'epoch': 1.25}\n",
      "{'loss': 0.5331, 'grad_norm': 18.849109649658203, 'learning_rate': 6.422222222222223e-05, 'epoch': 1.25}\n",
      "{'loss': 0.2194, 'grad_norm': 15.240303039550781, 'learning_rate': 6.411111111111111e-05, 'epoch': 1.25}\n",
      "{'loss': 0.2293, 'grad_norm': 4.9629974365234375, 'learning_rate': 6.400000000000001e-05, 'epoch': 1.25}\n",
      "{'loss': 0.2335, 'grad_norm': 7.770125389099121, 'learning_rate': 6.388888888888888e-05, 'epoch': 1.26}\n",
      "{'loss': 0.4182, 'grad_norm': 17.079998016357422, 'learning_rate': 6.377777777777778e-05, 'epoch': 1.26}\n",
      "{'loss': 0.2031, 'grad_norm': 3.6801438331604004, 'learning_rate': 6.366666666666668e-05, 'epoch': 1.26}\n",
      "{'loss': 0.2846, 'grad_norm': 21.31582260131836, 'learning_rate': 6.355555555555556e-05, 'epoch': 1.27}\n",
      "{'loss': 0.4492, 'grad_norm': 13.757279396057129, 'learning_rate': 6.344444444444445e-05, 'epoch': 1.27}\n",
      "{'loss': 0.3109, 'grad_norm': 22.997936248779297, 'learning_rate': 6.333333333333333e-05, 'epoch': 1.27}\n",
      "{'loss': 0.2322, 'grad_norm': 4.160528182983398, 'learning_rate': 6.322222222222223e-05, 'epoch': 1.28}\n",
      "{'loss': 0.2797, 'grad_norm': 7.93276834487915, 'learning_rate': 6.311111111111112e-05, 'epoch': 1.28}\n",
      "{'loss': 0.4368, 'grad_norm': 12.388116836547852, 'learning_rate': 6.3e-05, 'epoch': 1.28}\n",
      "{'loss': 0.2146, 'grad_norm': 6.501223087310791, 'learning_rate': 6.28888888888889e-05, 'epoch': 1.28}\n",
      "{'loss': 0.1936, 'grad_norm': 8.140752792358398, 'learning_rate': 6.277777777777778e-05, 'epoch': 1.29}\n",
      "{'loss': 0.2511, 'grad_norm': 5.14313268661499, 'learning_rate': 6.266666666666667e-05, 'epoch': 1.29}\n",
      "{'loss': 0.3282, 'grad_norm': 7.916168212890625, 'learning_rate': 6.255555555555555e-05, 'epoch': 1.29}\n",
      "{'loss': 0.3078, 'grad_norm': 6.766259670257568, 'learning_rate': 6.244444444444445e-05, 'epoch': 1.3}\n",
      "{'loss': 0.2169, 'grad_norm': 6.364228248596191, 'learning_rate': 6.233333333333334e-05, 'epoch': 1.3}\n",
      "{'loss': 0.4389, 'grad_norm': 26.020830154418945, 'learning_rate': 6.222222222222222e-05, 'epoch': 1.3}\n",
      "{'loss': 0.3326, 'grad_norm': 23.056724548339844, 'learning_rate': 6.21111111111111e-05, 'epoch': 1.3}\n",
      "{'loss': 0.2705, 'grad_norm': 15.252913475036621, 'learning_rate': 6.2e-05, 'epoch': 1.31}\n",
      "{'loss': 0.4943, 'grad_norm': 7.172509670257568, 'learning_rate': 6.18888888888889e-05, 'epoch': 1.31}\n",
      "{'loss': 0.227, 'grad_norm': 5.611758232116699, 'learning_rate': 6.177777777777779e-05, 'epoch': 1.31}\n",
      "{'loss': 0.5028, 'grad_norm': 6.957499980926514, 'learning_rate': 6.166666666666667e-05, 'epoch': 1.32}\n",
      "{'loss': 0.494, 'grad_norm': 8.605636596679688, 'learning_rate': 6.155555555555555e-05, 'epoch': 1.32}\n",
      "{'loss': 0.426, 'grad_norm': 29.705066680908203, 'learning_rate': 6.144444444444445e-05, 'epoch': 1.32}\n",
      "{'loss': 0.5018, 'grad_norm': 30.970008850097656, 'learning_rate': 6.133333333333334e-05, 'epoch': 1.33}\n",
      "{'loss': 0.4153, 'grad_norm': 23.842924118041992, 'learning_rate': 6.122222222222222e-05, 'epoch': 1.33}\n",
      "{'loss': 0.4535, 'grad_norm': 21.90642547607422, 'learning_rate': 6.111111111111112e-05, 'epoch': 1.33}\n",
      "{'loss': 0.2493, 'grad_norm': 17.594112396240234, 'learning_rate': 6.1e-05, 'epoch': 1.33}\n",
      "{'loss': 0.3136, 'grad_norm': 18.197927474975586, 'learning_rate': 6.08888888888889e-05, 'epoch': 1.34}\n",
      "{'loss': 0.2309, 'grad_norm': 4.428293228149414, 'learning_rate': 6.0777777777777775e-05, 'epoch': 1.34}\n",
      "{'loss': 0.1971, 'grad_norm': 6.124631404876709, 'learning_rate': 6.066666666666667e-05, 'epoch': 1.34}\n",
      "{'loss': 0.3218, 'grad_norm': 5.009487628936768, 'learning_rate': 6.055555555555555e-05, 'epoch': 1.35}\n",
      "{'loss': 0.3687, 'grad_norm': 16.696685791015625, 'learning_rate': 6.044444444444445e-05, 'epoch': 1.35}\n",
      "{'loss': 0.1934, 'grad_norm': 15.518573760986328, 'learning_rate': 6.033333333333334e-05, 'epoch': 1.35}\n",
      "{'loss': 0.2418, 'grad_norm': 9.243552207946777, 'learning_rate': 6.0222222222222225e-05, 'epoch': 1.36}\n",
      "{'loss': 0.392, 'grad_norm': 11.728911399841309, 'learning_rate': 6.011111111111112e-05, 'epoch': 1.36}\n",
      "{'loss': 0.5308, 'grad_norm': 20.383811950683594, 'learning_rate': 6e-05, 'epoch': 1.36}\n",
      "{'loss': 0.3444, 'grad_norm': 6.476333141326904, 'learning_rate': 5.988888888888889e-05, 'epoch': 1.36}\n",
      "{'loss': 0.2942, 'grad_norm': 4.85279655456543, 'learning_rate': 5.977777777777778e-05, 'epoch': 1.37}\n",
      "{'loss': 0.2934, 'grad_norm': 9.573623657226562, 'learning_rate': 5.966666666666667e-05, 'epoch': 1.37}\n",
      "{'loss': 0.3748, 'grad_norm': 6.316566467285156, 'learning_rate': 5.9555555555555554e-05, 'epoch': 1.37}\n",
      "{'loss': 0.446, 'grad_norm': 18.95176124572754, 'learning_rate': 5.9444444444444445e-05, 'epoch': 1.38}\n",
      "{'loss': 0.2543, 'grad_norm': 4.218609809875488, 'learning_rate': 5.9333333333333343e-05, 'epoch': 1.38}\n",
      "{'loss': 0.3451, 'grad_norm': 5.969419479370117, 'learning_rate': 5.922222222222222e-05, 'epoch': 1.38}\n",
      "{'loss': 0.2249, 'grad_norm': 10.459137916564941, 'learning_rate': 5.911111111111112e-05, 'epoch': 1.38}\n",
      "{'loss': 0.363, 'grad_norm': 14.580042839050293, 'learning_rate': 5.9e-05, 'epoch': 1.39}\n",
      "{'loss': 0.4455, 'grad_norm': 6.083368301391602, 'learning_rate': 5.8888888888888896e-05, 'epoch': 1.39}\n",
      "{'loss': 0.5353, 'grad_norm': 5.218168258666992, 'learning_rate': 5.8777777777777774e-05, 'epoch': 1.39}\n",
      "{'loss': 0.3832, 'grad_norm': 21.580028533935547, 'learning_rate': 5.866666666666667e-05, 'epoch': 1.4}\n",
      "{'loss': 0.306, 'grad_norm': 9.113948822021484, 'learning_rate': 5.855555555555556e-05, 'epoch': 1.4}\n",
      "{'loss': 0.2061, 'grad_norm': 3.0575947761535645, 'learning_rate': 5.844444444444445e-05, 'epoch': 1.4}\n",
      "{'loss': 0.2133, 'grad_norm': 6.236562728881836, 'learning_rate': 5.833333333333334e-05, 'epoch': 1.41}\n",
      "{'loss': 0.2982, 'grad_norm': 5.779118061065674, 'learning_rate': 5.8222222222222224e-05, 'epoch': 1.41}\n",
      "{'loss': 0.3776, 'grad_norm': 9.008039474487305, 'learning_rate': 5.8111111111111116e-05, 'epoch': 1.41}\n",
      "{'loss': 0.3612, 'grad_norm': 12.012595176696777, 'learning_rate': 5.8e-05, 'epoch': 1.41}\n",
      "{'loss': 0.2197, 'grad_norm': 9.965919494628906, 'learning_rate': 5.788888888888889e-05, 'epoch': 1.42}\n",
      "{'loss': 0.2147, 'grad_norm': 7.306247711181641, 'learning_rate': 5.7777777777777776e-05, 'epoch': 1.42}\n",
      "{'loss': 0.2923, 'grad_norm': 6.103448390960693, 'learning_rate': 5.766666666666667e-05, 'epoch': 1.42}\n",
      "{'loss': 0.3334, 'grad_norm': 5.279599666595459, 'learning_rate': 5.755555555555556e-05, 'epoch': 1.43}\n",
      "{'loss': 0.1221, 'grad_norm': 8.389861106872559, 'learning_rate': 5.7444444444444444e-05, 'epoch': 1.43}\n",
      "{'loss': 0.2842, 'grad_norm': 8.708433151245117, 'learning_rate': 5.7333333333333336e-05, 'epoch': 1.43}\n",
      "{'loss': 0.2429, 'grad_norm': 7.005973815917969, 'learning_rate': 5.722222222222222e-05, 'epoch': 1.43}\n",
      "{'loss': 0.3008, 'grad_norm': 20.151453018188477, 'learning_rate': 5.711111111111112e-05, 'epoch': 1.44}\n",
      "{'loss': 0.4752, 'grad_norm': 17.193635940551758, 'learning_rate': 5.6999999999999996e-05, 'epoch': 1.44}\n",
      "{'loss': 0.1733, 'grad_norm': 8.519271850585938, 'learning_rate': 5.6888888888888895e-05, 'epoch': 1.44}\n",
      "{'loss': 0.166, 'grad_norm': 3.5919992923736572, 'learning_rate': 5.6777777777777786e-05, 'epoch': 1.45}\n",
      "{'loss': 0.3267, 'grad_norm': 9.162622451782227, 'learning_rate': 5.666666666666667e-05, 'epoch': 1.45}\n",
      "{'loss': 0.1588, 'grad_norm': 4.314857482910156, 'learning_rate': 5.655555555555556e-05, 'epoch': 1.45}\n",
      "{'loss': 0.389, 'grad_norm': 18.189977645874023, 'learning_rate': 5.644444444444445e-05, 'epoch': 1.46}\n",
      "{'loss': 0.4653, 'grad_norm': 19.32156753540039, 'learning_rate': 5.633333333333334e-05, 'epoch': 1.46}\n",
      "{'loss': 0.5576, 'grad_norm': 8.148771286010742, 'learning_rate': 5.622222222222222e-05, 'epoch': 1.46}\n",
      "{'loss': 0.3368, 'grad_norm': 17.722427368164062, 'learning_rate': 5.6111111111111114e-05, 'epoch': 1.46}\n",
      "{'loss': 0.2896, 'grad_norm': 4.595861911773682, 'learning_rate': 5.6000000000000006e-05, 'epoch': 1.47}\n",
      "{'loss': 0.3925, 'grad_norm': 8.993956565856934, 'learning_rate': 5.588888888888889e-05, 'epoch': 1.47}\n",
      "{'loss': 0.5021, 'grad_norm': 25.26589012145996, 'learning_rate': 5.577777777777778e-05, 'epoch': 1.47}\n",
      "{'loss': 0.3704, 'grad_norm': 8.188225746154785, 'learning_rate': 5.566666666666667e-05, 'epoch': 1.48}\n",
      "{'loss': 0.3375, 'grad_norm': 17.949731826782227, 'learning_rate': 5.555555555555556e-05, 'epoch': 1.48}\n",
      "{'loss': 0.3589, 'grad_norm': 5.790643215179443, 'learning_rate': 5.544444444444444e-05, 'epoch': 1.48}\n",
      "{'loss': 0.3122, 'grad_norm': 7.043819904327393, 'learning_rate': 5.5333333333333334e-05, 'epoch': 1.49}\n",
      "{'loss': 0.3067, 'grad_norm': 8.360123634338379, 'learning_rate': 5.522222222222222e-05, 'epoch': 1.49}\n",
      "{'loss': 0.2255, 'grad_norm': 12.033740043640137, 'learning_rate': 5.511111111111111e-05, 'epoch': 1.49}\n",
      "{'loss': 0.4737, 'grad_norm': 16.21091651916504, 'learning_rate': 5.500000000000001e-05, 'epoch': 1.49}\n",
      "{'loss': 0.4793, 'grad_norm': 13.475336074829102, 'learning_rate': 5.488888888888889e-05, 'epoch': 1.5}\n",
      "{'loss': 0.2649, 'grad_norm': 8.197098731994629, 'learning_rate': 5.4777777777777785e-05, 'epoch': 1.5}\n",
      "{'loss': 0.1605, 'grad_norm': 4.288255214691162, 'learning_rate': 5.466666666666666e-05, 'epoch': 1.5}\n",
      "{'loss': 0.1698, 'grad_norm': 3.898388385772705, 'learning_rate': 5.455555555555556e-05, 'epoch': 1.51}\n",
      "{'loss': 0.3695, 'grad_norm': 10.668619155883789, 'learning_rate': 5.4444444444444446e-05, 'epoch': 1.51}\n",
      "{'loss': 0.3878, 'grad_norm': 16.30575180053711, 'learning_rate': 5.433333333333334e-05, 'epoch': 1.51}\n",
      "{'loss': 0.3631, 'grad_norm': 13.297852516174316, 'learning_rate': 5.422222222222223e-05, 'epoch': 1.51}\n",
      "{'loss': 0.2062, 'grad_norm': 4.6570587158203125, 'learning_rate': 5.411111111111111e-05, 'epoch': 1.52}\n",
      "{'loss': 0.1466, 'grad_norm': 2.629978656768799, 'learning_rate': 5.4000000000000005e-05, 'epoch': 1.52}\n",
      "{'loss': 0.2799, 'grad_norm': 6.395413398742676, 'learning_rate': 5.388888888888889e-05, 'epoch': 1.52}\n",
      "{'loss': 0.2688, 'grad_norm': 9.175026893615723, 'learning_rate': 5.377777777777778e-05, 'epoch': 1.53}\n",
      "{'loss': 0.4283, 'grad_norm': 24.4351749420166, 'learning_rate': 5.3666666666666666e-05, 'epoch': 1.53}\n",
      "{'loss': 0.4959, 'grad_norm': 18.50208282470703, 'learning_rate': 5.355555555555556e-05, 'epoch': 1.53}\n",
      "{'loss': 0.3117, 'grad_norm': 11.444906234741211, 'learning_rate': 5.3444444444444455e-05, 'epoch': 1.54}\n",
      "{'loss': 0.4676, 'grad_norm': 33.6196174621582, 'learning_rate': 5.333333333333333e-05, 'epoch': 1.54}\n",
      "{'loss': 0.3668, 'grad_norm': 13.33869457244873, 'learning_rate': 5.322222222222223e-05, 'epoch': 1.54}\n",
      "{'loss': 0.5567, 'grad_norm': 8.405784606933594, 'learning_rate': 5.311111111111111e-05, 'epoch': 1.54}\n",
      "{'loss': 0.3323, 'grad_norm': 10.100272178649902, 'learning_rate': 5.300000000000001e-05, 'epoch': 1.55}\n",
      "{'loss': 0.1869, 'grad_norm': 5.11841344833374, 'learning_rate': 5.2888888888888885e-05, 'epoch': 1.55}\n",
      "{'loss': 0.2962, 'grad_norm': 5.687424659729004, 'learning_rate': 5.2777777777777784e-05, 'epoch': 1.55}\n",
      "{'loss': 0.2988, 'grad_norm': 12.014461517333984, 'learning_rate': 5.266666666666666e-05, 'epoch': 1.56}\n",
      "{'loss': 0.3238, 'grad_norm': 7.069971561431885, 'learning_rate': 5.255555555555556e-05, 'epoch': 1.56}\n",
      "{'loss': 0.3213, 'grad_norm': 5.778009414672852, 'learning_rate': 5.244444444444445e-05, 'epoch': 1.56}\n",
      "{'loss': 0.2626, 'grad_norm': 8.850689888000488, 'learning_rate': 5.2333333333333336e-05, 'epoch': 1.57}\n",
      "{'loss': 0.3473, 'grad_norm': 20.801403045654297, 'learning_rate': 5.222222222222223e-05, 'epoch': 1.57}\n",
      "{'loss': 0.4492, 'grad_norm': 35.129337310791016, 'learning_rate': 5.211111111111111e-05, 'epoch': 1.57}\n",
      "{'loss': 0.1332, 'grad_norm': 3.4488096237182617, 'learning_rate': 5.2000000000000004e-05, 'epoch': 1.57}\n",
      "{'loss': 0.2257, 'grad_norm': 4.471258640289307, 'learning_rate': 5.188888888888889e-05, 'epoch': 1.58}\n",
      "{'loss': 0.1735, 'grad_norm': 4.049186706542969, 'learning_rate': 5.177777777777778e-05, 'epoch': 1.58}\n",
      "{'loss': 0.1768, 'grad_norm': 5.190948963165283, 'learning_rate': 5.166666666666667e-05, 'epoch': 1.58}\n",
      "{'loss': 0.2857, 'grad_norm': 7.05940055847168, 'learning_rate': 5.1555555555555556e-05, 'epoch': 1.59}\n",
      "{'loss': 0.2942, 'grad_norm': 9.1847505569458, 'learning_rate': 5.144444444444445e-05, 'epoch': 1.59}\n",
      "{'loss': 0.2458, 'grad_norm': 14.878098487854004, 'learning_rate': 5.133333333333333e-05, 'epoch': 1.59}\n",
      "{'loss': 0.1877, 'grad_norm': 18.417192459106445, 'learning_rate': 5.122222222222223e-05, 'epoch': 1.59}\n",
      "{'loss': 0.3383, 'grad_norm': 17.83968734741211, 'learning_rate': 5.111111111111111e-05, 'epoch': 1.6}\n",
      "{'loss': 0.3035, 'grad_norm': 13.460552215576172, 'learning_rate': 5.1000000000000006e-05, 'epoch': 1.6}\n",
      "{'loss': 0.3542, 'grad_norm': 9.308980941772461, 'learning_rate': 5.0888888888888884e-05, 'epoch': 1.6}\n",
      "{'loss': 0.256, 'grad_norm': 13.165419578552246, 'learning_rate': 5.077777777777778e-05, 'epoch': 1.61}\n",
      "{'loss': 0.1001, 'grad_norm': 6.825170516967773, 'learning_rate': 5.0666666666666674e-05, 'epoch': 1.61}\n",
      "{'loss': 0.4031, 'grad_norm': 14.742302894592285, 'learning_rate': 5.055555555555556e-05, 'epoch': 1.61}\n",
      "{'loss': 0.1675, 'grad_norm': 3.7624266147613525, 'learning_rate': 5.044444444444445e-05, 'epoch': 1.62}\n",
      "{'loss': 0.1854, 'grad_norm': 6.086262226104736, 'learning_rate': 5.0333333333333335e-05, 'epoch': 1.62}\n",
      "{'loss': 0.3582, 'grad_norm': 17.872377395629883, 'learning_rate': 5.0222222222222226e-05, 'epoch': 1.62}\n",
      "{'loss': 0.4496, 'grad_norm': 29.737884521484375, 'learning_rate': 5.011111111111111e-05, 'epoch': 1.62}\n",
      "{'loss': 0.4567, 'grad_norm': 21.526264190673828, 'learning_rate': 5e-05, 'epoch': 1.63}\n",
      "{'loss': 0.6146, 'grad_norm': 12.446234703063965, 'learning_rate': 4.9888888888888894e-05, 'epoch': 1.63}\n",
      "{'loss': 0.3211, 'grad_norm': 18.60319709777832, 'learning_rate': 4.977777777777778e-05, 'epoch': 1.63}\n",
      "{'loss': 0.2672, 'grad_norm': 6.123804092407227, 'learning_rate': 4.966666666666667e-05, 'epoch': 1.64}\n",
      "{'loss': 0.4304, 'grad_norm': 6.351837635040283, 'learning_rate': 4.955555555555556e-05, 'epoch': 1.64}\n",
      "{'loss': 0.428, 'grad_norm': 7.094404220581055, 'learning_rate': 4.9444444444444446e-05, 'epoch': 1.64}\n",
      "{'loss': 0.3264, 'grad_norm': 24.023086547851562, 'learning_rate': 4.933333333333334e-05, 'epoch': 1.64}\n",
      "{'loss': 0.5268, 'grad_norm': 27.0341854095459, 'learning_rate': 4.922222222222222e-05, 'epoch': 1.65}\n",
      "{'loss': 0.323, 'grad_norm': 10.901155471801758, 'learning_rate': 4.9111111111111114e-05, 'epoch': 1.65}\n",
      "{'loss': 0.6155, 'grad_norm': 42.62600326538086, 'learning_rate': 4.9e-05, 'epoch': 1.65}\n",
      "{'loss': 0.266, 'grad_norm': 5.571827411651611, 'learning_rate': 4.888888888888889e-05, 'epoch': 1.66}\n",
      "{'loss': 0.3603, 'grad_norm': 6.917967319488525, 'learning_rate': 4.8777777777777775e-05, 'epoch': 1.66}\n",
      "{'loss': 0.2762, 'grad_norm': 20.23543930053711, 'learning_rate': 4.866666666666667e-05, 'epoch': 1.66}\n",
      "{'loss': 0.1036, 'grad_norm': 8.069695472717285, 'learning_rate': 4.855555555555556e-05, 'epoch': 1.67}\n",
      "{'loss': 0.2749, 'grad_norm': 11.166092872619629, 'learning_rate': 4.844444444444445e-05, 'epoch': 1.67}\n",
      "{'loss': 0.4954, 'grad_norm': 32.292293548583984, 'learning_rate': 4.8333333333333334e-05, 'epoch': 1.67}\n",
      "{'loss': 0.2856, 'grad_norm': 8.457173347473145, 'learning_rate': 4.8222222222222225e-05, 'epoch': 1.67}\n",
      "{'loss': 0.3699, 'grad_norm': 14.712394714355469, 'learning_rate': 4.811111111111111e-05, 'epoch': 1.68}\n",
      "{'loss': 0.3149, 'grad_norm': 6.148645401000977, 'learning_rate': 4.8e-05, 'epoch': 1.68}\n",
      "{'loss': 0.2675, 'grad_norm': 7.937261581420898, 'learning_rate': 4.7888888888888886e-05, 'epoch': 1.68}\n",
      "{'loss': 0.2349, 'grad_norm': 14.217368125915527, 'learning_rate': 4.7777777777777784e-05, 'epoch': 1.69}\n",
      "{'loss': 0.1775, 'grad_norm': 13.507098197937012, 'learning_rate': 4.766666666666667e-05, 'epoch': 1.69}\n",
      "{'loss': 0.4407, 'grad_norm': 6.407873153686523, 'learning_rate': 4.755555555555556e-05, 'epoch': 1.69}\n",
      "{'loss': 0.2994, 'grad_norm': 4.846934795379639, 'learning_rate': 4.7444444444444445e-05, 'epoch': 1.7}\n",
      "{'loss': 0.3078, 'grad_norm': 5.17819356918335, 'learning_rate': 4.7333333333333336e-05, 'epoch': 1.7}\n",
      "{'loss': 0.2392, 'grad_norm': 5.136238098144531, 'learning_rate': 4.722222222222222e-05, 'epoch': 1.7}\n",
      "{'loss': 0.2404, 'grad_norm': 7.9270124435424805, 'learning_rate': 4.711111111111111e-05, 'epoch': 1.7}\n",
      "{'loss': 0.3001, 'grad_norm': 10.152840614318848, 'learning_rate': 4.7e-05, 'epoch': 1.71}\n",
      "{'loss': 0.4051, 'grad_norm': 5.671563148498535, 'learning_rate': 4.6888888888888895e-05, 'epoch': 1.71}\n",
      "{'loss': 0.2853, 'grad_norm': 5.9076995849609375, 'learning_rate': 4.677777777777778e-05, 'epoch': 1.71}\n",
      "{'loss': 0.1999, 'grad_norm': 6.162334442138672, 'learning_rate': 4.666666666666667e-05, 'epoch': 1.72}\n",
      "{'loss': 0.2404, 'grad_norm': 8.32553482055664, 'learning_rate': 4.6555555555555556e-05, 'epoch': 1.72}\n",
      "{'loss': 0.3742, 'grad_norm': 4.769587516784668, 'learning_rate': 4.644444444444445e-05, 'epoch': 1.72}\n",
      "{'loss': 0.4231, 'grad_norm': 11.981813430786133, 'learning_rate': 4.633333333333333e-05, 'epoch': 1.72}\n",
      "{'loss': 0.2429, 'grad_norm': 9.435473442077637, 'learning_rate': 4.6222222222222224e-05, 'epoch': 1.73}\n",
      "{'loss': 0.4265, 'grad_norm': 23.460098266601562, 'learning_rate': 4.6111111111111115e-05, 'epoch': 1.73}\n",
      "{'loss': 0.1752, 'grad_norm': 3.7138872146606445, 'learning_rate': 4.600000000000001e-05, 'epoch': 1.73}\n",
      "{'loss': 0.2701, 'grad_norm': 12.844460487365723, 'learning_rate': 4.588888888888889e-05, 'epoch': 1.74}\n",
      "{'loss': 0.3043, 'grad_norm': 3.7276089191436768, 'learning_rate': 4.577777777777778e-05, 'epoch': 1.74}\n",
      "{'loss': 0.299, 'grad_norm': 10.506038665771484, 'learning_rate': 4.566666666666667e-05, 'epoch': 1.74}\n",
      "{'loss': 0.3404, 'grad_norm': 20.31934928894043, 'learning_rate': 4.555555555555556e-05, 'epoch': 1.75}\n",
      "{'loss': 0.3122, 'grad_norm': 23.446937561035156, 'learning_rate': 4.5444444444444444e-05, 'epoch': 1.75}\n",
      "{'loss': 0.2452, 'grad_norm': 4.005446434020996, 'learning_rate': 4.5333333333333335e-05, 'epoch': 1.75}\n",
      "{'loss': 0.2747, 'grad_norm': 5.580004692077637, 'learning_rate': 4.522222222222223e-05, 'epoch': 1.75}\n",
      "{'loss': 0.3033, 'grad_norm': 17.45253562927246, 'learning_rate': 4.511111111111112e-05, 'epoch': 1.76}\n",
      "{'loss': 0.2918, 'grad_norm': 12.564645767211914, 'learning_rate': 4.5e-05, 'epoch': 1.76}\n",
      "{'loss': 0.4204, 'grad_norm': 6.680663585662842, 'learning_rate': 4.4888888888888894e-05, 'epoch': 1.76}\n",
      "{'loss': 0.2063, 'grad_norm': 10.364344596862793, 'learning_rate': 4.477777777777778e-05, 'epoch': 1.77}\n",
      "{'loss': 0.2072, 'grad_norm': 11.909722328186035, 'learning_rate': 4.466666666666667e-05, 'epoch': 1.77}\n",
      "{'loss': 0.2121, 'grad_norm': 4.200990200042725, 'learning_rate': 4.4555555555555555e-05, 'epoch': 1.77}\n",
      "{'loss': 0.1515, 'grad_norm': 8.335379600524902, 'learning_rate': 4.4444444444444447e-05, 'epoch': 1.78}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14cc5d86276a43e0b49b95dc23be51a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.342351496219635, 'eval_f1': 0.847520355292376, 'eval_runtime': 846.1859, 'eval_samples_per_second': 3.193, 'eval_steps_per_second': 0.1, 'epoch': 1.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/HDD/anaconda3/envs/AIS/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/HDD/anaconda3/envs/AIS/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.321, 'grad_norm': 7.37649393081665, 'learning_rate': 4.433333333333334e-05, 'epoch': 1.78}\n",
      "{'loss': 0.4496, 'grad_norm': 20.31473159790039, 'learning_rate': 4.422222222222222e-05, 'epoch': 1.78}\n",
      "{'loss': 0.1342, 'grad_norm': 7.104060649871826, 'learning_rate': 4.4111111111111114e-05, 'epoch': 1.78}\n",
      "{'loss': 0.2194, 'grad_norm': 5.511039733886719, 'learning_rate': 4.4000000000000006e-05, 'epoch': 1.79}\n",
      "{'loss': 0.2151, 'grad_norm': 5.674297332763672, 'learning_rate': 4.388888888888889e-05, 'epoch': 1.79}\n",
      "{'loss': 0.3339, 'grad_norm': 12.573616981506348, 'learning_rate': 4.377777777777778e-05, 'epoch': 1.79}\n",
      "{'loss': 0.2934, 'grad_norm': 5.158769607543945, 'learning_rate': 4.3666666666666666e-05, 'epoch': 1.8}\n",
      "{'loss': 0.1412, 'grad_norm': 3.6084353923797607, 'learning_rate': 4.355555555555556e-05, 'epoch': 1.8}\n",
      "{'loss': 0.3468, 'grad_norm': 6.407821178436279, 'learning_rate': 4.344444444444445e-05, 'epoch': 1.8}\n",
      "{'loss': 0.2575, 'grad_norm': 16.069202423095703, 'learning_rate': 4.3333333333333334e-05, 'epoch': 1.8}\n",
      "{'loss': 0.1917, 'grad_norm': 5.452245712280273, 'learning_rate': 4.3222222222222226e-05, 'epoch': 1.81}\n",
      "{'loss': 0.3001, 'grad_norm': 24.701751708984375, 'learning_rate': 4.311111111111111e-05, 'epoch': 1.81}\n",
      "{'loss': 0.372, 'grad_norm': 8.979790687561035, 'learning_rate': 4.3e-05, 'epoch': 1.81}\n",
      "{'loss': 0.3878, 'grad_norm': 14.384905815124512, 'learning_rate': 4.2888888888888886e-05, 'epoch': 1.82}\n",
      "{'loss': 0.3632, 'grad_norm': 7.556915283203125, 'learning_rate': 4.277777777777778e-05, 'epoch': 1.82}\n",
      "{'loss': 0.5968, 'grad_norm': 14.84535026550293, 'learning_rate': 4.266666666666667e-05, 'epoch': 1.82}\n",
      "{'loss': 0.1858, 'grad_norm': 5.7044830322265625, 'learning_rate': 4.255555555555556e-05, 'epoch': 1.83}\n",
      "{'loss': 0.2001, 'grad_norm': 3.751193046569824, 'learning_rate': 4.2444444444444445e-05, 'epoch': 1.83}\n",
      "{'loss': 0.3014, 'grad_norm': 7.4666266441345215, 'learning_rate': 4.233333333333334e-05, 'epoch': 1.83}\n",
      "{'loss': 0.1887, 'grad_norm': 15.041298866271973, 'learning_rate': 4.222222222222222e-05, 'epoch': 1.83}\n",
      "{'loss': 0.1773, 'grad_norm': 13.636908531188965, 'learning_rate': 4.211111111111111e-05, 'epoch': 1.84}\n",
      "{'loss': 0.6315, 'grad_norm': 19.20733070373535, 'learning_rate': 4.2e-05, 'epoch': 1.84}\n",
      "{'loss': 0.3259, 'grad_norm': 22.249372482299805, 'learning_rate': 4.188888888888889e-05, 'epoch': 1.84}\n",
      "{'loss': 0.4447, 'grad_norm': 21.138154983520508, 'learning_rate': 4.177777777777778e-05, 'epoch': 1.85}\n",
      "{'loss': 0.4086, 'grad_norm': 20.08399200439453, 'learning_rate': 4.166666666666667e-05, 'epoch': 1.85}\n",
      "{'loss': 0.2415, 'grad_norm': 13.239225387573242, 'learning_rate': 4.155555555555556e-05, 'epoch': 1.85}\n",
      "{'loss': 0.3581, 'grad_norm': 5.41789436340332, 'learning_rate': 4.144444444444445e-05, 'epoch': 1.86}\n",
      "{'loss': 0.1857, 'grad_norm': 4.316059589385986, 'learning_rate': 4.133333333333333e-05, 'epoch': 1.86}\n",
      "{'loss': 0.5488, 'grad_norm': 22.144184112548828, 'learning_rate': 4.1222222222222224e-05, 'epoch': 1.86}\n",
      "{'loss': 0.5184, 'grad_norm': 17.292884826660156, 'learning_rate': 4.111111111111111e-05, 'epoch': 1.86}\n",
      "{'loss': 0.2423, 'grad_norm': 13.389086723327637, 'learning_rate': 4.1e-05, 'epoch': 1.87}\n",
      "{'loss': 0.2852, 'grad_norm': 14.166813850402832, 'learning_rate': 4.088888888888889e-05, 'epoch': 1.87}\n",
      "{'loss': 0.4627, 'grad_norm': 20.587257385253906, 'learning_rate': 4.0777777777777783e-05, 'epoch': 1.87}\n",
      "{'loss': 0.3278, 'grad_norm': 10.611235618591309, 'learning_rate': 4.066666666666667e-05, 'epoch': 1.88}\n",
      "{'loss': 0.3597, 'grad_norm': 12.68005084991455, 'learning_rate': 4.055555555555556e-05, 'epoch': 1.88}\n",
      "{'loss': 0.3393, 'grad_norm': 16.412500381469727, 'learning_rate': 4.0444444444444444e-05, 'epoch': 1.88}\n",
      "{'loss': 0.3274, 'grad_norm': 4.488617897033691, 'learning_rate': 4.0333333333333336e-05, 'epoch': 1.88}\n",
      "{'loss': 0.3874, 'grad_norm': 7.957788467407227, 'learning_rate': 4.022222222222222e-05, 'epoch': 1.89}\n",
      "{'loss': 0.3633, 'grad_norm': 13.940401077270508, 'learning_rate': 4.011111111111111e-05, 'epoch': 1.89}\n",
      "{'loss': 0.2672, 'grad_norm': 7.047703266143799, 'learning_rate': 4e-05, 'epoch': 1.89}\n",
      "{'loss': 0.2253, 'grad_norm': 4.228344440460205, 'learning_rate': 3.9888888888888895e-05, 'epoch': 1.9}\n",
      "{'loss': 0.1865, 'grad_norm': 5.523984432220459, 'learning_rate': 3.977777777777778e-05, 'epoch': 1.9}\n",
      "{'loss': 0.1255, 'grad_norm': 4.329759120941162, 'learning_rate': 3.966666666666667e-05, 'epoch': 1.9}\n",
      "{'loss': 0.1975, 'grad_norm': 3.2986297607421875, 'learning_rate': 3.9555555555555556e-05, 'epoch': 1.91}\n",
      "{'loss': 0.1539, 'grad_norm': 6.404038906097412, 'learning_rate': 3.944444444444445e-05, 'epoch': 1.91}\n",
      "{'loss': 0.1169, 'grad_norm': 3.0868303775787354, 'learning_rate': 3.933333333333333e-05, 'epoch': 1.91}\n",
      "{'loss': 0.1473, 'grad_norm': 7.209825038909912, 'learning_rate': 3.922222222222223e-05, 'epoch': 1.91}\n",
      "{'loss': 0.2473, 'grad_norm': 7.146862506866455, 'learning_rate': 3.9111111111111115e-05, 'epoch': 1.92}\n",
      "{'loss': 0.1338, 'grad_norm': 12.125061988830566, 'learning_rate': 3.9000000000000006e-05, 'epoch': 1.92}\n",
      "{'loss': 0.1394, 'grad_norm': 4.008608341217041, 'learning_rate': 3.888888888888889e-05, 'epoch': 1.92}\n",
      "{'loss': 0.3055, 'grad_norm': 16.19706916809082, 'learning_rate': 3.877777777777778e-05, 'epoch': 1.93}\n",
      "{'loss': 0.2732, 'grad_norm': 5.305715560913086, 'learning_rate': 3.866666666666667e-05, 'epoch': 1.93}\n",
      "{'loss': 0.2606, 'grad_norm': 23.870153427124023, 'learning_rate': 3.855555555555556e-05, 'epoch': 1.93}\n",
      "{'loss': 0.3071, 'grad_norm': 15.007516860961914, 'learning_rate': 3.844444444444444e-05, 'epoch': 1.93}\n",
      "{'loss': 0.2245, 'grad_norm': 16.06472396850586, 'learning_rate': 3.8333333333333334e-05, 'epoch': 1.94}\n",
      "{'loss': 0.5334, 'grad_norm': 7.056077480316162, 'learning_rate': 3.8222222222222226e-05, 'epoch': 1.94}\n",
      "{'loss': 0.1087, 'grad_norm': 12.68460464477539, 'learning_rate': 3.811111111111112e-05, 'epoch': 1.94}\n",
      "{'loss': 0.3673, 'grad_norm': 19.651447296142578, 'learning_rate': 3.8e-05, 'epoch': 1.95}\n",
      "{'loss': 0.2095, 'grad_norm': 7.711225509643555, 'learning_rate': 3.7888888888888894e-05, 'epoch': 1.95}\n",
      "{'loss': 0.3898, 'grad_norm': 14.684368133544922, 'learning_rate': 3.777777777777778e-05, 'epoch': 1.95}\n",
      "{'loss': 0.3697, 'grad_norm': 7.897891044616699, 'learning_rate': 3.766666666666667e-05, 'epoch': 1.96}\n",
      "{'loss': 0.3246, 'grad_norm': 7.779378890991211, 'learning_rate': 3.7555555555555554e-05, 'epoch': 1.96}\n",
      "{'loss': 0.0997, 'grad_norm': 4.845866680145264, 'learning_rate': 3.7444444444444446e-05, 'epoch': 1.96}\n",
      "{'loss': 0.4746, 'grad_norm': 11.050419807434082, 'learning_rate': 3.733333333333334e-05, 'epoch': 1.96}\n",
      "{'loss': 0.548, 'grad_norm': 14.817390441894531, 'learning_rate': 3.722222222222222e-05, 'epoch': 1.97}\n",
      "{'loss': 0.6328, 'grad_norm': 13.309362411499023, 'learning_rate': 3.7111111111111113e-05, 'epoch': 1.97}\n",
      "{'loss': 0.2111, 'grad_norm': 6.172985553741455, 'learning_rate': 3.7e-05, 'epoch': 1.97}\n",
      "{'loss': 0.2471, 'grad_norm': 4.915154457092285, 'learning_rate': 3.688888888888889e-05, 'epoch': 1.98}\n",
      "{'loss': 0.3268, 'grad_norm': 16.863798141479492, 'learning_rate': 3.677777777777778e-05, 'epoch': 1.98}\n",
      "{'loss': 0.1784, 'grad_norm': 5.158685684204102, 'learning_rate': 3.6666666666666666e-05, 'epoch': 1.98}\n",
      "{'loss': 0.4211, 'grad_norm': 17.474637985229492, 'learning_rate': 3.655555555555556e-05, 'epoch': 1.99}\n",
      "{'loss': 0.1955, 'grad_norm': 4.379307270050049, 'learning_rate': 3.644444444444445e-05, 'epoch': 1.99}\n",
      "{'loss': 0.2348, 'grad_norm': 4.217288494110107, 'learning_rate': 3.633333333333333e-05, 'epoch': 1.99}\n",
      "{'loss': 0.275, 'grad_norm': 15.935317039489746, 'learning_rate': 3.6222222222222225e-05, 'epoch': 1.99}\n",
      "{'loss': 0.3037, 'grad_norm': 5.258251667022705, 'learning_rate': 3.611111111111111e-05, 'epoch': 2.0}\n",
      "{'loss': 0.385, 'grad_norm': 13.223947525024414, 'learning_rate': 3.6e-05, 'epoch': 2.0}\n",
      "{'loss': 0.2304, 'grad_norm': 6.404713153839111, 'learning_rate': 3.5888888888888886e-05, 'epoch': 2.0}\n",
      "{'loss': 0.2057, 'grad_norm': 3.8938965797424316, 'learning_rate': 3.577777777777778e-05, 'epoch': 2.01}\n",
      "{'loss': 0.3122, 'grad_norm': 4.901650905609131, 'learning_rate': 3.566666666666667e-05, 'epoch': 2.01}\n",
      "{'loss': 0.2598, 'grad_norm': 9.186615943908691, 'learning_rate': 3.555555555555556e-05, 'epoch': 2.01}\n",
      "{'loss': 0.2557, 'grad_norm': 10.622347831726074, 'learning_rate': 3.5444444444444445e-05, 'epoch': 2.01}\n",
      "{'loss': 0.1438, 'grad_norm': 4.515776634216309, 'learning_rate': 3.5333333333333336e-05, 'epoch': 2.02}\n",
      "{'loss': 0.1928, 'grad_norm': 6.180066108703613, 'learning_rate': 3.522222222222222e-05, 'epoch': 2.02}\n",
      "{'loss': 0.2452, 'grad_norm': 5.978329181671143, 'learning_rate': 3.511111111111111e-05, 'epoch': 2.02}\n",
      "{'loss': 0.523, 'grad_norm': 40.84219741821289, 'learning_rate': 3.5e-05, 'epoch': 2.03}\n",
      "{'loss': 0.3788, 'grad_norm': 12.470053672790527, 'learning_rate': 3.4888888888888895e-05, 'epoch': 2.03}\n",
      "{'loss': 0.2928, 'grad_norm': 13.478793144226074, 'learning_rate': 3.477777777777778e-05, 'epoch': 2.03}\n",
      "{'loss': 0.1542, 'grad_norm': 7.656398773193359, 'learning_rate': 3.466666666666667e-05, 'epoch': 2.04}\n",
      "{'loss': 0.215, 'grad_norm': 9.010497093200684, 'learning_rate': 3.4555555555555556e-05, 'epoch': 2.04}\n",
      "{'loss': 0.0871, 'grad_norm': 5.98270845413208, 'learning_rate': 3.444444444444445e-05, 'epoch': 2.04}\n",
      "{'loss': 0.2166, 'grad_norm': 5.213717937469482, 'learning_rate': 3.433333333333333e-05, 'epoch': 2.04}\n",
      "{'loss': 0.1776, 'grad_norm': 8.229825019836426, 'learning_rate': 3.4222222222222224e-05, 'epoch': 2.05}\n",
      "{'loss': 0.3879, 'grad_norm': 12.63607406616211, 'learning_rate': 3.411111111111111e-05, 'epoch': 2.05}\n",
      "{'loss': 0.3597, 'grad_norm': 6.524070739746094, 'learning_rate': 3.4000000000000007e-05, 'epoch': 2.05}\n",
      "{'loss': 0.2831, 'grad_norm': 12.641192436218262, 'learning_rate': 3.388888888888889e-05, 'epoch': 2.06}\n",
      "{'loss': 0.3059, 'grad_norm': 8.581917762756348, 'learning_rate': 3.377777777777778e-05, 'epoch': 2.06}\n",
      "{'loss': 0.2131, 'grad_norm': 8.762765884399414, 'learning_rate': 3.366666666666667e-05, 'epoch': 2.06}\n",
      "{'loss': 0.1695, 'grad_norm': 8.50082778930664, 'learning_rate': 3.355555555555556e-05, 'epoch': 2.07}\n",
      "{'loss': 0.1651, 'grad_norm': 6.363713264465332, 'learning_rate': 3.3444444444444443e-05, 'epoch': 2.07}\n",
      "{'loss': 0.2347, 'grad_norm': 17.602859497070312, 'learning_rate': 3.3333333333333335e-05, 'epoch': 2.07}\n",
      "{'loss': 0.2601, 'grad_norm': 10.31340503692627, 'learning_rate': 3.322222222222222e-05, 'epoch': 2.07}\n",
      "{'loss': 0.2746, 'grad_norm': 6.597854137420654, 'learning_rate': 3.311111111111112e-05, 'epoch': 2.08}\n",
      "{'loss': 0.6035, 'grad_norm': 12.439472198486328, 'learning_rate': 3.3e-05, 'epoch': 2.08}\n",
      "{'loss': 0.3237, 'grad_norm': 13.11374568939209, 'learning_rate': 3.2888888888888894e-05, 'epoch': 2.08}\n",
      "{'loss': 0.2213, 'grad_norm': 5.3482441902160645, 'learning_rate': 3.277777777777778e-05, 'epoch': 2.09}\n",
      "{'loss': 0.1556, 'grad_norm': 6.7009124755859375, 'learning_rate': 3.266666666666667e-05, 'epoch': 2.09}\n",
      "{'loss': 0.252, 'grad_norm': 9.084059715270996, 'learning_rate': 3.2555555555555555e-05, 'epoch': 2.09}\n",
      "{'loss': 0.2217, 'grad_norm': 7.244515419006348, 'learning_rate': 3.2444444444444446e-05, 'epoch': 2.09}\n",
      "{'loss': 0.1488, 'grad_norm': 8.084059715270996, 'learning_rate': 3.233333333333333e-05, 'epoch': 2.1}\n",
      "{'loss': 0.2192, 'grad_norm': 4.236448764801025, 'learning_rate': 3.222222222222223e-05, 'epoch': 2.1}\n",
      "{'loss': 0.3939, 'grad_norm': 14.571422576904297, 'learning_rate': 3.2111111111111114e-05, 'epoch': 2.1}\n",
      "{'loss': 0.1904, 'grad_norm': 3.6351423263549805, 'learning_rate': 3.2000000000000005e-05, 'epoch': 2.11}\n",
      "{'loss': 0.2068, 'grad_norm': 8.228081703186035, 'learning_rate': 3.188888888888889e-05, 'epoch': 2.11}\n",
      "{'loss': 0.2134, 'grad_norm': 8.117391586303711, 'learning_rate': 3.177777777777778e-05, 'epoch': 2.11}\n",
      "{'loss': 0.172, 'grad_norm': 9.065471649169922, 'learning_rate': 3.1666666666666666e-05, 'epoch': 2.12}\n",
      "{'loss': 0.2523, 'grad_norm': 9.406604766845703, 'learning_rate': 3.155555555555556e-05, 'epoch': 2.12}\n",
      "{'loss': 0.2783, 'grad_norm': 11.761161804199219, 'learning_rate': 3.144444444444445e-05, 'epoch': 2.12}\n",
      "{'loss': 0.1526, 'grad_norm': 3.4979422092437744, 'learning_rate': 3.1333333333333334e-05, 'epoch': 2.12}\n",
      "{'loss': 0.216, 'grad_norm': 14.831450462341309, 'learning_rate': 3.1222222222222225e-05, 'epoch': 2.13}\n",
      "{'loss': 0.1517, 'grad_norm': 4.518133640289307, 'learning_rate': 3.111111111111111e-05, 'epoch': 2.13}\n",
      "{'loss': 0.1043, 'grad_norm': 3.0436298847198486, 'learning_rate': 3.1e-05, 'epoch': 2.13}\n",
      "{'loss': 0.2124, 'grad_norm': 11.399806022644043, 'learning_rate': 3.088888888888889e-05, 'epoch': 2.14}\n",
      "{'loss': 0.1829, 'grad_norm': 5.857570171356201, 'learning_rate': 3.077777777777778e-05, 'epoch': 2.14}\n",
      "{'loss': 0.1985, 'grad_norm': 9.26357650756836, 'learning_rate': 3.066666666666667e-05, 'epoch': 2.14}\n",
      "{'loss': 0.1617, 'grad_norm': 8.012113571166992, 'learning_rate': 3.055555555555556e-05, 'epoch': 2.14}\n",
      "{'loss': 0.2371, 'grad_norm': 7.8771233558654785, 'learning_rate': 3.044444444444445e-05, 'epoch': 2.15}\n",
      "{'loss': 0.1898, 'grad_norm': 4.572041988372803, 'learning_rate': 3.0333333333333337e-05, 'epoch': 2.15}\n",
      "{'loss': 0.2948, 'grad_norm': 11.358799934387207, 'learning_rate': 3.0222222222222225e-05, 'epoch': 2.15}\n",
      "{'loss': 0.0691, 'grad_norm': 5.75646448135376, 'learning_rate': 3.0111111111111113e-05, 'epoch': 2.16}\n",
      "{'loss': 0.2957, 'grad_norm': 12.455635070800781, 'learning_rate': 3e-05, 'epoch': 2.16}\n",
      "{'loss': 0.2188, 'grad_norm': 6.950022220611572, 'learning_rate': 2.988888888888889e-05, 'epoch': 2.16}\n",
      "{'loss': 0.1614, 'grad_norm': 4.768161773681641, 'learning_rate': 2.9777777777777777e-05, 'epoch': 2.17}\n",
      "{'loss': 0.2416, 'grad_norm': 9.922395706176758, 'learning_rate': 2.9666666666666672e-05, 'epoch': 2.17}\n",
      "{'loss': 0.1688, 'grad_norm': 5.703797817230225, 'learning_rate': 2.955555555555556e-05, 'epoch': 2.17}\n",
      "{'loss': 0.1842, 'grad_norm': 16.057079315185547, 'learning_rate': 2.9444444444444448e-05, 'epoch': 2.17}\n",
      "{'loss': 0.19, 'grad_norm': 3.730269193649292, 'learning_rate': 2.9333333333333336e-05, 'epoch': 2.18}\n",
      "{'loss': 0.3464, 'grad_norm': 11.296356201171875, 'learning_rate': 2.9222222222222224e-05, 'epoch': 2.18}\n",
      "{'loss': 0.2094, 'grad_norm': 7.494575023651123, 'learning_rate': 2.9111111111111112e-05, 'epoch': 2.18}\n",
      "{'loss': 0.2803, 'grad_norm': 6.633047580718994, 'learning_rate': 2.9e-05, 'epoch': 2.19}\n",
      "{'loss': 0.2753, 'grad_norm': 15.36591625213623, 'learning_rate': 2.8888888888888888e-05, 'epoch': 2.19}\n",
      "{'loss': 0.2572, 'grad_norm': 9.620372772216797, 'learning_rate': 2.877777777777778e-05, 'epoch': 2.19}\n",
      "{'loss': 0.1915, 'grad_norm': 9.31982707977295, 'learning_rate': 2.8666666666666668e-05, 'epoch': 2.2}\n",
      "{'loss': 0.2908, 'grad_norm': 8.456964492797852, 'learning_rate': 2.855555555555556e-05, 'epoch': 2.2}\n",
      "{'loss': 0.293, 'grad_norm': 12.19841480255127, 'learning_rate': 2.8444444444444447e-05, 'epoch': 2.2}\n",
      "{'loss': 0.1534, 'grad_norm': 4.627444267272949, 'learning_rate': 2.8333333333333335e-05, 'epoch': 2.2}\n",
      "{'loss': 0.1834, 'grad_norm': 9.10828685760498, 'learning_rate': 2.8222222222222223e-05, 'epoch': 2.21}\n",
      "{'loss': 0.3371, 'grad_norm': 10.784631729125977, 'learning_rate': 2.811111111111111e-05, 'epoch': 2.21}\n",
      "{'loss': 0.3744, 'grad_norm': 6.847501277923584, 'learning_rate': 2.8000000000000003e-05, 'epoch': 2.21}\n",
      "{'loss': 0.1176, 'grad_norm': 8.299036026000977, 'learning_rate': 2.788888888888889e-05, 'epoch': 2.22}\n",
      "{'loss': 0.2054, 'grad_norm': 5.487534523010254, 'learning_rate': 2.777777777777778e-05, 'epoch': 2.22}\n",
      "{'loss': 0.1454, 'grad_norm': 8.091514587402344, 'learning_rate': 2.7666666666666667e-05, 'epoch': 2.22}\n",
      "{'loss': 0.1971, 'grad_norm': 7.564337730407715, 'learning_rate': 2.7555555555555555e-05, 'epoch': 2.22}\n",
      "{'loss': 0.1247, 'grad_norm': 4.646358013153076, 'learning_rate': 2.7444444444444443e-05, 'epoch': 2.23}\n",
      "{'loss': 0.2477, 'grad_norm': 8.934908866882324, 'learning_rate': 2.733333333333333e-05, 'epoch': 2.23}\n",
      "{'loss': 0.2036, 'grad_norm': 7.938473701477051, 'learning_rate': 2.7222222222222223e-05, 'epoch': 2.23}\n",
      "{'loss': 0.1628, 'grad_norm': 4.071837425231934, 'learning_rate': 2.7111111111111114e-05, 'epoch': 2.24}\n",
      "{'loss': 0.1684, 'grad_norm': 11.011306762695312, 'learning_rate': 2.7000000000000002e-05, 'epoch': 2.24}\n",
      "{'loss': 0.1588, 'grad_norm': 8.916749000549316, 'learning_rate': 2.688888888888889e-05, 'epoch': 2.24}\n",
      "{'loss': 0.1413, 'grad_norm': 4.708712100982666, 'learning_rate': 2.677777777777778e-05, 'epoch': 2.25}\n",
      "{'loss': 0.1495, 'grad_norm': 7.367927074432373, 'learning_rate': 2.6666666666666667e-05, 'epoch': 2.25}\n",
      "{'loss': 0.1009, 'grad_norm': 3.4992198944091797, 'learning_rate': 2.6555555555555555e-05, 'epoch': 2.25}\n",
      "{'loss': 0.2945, 'grad_norm': 7.437427043914795, 'learning_rate': 2.6444444444444443e-05, 'epoch': 2.25}\n",
      "{'loss': 0.1415, 'grad_norm': 7.760600566864014, 'learning_rate': 2.633333333333333e-05, 'epoch': 2.26}\n",
      "{'loss': 0.0425, 'grad_norm': 2.410736322402954, 'learning_rate': 2.6222222222222226e-05, 'epoch': 2.26}\n",
      "{'loss': 0.2568, 'grad_norm': 5.334359645843506, 'learning_rate': 2.6111111111111114e-05, 'epoch': 2.26}\n",
      "{'loss': 0.1026, 'grad_norm': 13.360332489013672, 'learning_rate': 2.6000000000000002e-05, 'epoch': 2.27}\n",
      "{'loss': 0.1629, 'grad_norm': 9.833662033081055, 'learning_rate': 2.588888888888889e-05, 'epoch': 2.27}\n",
      "{'loss': 0.2474, 'grad_norm': 12.428053855895996, 'learning_rate': 2.5777777777777778e-05, 'epoch': 2.27}\n",
      "{'loss': 0.0999, 'grad_norm': 3.026150941848755, 'learning_rate': 2.5666666666666666e-05, 'epoch': 2.28}\n",
      "{'loss': 0.2311, 'grad_norm': 7.342947483062744, 'learning_rate': 2.5555555555555554e-05, 'epoch': 2.28}\n",
      "{'loss': 0.1995, 'grad_norm': 5.7106218338012695, 'learning_rate': 2.5444444444444442e-05, 'epoch': 2.28}\n",
      "{'loss': 0.5362, 'grad_norm': 14.759955406188965, 'learning_rate': 2.5333333333333337e-05, 'epoch': 2.28}\n",
      "{'loss': 0.1134, 'grad_norm': 5.804505348205566, 'learning_rate': 2.5222222222222225e-05, 'epoch': 2.29}\n",
      "{'loss': 0.1699, 'grad_norm': 4.543341636657715, 'learning_rate': 2.5111111111111113e-05, 'epoch': 2.29}\n",
      "{'loss': 0.1891, 'grad_norm': 8.159210205078125, 'learning_rate': 2.5e-05, 'epoch': 2.29}\n",
      "{'loss': 0.0776, 'grad_norm': 4.501189231872559, 'learning_rate': 2.488888888888889e-05, 'epoch': 2.3}\n",
      "{'loss': 0.5602, 'grad_norm': 24.803485870361328, 'learning_rate': 2.477777777777778e-05, 'epoch': 2.3}\n",
      "{'loss': 0.1769, 'grad_norm': 6.273369312286377, 'learning_rate': 2.466666666666667e-05, 'epoch': 2.3}\n",
      "{'loss': 0.2344, 'grad_norm': 14.42827033996582, 'learning_rate': 2.4555555555555557e-05, 'epoch': 2.3}\n",
      "{'loss': 0.2805, 'grad_norm': 13.886256217956543, 'learning_rate': 2.4444444444444445e-05, 'epoch': 2.31}\n",
      "{'loss': 0.1236, 'grad_norm': 6.478574752807617, 'learning_rate': 2.4333333333333336e-05, 'epoch': 2.31}\n",
      "{'loss': 0.1517, 'grad_norm': 7.688773155212402, 'learning_rate': 2.4222222222222224e-05, 'epoch': 2.31}\n",
      "{'loss': 0.2518, 'grad_norm': 7.142380714416504, 'learning_rate': 2.4111111111111113e-05, 'epoch': 2.32}\n",
      "{'loss': 0.1485, 'grad_norm': 7.685512065887451, 'learning_rate': 2.4e-05, 'epoch': 2.32}\n",
      "{'loss': 0.0807, 'grad_norm': 8.369891166687012, 'learning_rate': 2.3888888888888892e-05, 'epoch': 2.32}\n",
      "{'loss': 0.2616, 'grad_norm': 7.888469219207764, 'learning_rate': 2.377777777777778e-05, 'epoch': 2.33}\n",
      "{'loss': 0.1234, 'grad_norm': 12.154151916503906, 'learning_rate': 2.3666666666666668e-05, 'epoch': 2.33}\n",
      "{'loss': 0.3493, 'grad_norm': 8.898419380187988, 'learning_rate': 2.3555555555555556e-05, 'epoch': 2.33}\n",
      "{'loss': 0.1264, 'grad_norm': 13.508600234985352, 'learning_rate': 2.3444444444444448e-05, 'epoch': 2.33}\n",
      "{'loss': 0.1372, 'grad_norm': 12.042119979858398, 'learning_rate': 2.3333333333333336e-05, 'epoch': 2.34}\n",
      "{'loss': 0.3493, 'grad_norm': 12.91722297668457, 'learning_rate': 2.3222222222222224e-05, 'epoch': 2.34}\n",
      "{'loss': 0.137, 'grad_norm': 5.68656063079834, 'learning_rate': 2.3111111111111112e-05, 'epoch': 2.34}\n",
      "{'loss': 0.1181, 'grad_norm': 6.523951530456543, 'learning_rate': 2.3000000000000003e-05, 'epoch': 2.35}\n",
      "{'loss': 0.2463, 'grad_norm': 13.297441482543945, 'learning_rate': 2.288888888888889e-05, 'epoch': 2.35}\n",
      "{'loss': 0.1507, 'grad_norm': 5.6947102546691895, 'learning_rate': 2.277777777777778e-05, 'epoch': 2.35}\n",
      "{'loss': 0.2349, 'grad_norm': 4.995016574859619, 'learning_rate': 2.2666666666666668e-05, 'epoch': 2.36}\n",
      "{'loss': 0.1541, 'grad_norm': 5.879386901855469, 'learning_rate': 2.255555555555556e-05, 'epoch': 2.36}\n",
      "{'loss': 0.2684, 'grad_norm': 11.054800987243652, 'learning_rate': 2.2444444444444447e-05, 'epoch': 2.36}\n",
      "{'loss': 0.2349, 'grad_norm': 17.266536712646484, 'learning_rate': 2.2333333333333335e-05, 'epoch': 2.36}\n",
      "{'loss': 0.2228, 'grad_norm': 14.597687721252441, 'learning_rate': 2.2222222222222223e-05, 'epoch': 2.37}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec07ddab9faa43c7a9ed21862428245c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3583008348941803, 'eval_f1': 0.8534418948926721, 'eval_runtime': 846.5001, 'eval_samples_per_second': 3.192, 'eval_steps_per_second': 0.1, 'epoch': 2.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/HDD/anaconda3/envs/AIS/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/HDD/anaconda3/envs/AIS/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5591, 'grad_norm': 15.300568580627441, 'learning_rate': 2.211111111111111e-05, 'epoch': 2.37}\n",
      "{'loss': 0.0734, 'grad_norm': 4.083217620849609, 'learning_rate': 2.2000000000000003e-05, 'epoch': 2.37}\n",
      "{'loss': 0.3302, 'grad_norm': 16.737276077270508, 'learning_rate': 2.188888888888889e-05, 'epoch': 2.38}\n",
      "{'loss': 0.2069, 'grad_norm': 6.334962368011475, 'learning_rate': 2.177777777777778e-05, 'epoch': 2.38}\n",
      "{'loss': 0.1315, 'grad_norm': 7.969024658203125, 'learning_rate': 2.1666666666666667e-05, 'epoch': 2.38}\n",
      "{'loss': 0.3225, 'grad_norm': 9.325034141540527, 'learning_rate': 2.1555555555555555e-05, 'epoch': 2.38}\n",
      "{'loss': 0.1641, 'grad_norm': 8.319960594177246, 'learning_rate': 2.1444444444444443e-05, 'epoch': 2.39}\n",
      "{'loss': 0.0992, 'grad_norm': 4.730285167694092, 'learning_rate': 2.1333333333333335e-05, 'epoch': 2.39}\n",
      "{'loss': 0.3109, 'grad_norm': 10.840936660766602, 'learning_rate': 2.1222222222222223e-05, 'epoch': 2.39}\n",
      "{'loss': 0.3456, 'grad_norm': 15.430804252624512, 'learning_rate': 2.111111111111111e-05, 'epoch': 2.4}\n",
      "{'loss': 0.327, 'grad_norm': 14.401288986206055, 'learning_rate': 2.1e-05, 'epoch': 2.4}\n",
      "{'loss': 0.2138, 'grad_norm': 9.763056755065918, 'learning_rate': 2.088888888888889e-05, 'epoch': 2.4}\n",
      "{'loss': 0.4877, 'grad_norm': 10.140857696533203, 'learning_rate': 2.077777777777778e-05, 'epoch': 2.41}\n",
      "{'loss': 0.1061, 'grad_norm': 3.6581130027770996, 'learning_rate': 2.0666666666666666e-05, 'epoch': 2.41}\n",
      "{'loss': 0.1861, 'grad_norm': 8.224797248840332, 'learning_rate': 2.0555555555555555e-05, 'epoch': 2.41}\n",
      "{'loss': 0.3087, 'grad_norm': 6.730212688446045, 'learning_rate': 2.0444444444444446e-05, 'epoch': 2.41}\n",
      "{'loss': 0.236, 'grad_norm': 17.068172454833984, 'learning_rate': 2.0333333333333334e-05, 'epoch': 2.42}\n",
      "{'loss': 0.2406, 'grad_norm': 6.873172760009766, 'learning_rate': 2.0222222222222222e-05, 'epoch': 2.42}\n",
      "{'loss': 0.1182, 'grad_norm': 5.783923625946045, 'learning_rate': 2.011111111111111e-05, 'epoch': 2.42}\n",
      "{'loss': 0.1913, 'grad_norm': 7.238710880279541, 'learning_rate': 2e-05, 'epoch': 2.43}\n",
      "{'loss': 0.2742, 'grad_norm': 5.960870742797852, 'learning_rate': 1.988888888888889e-05, 'epoch': 2.43}\n",
      "{'loss': 0.3071, 'grad_norm': 17.232295989990234, 'learning_rate': 1.9777777777777778e-05, 'epoch': 2.43}\n",
      "{'loss': 0.2769, 'grad_norm': 6.172830581665039, 'learning_rate': 1.9666666666666666e-05, 'epoch': 2.43}\n",
      "{'loss': 0.2489, 'grad_norm': 8.397618293762207, 'learning_rate': 1.9555555555555557e-05, 'epoch': 2.44}\n",
      "{'loss': 0.1254, 'grad_norm': 12.257959365844727, 'learning_rate': 1.9444444444444445e-05, 'epoch': 2.44}\n",
      "{'loss': 0.3105, 'grad_norm': 6.304813861846924, 'learning_rate': 1.9333333333333333e-05, 'epoch': 2.44}\n",
      "{'loss': 0.285, 'grad_norm': 11.715554237365723, 'learning_rate': 1.922222222222222e-05, 'epoch': 2.45}\n",
      "{'loss': 0.5379, 'grad_norm': 26.3096981048584, 'learning_rate': 1.9111111111111113e-05, 'epoch': 2.45}\n",
      "{'loss': 0.1061, 'grad_norm': 8.802739143371582, 'learning_rate': 1.9e-05, 'epoch': 2.45}\n",
      "{'loss': 0.0451, 'grad_norm': 3.0379536151885986, 'learning_rate': 1.888888888888889e-05, 'epoch': 2.46}\n",
      "{'loss': 0.4651, 'grad_norm': 26.83220863342285, 'learning_rate': 1.8777777777777777e-05, 'epoch': 2.46}\n",
      "{'loss': 0.2713, 'grad_norm': 7.37775182723999, 'learning_rate': 1.866666666666667e-05, 'epoch': 2.46}\n",
      "{'loss': 0.2471, 'grad_norm': 5.4622321128845215, 'learning_rate': 1.8555555555555557e-05, 'epoch': 2.46}\n",
      "{'loss': 0.2534, 'grad_norm': 10.197774887084961, 'learning_rate': 1.8444444444444445e-05, 'epoch': 2.47}\n",
      "{'loss': 0.1566, 'grad_norm': 5.84623908996582, 'learning_rate': 1.8333333333333333e-05, 'epoch': 2.47}\n",
      "{'loss': 0.1862, 'grad_norm': 7.4704437255859375, 'learning_rate': 1.8222222222222224e-05, 'epoch': 2.47}\n",
      "{'loss': 0.2345, 'grad_norm': 5.863738059997559, 'learning_rate': 1.8111111111111112e-05, 'epoch': 2.48}\n",
      "{'loss': 0.1853, 'grad_norm': 5.348368167877197, 'learning_rate': 1.8e-05, 'epoch': 2.48}\n",
      "{'loss': 0.4039, 'grad_norm': 13.892605781555176, 'learning_rate': 1.788888888888889e-05, 'epoch': 2.48}\n",
      "{'loss': 0.1616, 'grad_norm': 5.207129001617432, 'learning_rate': 1.777777777777778e-05, 'epoch': 2.49}\n",
      "{'loss': 0.0934, 'grad_norm': 3.7545924186706543, 'learning_rate': 1.7666666666666668e-05, 'epoch': 2.49}\n",
      "{'loss': 0.1205, 'grad_norm': 8.882872581481934, 'learning_rate': 1.7555555555555556e-05, 'epoch': 2.49}\n",
      "{'loss': 0.329, 'grad_norm': 19.350236892700195, 'learning_rate': 1.7444444444444448e-05, 'epoch': 2.49}\n",
      "{'loss': 0.3169, 'grad_norm': 13.702183723449707, 'learning_rate': 1.7333333333333336e-05, 'epoch': 2.5}\n",
      "{'loss': 0.2783, 'grad_norm': 4.735455513000488, 'learning_rate': 1.7222222222222224e-05, 'epoch': 2.5}\n",
      "{'loss': 0.2959, 'grad_norm': 7.392889499664307, 'learning_rate': 1.7111111111111112e-05, 'epoch': 2.5}\n",
      "{'loss': 0.187, 'grad_norm': 6.078539848327637, 'learning_rate': 1.7000000000000003e-05, 'epoch': 2.51}\n",
      "{'loss': 0.121, 'grad_norm': 5.330676078796387, 'learning_rate': 1.688888888888889e-05, 'epoch': 2.51}\n",
      "{'loss': 0.2309, 'grad_norm': 9.2518949508667, 'learning_rate': 1.677777777777778e-05, 'epoch': 2.51}\n",
      "{'loss': 0.3566, 'grad_norm': 10.575078010559082, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.51}\n",
      "{'loss': 0.246, 'grad_norm': 6.825026512145996, 'learning_rate': 1.655555555555556e-05, 'epoch': 2.52}\n",
      "{'loss': 0.3809, 'grad_norm': 6.691106796264648, 'learning_rate': 1.6444444444444447e-05, 'epoch': 2.52}\n",
      "{'loss': 0.2292, 'grad_norm': 13.51227855682373, 'learning_rate': 1.6333333333333335e-05, 'epoch': 2.52}\n",
      "{'loss': 0.1235, 'grad_norm': 5.79071044921875, 'learning_rate': 1.6222222222222223e-05, 'epoch': 2.53}\n",
      "{'loss': 0.4454, 'grad_norm': 29.519847869873047, 'learning_rate': 1.6111111111111115e-05, 'epoch': 2.53}\n",
      "{'loss': 0.1665, 'grad_norm': 5.551687240600586, 'learning_rate': 1.6000000000000003e-05, 'epoch': 2.53}\n",
      "{'loss': 0.0679, 'grad_norm': 4.507885456085205, 'learning_rate': 1.588888888888889e-05, 'epoch': 2.54}\n",
      "{'loss': 0.2113, 'grad_norm': 13.109485626220703, 'learning_rate': 1.577777777777778e-05, 'epoch': 2.54}\n",
      "{'loss': 0.3446, 'grad_norm': 10.272279739379883, 'learning_rate': 1.5666666666666667e-05, 'epoch': 2.54}\n",
      "{'loss': 0.267, 'grad_norm': 7.7229323387146, 'learning_rate': 1.5555555555555555e-05, 'epoch': 2.54}\n",
      "{'loss': 0.1744, 'grad_norm': 9.200307846069336, 'learning_rate': 1.5444444444444446e-05, 'epoch': 2.55}\n",
      "{'loss': 0.2516, 'grad_norm': 12.636744499206543, 'learning_rate': 1.5333333333333334e-05, 'epoch': 2.55}\n",
      "{'loss': 0.1397, 'grad_norm': 8.930403709411621, 'learning_rate': 1.5222222222222224e-05, 'epoch': 2.55}\n",
      "{'loss': 0.1082, 'grad_norm': 11.521127700805664, 'learning_rate': 1.5111111111111112e-05, 'epoch': 2.56}\n",
      "{'loss': 0.2139, 'grad_norm': 10.6957368850708, 'learning_rate': 1.5e-05, 'epoch': 2.56}\n",
      "{'loss': 0.4193, 'grad_norm': 30.98399543762207, 'learning_rate': 1.4888888888888888e-05, 'epoch': 2.56}\n",
      "{'loss': 0.1625, 'grad_norm': 9.958785057067871, 'learning_rate': 1.477777777777778e-05, 'epoch': 2.57}\n",
      "{'loss': 0.1925, 'grad_norm': 5.852067947387695, 'learning_rate': 1.4666666666666668e-05, 'epoch': 2.57}\n",
      "{'loss': 0.2855, 'grad_norm': 8.316666603088379, 'learning_rate': 1.4555555555555556e-05, 'epoch': 2.57}\n",
      "{'loss': 0.3175, 'grad_norm': 6.814608097076416, 'learning_rate': 1.4444444444444444e-05, 'epoch': 2.57}\n",
      "{'loss': 0.2769, 'grad_norm': 6.605434894561768, 'learning_rate': 1.4333333333333334e-05, 'epoch': 2.58}\n",
      "{'loss': 0.1137, 'grad_norm': 7.092526435852051, 'learning_rate': 1.4222222222222224e-05, 'epoch': 2.58}\n",
      "{'loss': 0.1554, 'grad_norm': 9.742697715759277, 'learning_rate': 1.4111111111111112e-05, 'epoch': 2.58}\n",
      "{'loss': 0.2172, 'grad_norm': 14.725396156311035, 'learning_rate': 1.4000000000000001e-05, 'epoch': 2.59}\n",
      "{'loss': 0.313, 'grad_norm': 9.265246391296387, 'learning_rate': 1.388888888888889e-05, 'epoch': 2.59}\n",
      "{'loss': 0.2198, 'grad_norm': 7.527859687805176, 'learning_rate': 1.3777777777777778e-05, 'epoch': 2.59}\n",
      "{'loss': 0.1328, 'grad_norm': 10.33311653137207, 'learning_rate': 1.3666666666666666e-05, 'epoch': 2.59}\n",
      "{'loss': 0.2503, 'grad_norm': 6.584764003753662, 'learning_rate': 1.3555555555555557e-05, 'epoch': 2.6}\n",
      "{'loss': 0.0968, 'grad_norm': 3.644867181777954, 'learning_rate': 1.3444444444444445e-05, 'epoch': 2.6}\n",
      "{'loss': 0.242, 'grad_norm': 10.81017780303955, 'learning_rate': 1.3333333333333333e-05, 'epoch': 2.6}\n",
      "{'loss': 0.1775, 'grad_norm': 7.849219799041748, 'learning_rate': 1.3222222222222221e-05, 'epoch': 2.61}\n",
      "{'loss': 0.2347, 'grad_norm': 11.062612533569336, 'learning_rate': 1.3111111111111113e-05, 'epoch': 2.61}\n",
      "{'loss': 0.1211, 'grad_norm': 6.295886993408203, 'learning_rate': 1.3000000000000001e-05, 'epoch': 2.61}\n",
      "{'loss': 0.2428, 'grad_norm': 7.8479156494140625, 'learning_rate': 1.2888888888888889e-05, 'epoch': 2.62}\n",
      "{'loss': 0.1969, 'grad_norm': 5.5095601081848145, 'learning_rate': 1.2777777777777777e-05, 'epoch': 2.62}\n",
      "{'loss': 0.3829, 'grad_norm': 9.857990264892578, 'learning_rate': 1.2666666666666668e-05, 'epoch': 2.62}\n",
      "{'loss': 0.0931, 'grad_norm': 4.188445568084717, 'learning_rate': 1.2555555555555557e-05, 'epoch': 2.62}\n",
      "{'loss': 0.2643, 'grad_norm': 6.563122272491455, 'learning_rate': 1.2444444444444445e-05, 'epoch': 2.63}\n",
      "{'loss': 0.0833, 'grad_norm': 5.868740081787109, 'learning_rate': 1.2333333333333334e-05, 'epoch': 2.63}\n",
      "{'loss': 0.1691, 'grad_norm': 6.2039971351623535, 'learning_rate': 1.2222222222222222e-05, 'epoch': 2.63}\n",
      "{'loss': 0.2761, 'grad_norm': 10.065675735473633, 'learning_rate': 1.2111111111111112e-05, 'epoch': 2.64}\n",
      "{'loss': 0.1303, 'grad_norm': 5.08325719833374, 'learning_rate': 1.2e-05, 'epoch': 2.64}\n",
      "{'loss': 0.2046, 'grad_norm': 4.922506809234619, 'learning_rate': 1.188888888888889e-05, 'epoch': 2.64}\n",
      "{'loss': 0.0598, 'grad_norm': 6.007766246795654, 'learning_rate': 1.1777777777777778e-05, 'epoch': 2.64}\n",
      "{'loss': 0.2808, 'grad_norm': 7.099747657775879, 'learning_rate': 1.1666666666666668e-05, 'epoch': 2.65}\n",
      "{'loss': 0.2935, 'grad_norm': 5.833065509796143, 'learning_rate': 1.1555555555555556e-05, 'epoch': 2.65}\n",
      "{'loss': 0.2909, 'grad_norm': 7.754574775695801, 'learning_rate': 1.1444444444444446e-05, 'epoch': 2.65}\n",
      "{'loss': 0.1851, 'grad_norm': 14.517799377441406, 'learning_rate': 1.1333333333333334e-05, 'epoch': 2.66}\n",
      "{'loss': 0.2474, 'grad_norm': 8.701436042785645, 'learning_rate': 1.1222222222222224e-05, 'epoch': 2.66}\n",
      "{'loss': 0.0958, 'grad_norm': 3.250891923904419, 'learning_rate': 1.1111111111111112e-05, 'epoch': 2.66}\n",
      "{'loss': 0.4351, 'grad_norm': 8.191359519958496, 'learning_rate': 1.1000000000000001e-05, 'epoch': 2.67}\n",
      "{'loss': 0.1842, 'grad_norm': 16.4291934967041, 'learning_rate': 1.088888888888889e-05, 'epoch': 2.67}\n",
      "{'loss': 0.3302, 'grad_norm': 11.81849479675293, 'learning_rate': 1.0777777777777778e-05, 'epoch': 2.67}\n",
      "{'loss': 0.1152, 'grad_norm': 11.077020645141602, 'learning_rate': 1.0666666666666667e-05, 'epoch': 2.67}\n",
      "{'loss': 0.1297, 'grad_norm': 10.043807983398438, 'learning_rate': 1.0555555555555555e-05, 'epoch': 2.68}\n",
      "{'loss': 0.1172, 'grad_norm': 6.090947151184082, 'learning_rate': 1.0444444444444445e-05, 'epoch': 2.68}\n",
      "{'loss': 0.3089, 'grad_norm': 20.714218139648438, 'learning_rate': 1.0333333333333333e-05, 'epoch': 2.68}\n",
      "{'loss': 0.1556, 'grad_norm': 8.528267860412598, 'learning_rate': 1.0222222222222223e-05, 'epoch': 2.69}\n",
      "{'loss': 0.1369, 'grad_norm': 12.40937614440918, 'learning_rate': 1.0111111111111111e-05, 'epoch': 2.69}\n",
      "{'loss': 0.2567, 'grad_norm': 9.657251358032227, 'learning_rate': 1e-05, 'epoch': 2.69}\n",
      "{'loss': 0.2304, 'grad_norm': 15.465532302856445, 'learning_rate': 9.888888888888889e-06, 'epoch': 2.7}\n",
      "{'loss': 0.1768, 'grad_norm': 6.432822227478027, 'learning_rate': 9.777777777777779e-06, 'epoch': 2.7}\n",
      "{'loss': 0.1239, 'grad_norm': 7.13606595993042, 'learning_rate': 9.666666666666667e-06, 'epoch': 2.7}\n",
      "{'loss': 0.0617, 'grad_norm': 5.815152168273926, 'learning_rate': 9.555555555555556e-06, 'epoch': 2.7}\n",
      "{'loss': 0.1581, 'grad_norm': 7.757179260253906, 'learning_rate': 9.444444444444445e-06, 'epoch': 2.71}\n",
      "{'loss': 0.122, 'grad_norm': 5.753157138824463, 'learning_rate': 9.333333333333334e-06, 'epoch': 2.71}\n",
      "{'loss': 0.1948, 'grad_norm': 4.5745015144348145, 'learning_rate': 9.222222222222222e-06, 'epoch': 2.71}\n",
      "{'loss': 0.1911, 'grad_norm': 5.373142719268799, 'learning_rate': 9.111111111111112e-06, 'epoch': 2.72}\n",
      "{'loss': 0.1558, 'grad_norm': 4.938533782958984, 'learning_rate': 9e-06, 'epoch': 2.72}\n",
      "{'loss': 0.1877, 'grad_norm': 6.811249732971191, 'learning_rate': 8.88888888888889e-06, 'epoch': 2.72}\n",
      "{'loss': 0.1274, 'grad_norm': 5.732710838317871, 'learning_rate': 8.777777777777778e-06, 'epoch': 2.72}\n",
      "{'loss': 0.2826, 'grad_norm': 14.962512016296387, 'learning_rate': 8.666666666666668e-06, 'epoch': 2.73}\n",
      "{'loss': 0.0828, 'grad_norm': 5.370089530944824, 'learning_rate': 8.555555555555556e-06, 'epoch': 2.73}\n",
      "{'loss': 0.316, 'grad_norm': 13.310829162597656, 'learning_rate': 8.444444444444446e-06, 'epoch': 2.73}\n",
      "{'loss': 0.3942, 'grad_norm': 9.807024002075195, 'learning_rate': 8.333333333333334e-06, 'epoch': 2.74}\n",
      "{'loss': 0.1177, 'grad_norm': 4.449888229370117, 'learning_rate': 8.222222222222223e-06, 'epoch': 2.74}\n",
      "{'loss': 0.2401, 'grad_norm': 13.100666999816895, 'learning_rate': 8.111111111111112e-06, 'epoch': 2.74}\n",
      "{'loss': 0.2009, 'grad_norm': 8.781820297241211, 'learning_rate': 8.000000000000001e-06, 'epoch': 2.75}\n",
      "{'loss': 0.281, 'grad_norm': 11.690186500549316, 'learning_rate': 7.88888888888889e-06, 'epoch': 2.75}\n",
      "{'loss': 0.2496, 'grad_norm': 10.493659973144531, 'learning_rate': 7.777777777777777e-06, 'epoch': 2.75}\n",
      "{'loss': 0.5153, 'grad_norm': 9.697723388671875, 'learning_rate': 7.666666666666667e-06, 'epoch': 2.75}\n",
      "{'loss': 0.1177, 'grad_norm': 4.838150501251221, 'learning_rate': 7.555555555555556e-06, 'epoch': 2.76}\n",
      "{'loss': 0.3067, 'grad_norm': 13.938752174377441, 'learning_rate': 7.444444444444444e-06, 'epoch': 2.76}\n",
      "{'loss': 0.2321, 'grad_norm': 5.938438415527344, 'learning_rate': 7.333333333333334e-06, 'epoch': 2.76}\n",
      "{'loss': 0.2278, 'grad_norm': 14.329904556274414, 'learning_rate': 7.222222222222222e-06, 'epoch': 2.77}\n",
      "{'loss': 0.1729, 'grad_norm': 6.345469951629639, 'learning_rate': 7.111111111111112e-06, 'epoch': 2.77}\n",
      "{'loss': 0.1759, 'grad_norm': 17.005508422851562, 'learning_rate': 7.000000000000001e-06, 'epoch': 2.77}\n",
      "{'loss': 0.2026, 'grad_norm': 6.446166038513184, 'learning_rate': 6.888888888888889e-06, 'epoch': 2.78}\n",
      "{'loss': 0.1619, 'grad_norm': 5.991452217102051, 'learning_rate': 6.777777777777779e-06, 'epoch': 2.78}\n",
      "{'loss': 0.2522, 'grad_norm': 10.02150821685791, 'learning_rate': 6.666666666666667e-06, 'epoch': 2.78}\n",
      "{'loss': 0.1229, 'grad_norm': 4.5419840812683105, 'learning_rate': 6.555555555555556e-06, 'epoch': 2.78}\n",
      "{'loss': 0.1423, 'grad_norm': 9.58743953704834, 'learning_rate': 6.4444444444444445e-06, 'epoch': 2.79}\n",
      "{'loss': 0.368, 'grad_norm': 15.051041603088379, 'learning_rate': 6.333333333333334e-06, 'epoch': 2.79}\n",
      "{'loss': 0.0993, 'grad_norm': 5.0353522300720215, 'learning_rate': 6.222222222222222e-06, 'epoch': 2.79}\n",
      "{'loss': 0.109, 'grad_norm': 7.988036155700684, 'learning_rate': 6.111111111111111e-06, 'epoch': 2.8}\n",
      "{'loss': 0.4792, 'grad_norm': 8.944350242614746, 'learning_rate': 6e-06, 'epoch': 2.8}\n",
      "{'loss': 0.3784, 'grad_norm': 14.449566841125488, 'learning_rate': 5.888888888888889e-06, 'epoch': 2.8}\n",
      "{'loss': 0.1554, 'grad_norm': 4.669223308563232, 'learning_rate': 5.777777777777778e-06, 'epoch': 2.8}\n",
      "{'loss': 0.2395, 'grad_norm': 7.611572742462158, 'learning_rate': 5.666666666666667e-06, 'epoch': 2.81}\n",
      "{'loss': 0.1929, 'grad_norm': 7.1260151863098145, 'learning_rate': 5.555555555555556e-06, 'epoch': 2.81}\n",
      "{'loss': 0.0612, 'grad_norm': 2.03041672706604, 'learning_rate': 5.444444444444445e-06, 'epoch': 2.81}\n",
      "{'loss': 0.2183, 'grad_norm': 18.86992073059082, 'learning_rate': 5.333333333333334e-06, 'epoch': 2.82}\n",
      "{'loss': 0.3358, 'grad_norm': 18.081462860107422, 'learning_rate': 5.2222222222222226e-06, 'epoch': 2.82}\n",
      "{'loss': 0.2665, 'grad_norm': 7.463919639587402, 'learning_rate': 5.1111111111111115e-06, 'epoch': 2.82}\n",
      "{'loss': 0.2786, 'grad_norm': 13.852907180786133, 'learning_rate': 5e-06, 'epoch': 2.83}\n",
      "{'loss': 0.1326, 'grad_norm': 3.972611665725708, 'learning_rate': 4.888888888888889e-06, 'epoch': 2.83}\n",
      "{'loss': 0.4293, 'grad_norm': 26.824987411499023, 'learning_rate': 4.777777777777778e-06, 'epoch': 2.83}\n",
      "{'loss': 0.2929, 'grad_norm': 15.108784675598145, 'learning_rate': 4.666666666666667e-06, 'epoch': 2.83}\n",
      "{'loss': 0.2014, 'grad_norm': 15.548799514770508, 'learning_rate': 4.555555555555556e-06, 'epoch': 2.84}\n",
      "{'loss': 0.3489, 'grad_norm': 9.46787166595459, 'learning_rate': 4.444444444444445e-06, 'epoch': 2.84}\n",
      "{'loss': 0.2504, 'grad_norm': 7.714321136474609, 'learning_rate': 4.333333333333334e-06, 'epoch': 2.84}\n",
      "{'loss': 0.1862, 'grad_norm': 6.5073771476745605, 'learning_rate': 4.222222222222223e-06, 'epoch': 2.85}\n",
      "{'loss': 0.2075, 'grad_norm': 9.512484550476074, 'learning_rate': 4.111111111111112e-06, 'epoch': 2.85}\n",
      "{'loss': 0.0682, 'grad_norm': 2.49613881111145, 'learning_rate': 4.000000000000001e-06, 'epoch': 2.85}\n",
      "{'loss': 0.1441, 'grad_norm': 10.375941276550293, 'learning_rate': 3.888888888888889e-06, 'epoch': 2.86}\n",
      "{'loss': 0.223, 'grad_norm': 6.07021427154541, 'learning_rate': 3.777777777777778e-06, 'epoch': 2.86}\n",
      "{'loss': 0.4009, 'grad_norm': 6.368527412414551, 'learning_rate': 3.666666666666667e-06, 'epoch': 2.86}\n",
      "{'loss': 0.1609, 'grad_norm': 4.3974223136901855, 'learning_rate': 3.555555555555556e-06, 'epoch': 2.86}\n",
      "{'loss': 0.2123, 'grad_norm': 6.647777557373047, 'learning_rate': 3.4444444444444444e-06, 'epoch': 2.87}\n",
      "{'loss': 0.1967, 'grad_norm': 12.011374473571777, 'learning_rate': 3.3333333333333333e-06, 'epoch': 2.87}\n",
      "{'loss': 0.1933, 'grad_norm': 5.74544620513916, 'learning_rate': 3.2222222222222222e-06, 'epoch': 2.87}\n",
      "{'loss': 0.3289, 'grad_norm': 14.382939338684082, 'learning_rate': 3.111111111111111e-06, 'epoch': 2.88}\n",
      "{'loss': 0.1886, 'grad_norm': 16.761545181274414, 'learning_rate': 3e-06, 'epoch': 2.88}\n",
      "{'loss': 0.306, 'grad_norm': 16.03973388671875, 'learning_rate': 2.888888888888889e-06, 'epoch': 2.88}\n",
      "{'loss': 0.2158, 'grad_norm': 5.7143707275390625, 'learning_rate': 2.777777777777778e-06, 'epoch': 2.88}\n",
      "{'loss': 0.152, 'grad_norm': 3.9328882694244385, 'learning_rate': 2.666666666666667e-06, 'epoch': 2.89}\n",
      "{'loss': 0.227, 'grad_norm': 6.2495317459106445, 'learning_rate': 2.5555555555555557e-06, 'epoch': 2.89}\n",
      "{'loss': 0.4023, 'grad_norm': 11.105426788330078, 'learning_rate': 2.4444444444444447e-06, 'epoch': 2.89}\n",
      "{'loss': 0.1913, 'grad_norm': 8.955824851989746, 'learning_rate': 2.3333333333333336e-06, 'epoch': 2.9}\n",
      "{'loss': 0.1378, 'grad_norm': 9.975499153137207, 'learning_rate': 2.2222222222222225e-06, 'epoch': 2.9}\n",
      "{'loss': 0.1683, 'grad_norm': 5.958371639251709, 'learning_rate': 2.1111111111111114e-06, 'epoch': 2.9}\n",
      "{'loss': 0.1983, 'grad_norm': 11.595132827758789, 'learning_rate': 2.0000000000000003e-06, 'epoch': 2.91}\n",
      "{'loss': 0.2864, 'grad_norm': 6.235973834991455, 'learning_rate': 1.888888888888889e-06, 'epoch': 2.91}\n",
      "{'loss': 0.2193, 'grad_norm': 11.157241821289062, 'learning_rate': 1.777777777777778e-06, 'epoch': 2.91}\n",
      "{'loss': 0.2559, 'grad_norm': 10.230487823486328, 'learning_rate': 1.6666666666666667e-06, 'epoch': 2.91}\n",
      "{'loss': 0.1761, 'grad_norm': 10.095941543579102, 'learning_rate': 1.5555555555555556e-06, 'epoch': 2.92}\n",
      "{'loss': 0.2628, 'grad_norm': 8.647289276123047, 'learning_rate': 1.4444444444444445e-06, 'epoch': 2.92}\n",
      "{'loss': 0.1443, 'grad_norm': 9.917682647705078, 'learning_rate': 1.3333333333333334e-06, 'epoch': 2.92}\n",
      "{'loss': 0.1355, 'grad_norm': 4.803474426269531, 'learning_rate': 1.2222222222222223e-06, 'epoch': 2.93}\n",
      "{'loss': 0.1144, 'grad_norm': 8.15444564819336, 'learning_rate': 1.1111111111111112e-06, 'epoch': 2.93}\n",
      "{'loss': 0.2503, 'grad_norm': 10.003358840942383, 'learning_rate': 1.0000000000000002e-06, 'epoch': 2.93}\n",
      "{'loss': 0.4104, 'grad_norm': 6.8239054679870605, 'learning_rate': 8.88888888888889e-07, 'epoch': 2.93}\n",
      "{'loss': 0.2259, 'grad_norm': 7.209998607635498, 'learning_rate': 7.777777777777778e-07, 'epoch': 2.94}\n",
      "{'loss': 0.1293, 'grad_norm': 4.152981281280518, 'learning_rate': 6.666666666666667e-07, 'epoch': 2.94}\n",
      "{'loss': 0.1731, 'grad_norm': 16.509077072143555, 'learning_rate': 5.555555555555556e-07, 'epoch': 2.94}\n",
      "{'loss': 0.1199, 'grad_norm': 12.193693161010742, 'learning_rate': 4.444444444444445e-07, 'epoch': 2.95}\n",
      "{'loss': 0.2308, 'grad_norm': 9.615890502929688, 'learning_rate': 3.3333333333333335e-07, 'epoch': 2.95}\n",
      "{'loss': 0.2933, 'grad_norm': 12.428579330444336, 'learning_rate': 2.2222222222222224e-07, 'epoch': 2.95}\n",
      "{'loss': 0.4763, 'grad_norm': 7.9704389572143555, 'learning_rate': 1.1111111111111112e-07, 'epoch': 2.96}\n",
      "{'loss': 0.3296, 'grad_norm': 6.522151470184326, 'learning_rate': 0.0, 'epoch': 2.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c649b90e9cf34ba18ef876cbb9d66b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3354032337665558, 'eval_f1': 0.8578830495928942, 'eval_runtime': 846.784, 'eval_samples_per_second': 3.191, 'eval_steps_per_second': 0.1, 'epoch': 2.96}\n",
      "{'train_runtime': 35128.4898, 'train_samples_per_second': 0.911, 'train_steps_per_second': 0.028, 'train_loss': 0.40187835543602707, 'epoch': 2.96}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=0.40187835543602707, metrics={'train_runtime': 35128.4898, 'train_samples_per_second': 0.911, 'train_steps_per_second': 0.028, 'total_flos': 5.144574020372398e+17, 'train_loss': 0.40187835543602707, 'epoch': 2.9585798816568047})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.use_cache=False\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.train()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('fine-tuned model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference + Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571d7339025d43429634ab8f2d637fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at taide/Llama3-TAIDE-LX-8B-Chat-Alpha1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from peft import AutoPeftModelForSequenceClassification, PeftModel\n",
    "\n",
    "base_model_name = 'taide/Llama3-TAIDE-LX-8B-Chat-Alpha1'\n",
    "adapter_model_path = './fine-tuned model'\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_name, \n",
    "    add_prefix_space=True, \n",
    "    cache_dir = '/HDD/model_cache'\n",
    ")\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    base_model_name,\n",
    "    cache_dir = '/HDD/model_cache',\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(base_model, adapter_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LABEL_1: 詐騙 #LABEL_2: 非詐騙\n",
    "from transformers import pipeline\n",
    "peft_model.eval()\n",
    "classifier = pipeline(\n",
    "    model=peft_model,\n",
    "    tokenizer=tokenizer,\n",
    "    task='sentiment-analysis',\n",
    "    device=0,\n",
    ")\n",
    "classifier(work_dataset[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "def get_evaluation_dataset(path:str)->dict:\n",
    "    data: list[dict] = json.loads(Path(path).read_text(encoding='utf-8'))['thread']\n",
    "    dataset = [{\"text\": datapoint['text'], \"label\": datapoint['label']} for datapoint in data]\n",
    "    return dataset\n",
    "work_dataset = get_evaluation_dataset('labeled_datasets/data_1.json')\n",
    "gambling_dataset = get_evaluation_dataset('labeled_datasets/data_2.json')\n",
    "dating_dataset = get_evaluation_dataset('labeled_datasets/data_3.json')\n",
    "investment_dataset = get_evaluation_dataset('labeled_datasets/data_4.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:05<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category: work, F1 score: 0.8421052631578947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:07<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category: gambling, F1 score: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:05<00:00,  9.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category: dating, F1 score: 0.6557377049180327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:08<00:00,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category: investment, F1 score: 0.8260869565217391\n",
      "total F1 0.7307692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "from sklearn.metrics import f1_score\n",
    "total_true_labels = []\n",
    "total_predictions = []\n",
    "def get_score(category: str, dataset):\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        prediction = classifier(dataset[i]['text'])[0]\n",
    "        predicted_label = 1 if prediction['label'] == 'LABEL_1' else 0\n",
    "        score = prediction['score']\n",
    "        dataset[i]['prediction'] = predicted_label\n",
    "        dataset[i]['score'] = score\n",
    "    with open(f'test_result/test_result_{category}', 'w', encoding='utf-8') as f:\n",
    "        json.dump(dataset, f, ensure_ascii=False, indent=4)\n",
    "    true_labels = [item['label'] for item in dataset]\n",
    "    predictions = [item['prediction'] for item in dataset]\n",
    "    total_true_labels.extend(true_labels)\n",
    "    total_predictions.extend(predictions)\n",
    "    f1 = f1_score(y_true=true_labels, y_pred=predictions)\n",
    "    print(f'category: {category}, F1 score: {f1}')\n",
    "\n",
    "get_score('work', work_dataset)\n",
    "get_score('gambling', gambling_dataset)\n",
    "get_score('dating', dating_dataset)\n",
    "get_score('investment', investment_dataset)\n",
    "print(f'total F1 {f1_score(y_true=total_true_labels, y_pred=total_predictions)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
